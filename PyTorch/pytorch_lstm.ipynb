{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahcVCM5FqGSN"
   },
   "source": [
    "### Pytorch.  LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1602574838712,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "_ilP4ka-rSqX",
    "outputId": "8e479d9c-bb20-4c7b-f7a5-12a0ed5770fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1602574839697,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "KtSTJ1hJqGSY",
    "outputId": "07bd7d61-17dd-4f9a-ea32-662a34686700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVB6hsRrqGSl"
   },
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim,layer_num):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = torch.nn.LSTM(input_dim, hidden_dim,layer_num,batch_first=True)\n",
    "        self.dr = torch.nn.Dropout2d(0.25)\n",
    "        self.fc = torch.nn.Linear(hidden_dim,output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = inputs\n",
    "        lstm_out,(hn,cn) = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:,-1,:])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvlBwpIx09F_"
   },
   "source": [
    "Я выбрал следующие классы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2xTkyxPqGSn"
   },
   "source": [
    "\n",
    " - 0 sitting down\n",
    " - 1 standing up (from sitting position)\n",
    " - 2 clapping\n",
    " - 3 reading\n",
    " - 4 writing\n",
    " - 5 take off a hat/cap\n",
    " - 6 cheer up\n",
    " - 7 hand waving\n",
    " - 8 jump up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IgO6W412qGSo"
   },
   "outputs": [],
   "source": [
    "skeletons = pd.read_csv(\"/content/drive/My Drive/PyTorch/test_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aOc-5HWqGSr"
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    0: \"sitting down\", \n",
    "    1: \"standing up\", \n",
    "    2: \"clapping\", \n",
    "    3: \"reading\", \n",
    "    4: \"writing\", \n",
    "    5: \"take off a hat/cap\", \n",
    "    6: \"cheer up\", \n",
    "    7: \"hand waving\", \n",
    "    8: \"jump up\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 3182,
     "status": "ok",
     "timestamp": 1602574841046,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "ReYnGB71qGSt",
    "outputId": "b2c7e73e-a080-46f1-bbe5-b409ac2a3846",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>3336</th>\n",
       "      <th>3337</th>\n",
       "      <th>3338</th>\n",
       "      <th>3339</th>\n",
       "      <th>3340</th>\n",
       "      <th>3341</th>\n",
       "      <th>3342</th>\n",
       "      <th>3343</th>\n",
       "      <th>3344</th>\n",
       "      <th>3345</th>\n",
       "      <th>3346</th>\n",
       "      <th>3347</th>\n",
       "      <th>3348</th>\n",
       "      <th>3349</th>\n",
       "      <th>3350</th>\n",
       "      <th>3351</th>\n",
       "      <th>3352</th>\n",
       "      <th>3353</th>\n",
       "      <th>3354</th>\n",
       "      <th>3355</th>\n",
       "      <th>3356</th>\n",
       "      <th>3357</th>\n",
       "      <th>3358</th>\n",
       "      <th>3359</th>\n",
       "      <th>3360</th>\n",
       "      <th>3361</th>\n",
       "      <th>3362</th>\n",
       "      <th>3363</th>\n",
       "      <th>3364</th>\n",
       "      <th>3365</th>\n",
       "      <th>3366</th>\n",
       "      <th>3367</th>\n",
       "      <th>3368</th>\n",
       "      <th>3369</th>\n",
       "      <th>3370</th>\n",
       "      <th>3371</th>\n",
       "      <th>3372</th>\n",
       "      <th>3373</th>\n",
       "      <th>3374</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.080141</td>\n",
       "      <td>0.135073</td>\n",
       "      <td>3.691227</td>\n",
       "      <td>-0.058513</td>\n",
       "      <td>0.396866</td>\n",
       "      <td>3.606265</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>0.652906</td>\n",
       "      <td>3.509790</td>\n",
       "      <td>-0.066903</td>\n",
       "      <td>0.771350</td>\n",
       "      <td>3.486234</td>\n",
       "      <td>-0.164331</td>\n",
       "      <td>0.563798</td>\n",
       "      <td>3.590046</td>\n",
       "      <td>-0.190102</td>\n",
       "      <td>0.352717</td>\n",
       "      <td>3.684158</td>\n",
       "      <td>-0.216094</td>\n",
       "      <td>0.134737</td>\n",
       "      <td>3.713189</td>\n",
       "      <td>-0.213840</td>\n",
       "      <td>0.078266</td>\n",
       "      <td>3.713352</td>\n",
       "      <td>0.055824</td>\n",
       "      <td>0.536555</td>\n",
       "      <td>3.467626</td>\n",
       "      <td>0.093535</td>\n",
       "      <td>0.305820</td>\n",
       "      <td>3.504891</td>\n",
       "      <td>0.066233</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>3.507060</td>\n",
       "      <td>0.051085</td>\n",
       "      <td>0.041107</td>\n",
       "      <td>3.520018</td>\n",
       "      <td>-0.129093</td>\n",
       "      <td>0.140596</td>\n",
       "      <td>3.682804</td>\n",
       "      <td>-0.095307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125316</td>\n",
       "      <td>-0.082284</td>\n",
       "      <td>3.994426</td>\n",
       "      <td>-0.091925</td>\n",
       "      <td>-0.150032</td>\n",
       "      <td>3.786463</td>\n",
       "      <td>-0.059436</td>\n",
       "      <td>-0.470481</td>\n",
       "      <td>3.933452</td>\n",
       "      <td>-0.015971</td>\n",
       "      <td>-0.536822</td>\n",
       "      <td>3.898054</td>\n",
       "      <td>0.232809</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>3.950686</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>-0.151474</td>\n",
       "      <td>3.729795</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>-0.455693</td>\n",
       "      <td>3.827238</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>-0.522025</td>\n",
       "      <td>3.745156</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.309071</td>\n",
       "      <td>3.770465</td>\n",
       "      <td>-0.037153</td>\n",
       "      <td>-0.219317</td>\n",
       "      <td>3.875848</td>\n",
       "      <td>-0.066586</td>\n",
       "      <td>-0.194186</td>\n",
       "      <td>3.880914</td>\n",
       "      <td>0.103227</td>\n",
       "      <td>-0.183070</td>\n",
       "      <td>3.717531</td>\n",
       "      <td>0.180819</td>\n",
       "      <td>-0.130425</td>\n",
       "      <td>3.724300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224113</td>\n",
       "      <td>-0.031984</td>\n",
       "      <td>4.022326</td>\n",
       "      <td>0.217001</td>\n",
       "      <td>0.177784</td>\n",
       "      <td>3.932267</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>0.384047</td>\n",
       "      <td>3.831980</td>\n",
       "      <td>0.188331</td>\n",
       "      <td>0.497932</td>\n",
       "      <td>3.802332</td>\n",
       "      <td>0.093215</td>\n",
       "      <td>0.312804</td>\n",
       "      <td>3.919903</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.095412</td>\n",
       "      <td>3.990293</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>-0.041901</td>\n",
       "      <td>3.864388</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>-0.063312</td>\n",
       "      <td>3.832369</td>\n",
       "      <td>0.303312</td>\n",
       "      <td>0.284615</td>\n",
       "      <td>3.789172</td>\n",
       "      <td>0.313195</td>\n",
       "      <td>0.091174</td>\n",
       "      <td>3.804576</td>\n",
       "      <td>0.198835</td>\n",
       "      <td>-0.115773</td>\n",
       "      <td>3.724540</td>\n",
       "      <td>0.148842</td>\n",
       "      <td>-0.153402</td>\n",
       "      <td>3.706457</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>-0.025939</td>\n",
       "      <td>4.018429</td>\n",
       "      <td>-0.069625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015752</td>\n",
       "      <td>0.186064</td>\n",
       "      <td>3.735717</td>\n",
       "      <td>-0.026741</td>\n",
       "      <td>-0.171879</td>\n",
       "      <td>3.820120</td>\n",
       "      <td>0.039023</td>\n",
       "      <td>-0.410326</td>\n",
       "      <td>3.954949</td>\n",
       "      <td>0.040712</td>\n",
       "      <td>-0.513942</td>\n",
       "      <td>3.894690</td>\n",
       "      <td>0.070837</td>\n",
       "      <td>0.168282</td>\n",
       "      <td>3.702682</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>-0.200432</td>\n",
       "      <td>3.748308</td>\n",
       "      <td>0.089038</td>\n",
       "      <td>-0.472481</td>\n",
       "      <td>3.867306</td>\n",
       "      <td>0.058827</td>\n",
       "      <td>-0.566387</td>\n",
       "      <td>3.851228</td>\n",
       "      <td>-0.012763</td>\n",
       "      <td>0.536085</td>\n",
       "      <td>3.509441</td>\n",
       "      <td>-0.095632</td>\n",
       "      <td>0.056224</td>\n",
       "      <td>3.739927</td>\n",
       "      <td>-0.114635</td>\n",
       "      <td>0.082521</td>\n",
       "      <td>3.725400</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>-0.081738</td>\n",
       "      <td>3.656859</td>\n",
       "      <td>0.067479</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>3.618084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.035358</td>\n",
       "      <td>0.192430</td>\n",
       "      <td>3.681518</td>\n",
       "      <td>-0.021036</td>\n",
       "      <td>0.422171</td>\n",
       "      <td>3.606487</td>\n",
       "      <td>-0.007186</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>3.520689</td>\n",
       "      <td>-0.042399</td>\n",
       "      <td>0.769087</td>\n",
       "      <td>3.496161</td>\n",
       "      <td>-0.135204</td>\n",
       "      <td>0.577477</td>\n",
       "      <td>3.618551</td>\n",
       "      <td>-0.133122</td>\n",
       "      <td>0.358243</td>\n",
       "      <td>3.487167</td>\n",
       "      <td>-0.120882</td>\n",
       "      <td>0.534694</td>\n",
       "      <td>3.514019</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>0.588087</td>\n",
       "      <td>3.538668</td>\n",
       "      <td>0.089661</td>\n",
       "      <td>0.531060</td>\n",
       "      <td>3.476222</td>\n",
       "      <td>0.165636</td>\n",
       "      <td>0.352696</td>\n",
       "      <td>3.504042</td>\n",
       "      <td>-0.065932</td>\n",
       "      <td>0.337171</td>\n",
       "      <td>3.454219</td>\n",
       "      <td>-0.127669</td>\n",
       "      <td>0.346036</td>\n",
       "      <td>3.451911</td>\n",
       "      <td>-0.075961</td>\n",
       "      <td>0.195749</td>\n",
       "      <td>3.667959</td>\n",
       "      <td>-0.064483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065839</td>\n",
       "      <td>0.197170</td>\n",
       "      <td>3.664950</td>\n",
       "      <td>-0.058025</td>\n",
       "      <td>-0.141329</td>\n",
       "      <td>3.785261</td>\n",
       "      <td>-0.033219</td>\n",
       "      <td>-0.421956</td>\n",
       "      <td>3.935089</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>-0.476134</td>\n",
       "      <td>3.845834</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.183455</td>\n",
       "      <td>3.615751</td>\n",
       "      <td>0.072281</td>\n",
       "      <td>-0.152907</td>\n",
       "      <td>3.702846</td>\n",
       "      <td>0.074534</td>\n",
       "      <td>-0.468743</td>\n",
       "      <td>3.884177</td>\n",
       "      <td>0.027604</td>\n",
       "      <td>-0.522516</td>\n",
       "      <td>3.794972</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.593457</td>\n",
       "      <td>3.544754</td>\n",
       "      <td>-0.267565</td>\n",
       "      <td>0.550163</td>\n",
       "      <td>3.435139</td>\n",
       "      <td>-0.247820</td>\n",
       "      <td>0.496548</td>\n",
       "      <td>3.406900</td>\n",
       "      <td>-0.056666</td>\n",
       "      <td>0.495373</td>\n",
       "      <td>3.269386</td>\n",
       "      <td>-0.050549</td>\n",
       "      <td>0.490788</td>\n",
       "      <td>3.258667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205810</td>\n",
       "      <td>0.192052</td>\n",
       "      <td>3.810989</td>\n",
       "      <td>0.213430</td>\n",
       "      <td>0.442297</td>\n",
       "      <td>3.726759</td>\n",
       "      <td>0.221343</td>\n",
       "      <td>0.687635</td>\n",
       "      <td>3.632531</td>\n",
       "      <td>0.190760</td>\n",
       "      <td>0.800906</td>\n",
       "      <td>3.606914</td>\n",
       "      <td>0.091805</td>\n",
       "      <td>0.614839</td>\n",
       "      <td>3.709685</td>\n",
       "      <td>0.070733</td>\n",
       "      <td>0.485538</td>\n",
       "      <td>3.835492</td>\n",
       "      <td>0.075981</td>\n",
       "      <td>0.413761</td>\n",
       "      <td>3.604359</td>\n",
       "      <td>0.084202</td>\n",
       "      <td>0.368417</td>\n",
       "      <td>3.539332</td>\n",
       "      <td>0.328296</td>\n",
       "      <td>0.590779</td>\n",
       "      <td>3.601562</td>\n",
       "      <td>0.397093</td>\n",
       "      <td>0.398531</td>\n",
       "      <td>3.637018</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>0.369753</td>\n",
       "      <td>3.554382</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>0.365475</td>\n",
       "      <td>3.549501</td>\n",
       "      <td>0.150665</td>\n",
       "      <td>0.193746</td>\n",
       "      <td>3.799509</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156123</td>\n",
       "      <td>0.208811</td>\n",
       "      <td>3.815786</td>\n",
       "      <td>0.189649</td>\n",
       "      <td>-0.108433</td>\n",
       "      <td>3.940452</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>-0.415661</td>\n",
       "      <td>4.092692</td>\n",
       "      <td>0.244529</td>\n",
       "      <td>-0.481803</td>\n",
       "      <td>4.059097</td>\n",
       "      <td>0.259376</td>\n",
       "      <td>0.201769</td>\n",
       "      <td>3.777712</td>\n",
       "      <td>0.302917</td>\n",
       "      <td>-0.115797</td>\n",
       "      <td>3.862270</td>\n",
       "      <td>0.321422</td>\n",
       "      <td>-0.423885</td>\n",
       "      <td>4.006565</td>\n",
       "      <td>0.284749</td>\n",
       "      <td>-0.474948</td>\n",
       "      <td>4.029401</td>\n",
       "      <td>0.225790</td>\n",
       "      <td>0.625955</td>\n",
       "      <td>3.697713</td>\n",
       "      <td>0.231251</td>\n",
       "      <td>0.453419</td>\n",
       "      <td>3.475247</td>\n",
       "      <td>0.218939</td>\n",
       "      <td>0.449263</td>\n",
       "      <td>3.478400</td>\n",
       "      <td>-0.009107</td>\n",
       "      <td>0.534840</td>\n",
       "      <td>3.517180</td>\n",
       "      <td>0.053082</td>\n",
       "      <td>0.530157</td>\n",
       "      <td>3.493546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233268</td>\n",
       "      <td>0.182226</td>\n",
       "      <td>3.738342</td>\n",
       "      <td>0.246664</td>\n",
       "      <td>0.427726</td>\n",
       "      <td>3.664138</td>\n",
       "      <td>0.258953</td>\n",
       "      <td>0.668395</td>\n",
       "      <td>3.579175</td>\n",
       "      <td>0.232204</td>\n",
       "      <td>0.781505</td>\n",
       "      <td>3.551870</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.601550</td>\n",
       "      <td>3.670279</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>0.509896</td>\n",
       "      <td>3.821514</td>\n",
       "      <td>0.162564</td>\n",
       "      <td>0.409676</td>\n",
       "      <td>3.584376</td>\n",
       "      <td>0.068962</td>\n",
       "      <td>0.411862</td>\n",
       "      <td>3.408963</td>\n",
       "      <td>0.374092</td>\n",
       "      <td>0.579483</td>\n",
       "      <td>3.550387</td>\n",
       "      <td>0.418521</td>\n",
       "      <td>0.377121</td>\n",
       "      <td>3.579854</td>\n",
       "      <td>0.245717</td>\n",
       "      <td>0.343384</td>\n",
       "      <td>3.455242</td>\n",
       "      <td>0.197204</td>\n",
       "      <td>0.363410</td>\n",
       "      <td>3.468647</td>\n",
       "      <td>0.175561</td>\n",
       "      <td>0.183498</td>\n",
       "      <td>3.725377</td>\n",
       "      <td>0.198265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168774</td>\n",
       "      <td>0.190261</td>\n",
       "      <td>3.724671</td>\n",
       "      <td>0.196067</td>\n",
       "      <td>-0.134319</td>\n",
       "      <td>3.857288</td>\n",
       "      <td>0.246618</td>\n",
       "      <td>-0.421726</td>\n",
       "      <td>4.010206</td>\n",
       "      <td>0.213246</td>\n",
       "      <td>-0.470665</td>\n",
       "      <td>3.924187</td>\n",
       "      <td>0.275668</td>\n",
       "      <td>0.183728</td>\n",
       "      <td>3.684674</td>\n",
       "      <td>0.316404</td>\n",
       "      <td>-0.131877</td>\n",
       "      <td>3.781667</td>\n",
       "      <td>0.316957</td>\n",
       "      <td>-0.438056</td>\n",
       "      <td>3.959861</td>\n",
       "      <td>0.283030</td>\n",
       "      <td>-0.486836</td>\n",
       "      <td>3.873899</td>\n",
       "      <td>0.226930</td>\n",
       "      <td>0.592966</td>\n",
       "      <td>3.605333</td>\n",
       "      <td>0.362158</td>\n",
       "      <td>0.365421</td>\n",
       "      <td>3.476291</td>\n",
       "      <td>0.341380</td>\n",
       "      <td>0.398297</td>\n",
       "      <td>3.464900</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>0.484182</td>\n",
       "      <td>3.377581</td>\n",
       "      <td>0.137638</td>\n",
       "      <td>0.470977</td>\n",
       "      <td>3.347150</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3  ...      3372      3373      3374  labels\n",
       "0 -0.080141  0.135073  3.691227 -0.058513  ...  0.180819 -0.130425  3.724300       0\n",
       "1  0.224113 -0.031984  4.022326  0.217001  ...  0.067479 -0.000107  3.618084       1\n",
       "2 -0.035358  0.192430  3.681518 -0.021036  ... -0.050549  0.490788  3.258667       2\n",
       "3  0.205810  0.192052  3.810989  0.213430  ...  0.053082  0.530157  3.493546       3\n",
       "4  0.233268  0.182226  3.738342  0.246664  ...  0.137638  0.470977  3.347150       4\n",
       "\n",
       "[5 rows x 3376 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skeletons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzz7WGsRqGSv"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGsJUqPDqGS4"
   },
   "outputs": [],
   "source": [
    "class Skeleton_Dataset(Dataset):\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.transform = transform\n",
    "        self.normalize = self.normalize(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n",
    "        label = self.data.iloc[idx,-1]\n",
    "        \n",
    "        if self.transform != None:\n",
    "            item = self.transform(item)\n",
    "\n",
    "        return (item, label)\n",
    "\n",
    "\n",
    "    def normalize(self, data):\n",
    "        '''Приводит данные к отрезку от 0 до 1'''\n",
    "        X = data.values\n",
    "        result = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "        return result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sfhXx_IqGS6"
   },
   "outputs": [],
   "source": [
    "dataset = Skeleton_Dataset(file_path = \"/content/drive/My Drive/PyTorch/test_01.csv\", transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AlTu3t3v6fr"
   },
   "outputs": [],
   "source": [
    "skel, lab = dataset.__getitem__(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 4712,
     "status": "ok",
     "timestamp": 1602574842592,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "WJ_Pbx1s-W75",
    "outputId": "05cad9fd-ced7-4342-ab6f-eb2dd923d5e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38029  , 0.2208916, 3.816976 , ..., 0.4855051, 0.5063214,\n",
       "        3.4082   ],\n",
       "       [0.3802876, 0.2208559, 3.816864 , ..., 0.368538 , 0.4338186,\n",
       "        3.4935   ],\n",
       "       [0.3805799, 0.2214972, 3.816803 , ..., 0.3224915, 0.4371471,\n",
       "        3.545334 ],\n",
       "       ...,\n",
       "       [0.3770275, 0.2149056, 3.804242 , ..., 0.5289171, 0.4943787,\n",
       "        3.460667 ],\n",
       "       [0.3756532, 0.2142559, 3.804005 , ..., 0.5425205, 0.5035607,\n",
       "        3.43775  ],\n",
       "       [0.3766641, 0.2112738, 3.805015 , ..., 0.4998489, 0.5147105,\n",
       "        3.41775  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmJ92b7Q2YR1"
   },
   "source": [
    "Данные не нормализованы.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "648ErXSfqGTL"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.6*len(dataset)+1),int(0.4*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 6974,
     "status": "ok",
     "timestamp": 1602574844865,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "Y1A6V5UVqGTN",
    "outputId": "93007c7b-8229-4cf9-d585-7d010703aa5c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_net(\n",
       "  (lstm): LSTM(75, 256, num_layers=3, batch_first=True)\n",
       "  (dr): Dropout2d(p=0.25, inplace=False)\n",
       "  (fc): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 256\n",
    "n_joints = 25*3\n",
    "n_categories = len(LABELS)\n",
    "n_layer = 3\n",
    "rnn = LSTM_net(n_joints,n_hidden,n_categories,n_layer)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lc_m_7S1qGTP"
   },
   "outputs": [],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return LABELS[category_i], category_i\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "executionInfo": {
     "elapsed": 181024,
     "status": "ok",
     "timestamp": 1602575248343,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "jpZDoxj3qGTo",
    "outputId": "f545aee0-6be1-4b16-9956-5bd7ac3ddcaa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 iter : 0 (0m 0s) 0.1565  / take off a hat/cap ✓\n",
      "epoch : 1 iter : 3 (0m 3s) 0.6247  / hand waving ✓\n",
      "epoch : 2 iter : 6 (0m 6s) 0.4090  / jump up ✓\n",
      "epoch : 3 iter : 9 (0m 9s) 0.3195  / jump up ✓\n",
      "epoch : 4 iter : 12 (0m 12s) 0.4618  / cheer up ✓\n",
      "epoch : 5 iter : 15 (0m 16s) 0.1083  / take off a hat/cap ✓\n",
      "epoch : 6 iter : 18 (0m 19s) 0.2507  / standing up ✓\n",
      "epoch : 7 iter : 21 (0m 22s) 0.3777  / reading ✓\n",
      "epoch : 8 iter : 24 (0m 25s) 0.5094  / writing ✗, the answer is (reading)\n",
      "epoch : 9 iter : 27 (0m 28s) 0.1486  / take off a hat/cap ✓\n",
      "epoch : 10 iter : 30 (0m 31s) 0.2682  / reading ✓\n",
      "epoch : 11 iter : 33 (0m 35s) 0.1825  / take off a hat/cap ✓\n",
      "epoch : 12 iter : 36 (0m 38s) 0.2106  / hand waving ✓\n",
      "epoch : 13 iter : 39 (0m 41s) 0.1197  / sitting down ✓\n",
      "epoch : 14 iter : 42 (0m 44s) 0.2721  / take off a hat/cap ✗, the answer is (hand waving)\n",
      "epoch : 15 iter : 45 (0m 47s) 0.2032  / jump up ✓\n",
      "epoch : 17 iter : 1 (0m 51s) 0.2100  / standing up ✓\n",
      "epoch : 18 iter : 4 (0m 54s) 0.2761  / jump up ✓\n",
      "epoch : 19 iter : 7 (0m 57s) 0.3614  / cheer up ✓\n",
      "epoch : 20 iter : 10 (1m 0s) 0.6583  / writing ✗, the answer is (sitting down)\n",
      "epoch : 21 iter : 13 (1m 3s) 0.5692  / take off a hat/cap ✓\n",
      "epoch : 22 iter : 16 (1m 7s) 0.3380  / hand waving ✓\n",
      "epoch : 23 iter : 19 (1m 10s) 0.3568  / sitting down ✗, the answer is (standing up)\n",
      "epoch : 24 iter : 22 (1m 13s) 0.1587  / clapping ✓\n",
      "epoch : 25 iter : 25 (1m 16s) 0.1445  / clapping ✓\n",
      "epoch : 26 iter : 28 (1m 19s) 1.2951  / take off a hat/cap ✗, the answer is (hand waving)\n",
      "epoch : 27 iter : 31 (1m 22s) 0.1738  / clapping ✓\n",
      "epoch : 28 iter : 34 (1m 26s) 0.2013  / clapping ✓\n",
      "epoch : 29 iter : 37 (1m 29s) 0.1233  / cheer up ✓\n",
      "epoch : 30 iter : 40 (1m 32s) 0.1063  / reading ✓\n",
      "epoch : 31 iter : 43 (1m 35s) 0.0936  / sitting down ✓\n",
      "epoch : 32 iter : 46 (1m 38s) 0.2101  / take off a hat/cap ✓\n",
      "epoch : 34 iter : 2 (1m 42s) 0.3175  / cheer up ✓\n",
      "epoch : 35 iter : 5 (1m 45s) 0.1067  / cheer up ✓\n",
      "epoch : 36 iter : 8 (1m 48s) 0.1709  / sitting down ✓\n",
      "epoch : 37 iter : 11 (1m 51s) 0.1161  / writing ✗, the answer is (reading)\n",
      "epoch : 38 iter : 14 (1m 55s) 0.0833  / sitting down ✓\n",
      "epoch : 39 iter : 17 (1m 58s) 0.6001  / take off a hat/cap ✓\n",
      "epoch : 40 iter : 20 (2m 1s) 0.5674  / hand waving ✓\n",
      "epoch : 41 iter : 23 (2m 4s) 0.1245  / jump up ✓\n",
      "epoch : 42 iter : 26 (2m 7s) 0.2220  / clapping ✓\n",
      "epoch : 43 iter : 29 (2m 10s) 0.1401  / take off a hat/cap ✓\n",
      "epoch : 44 iter : 32 (2m 14s) 0.0986  / jump up ✓\n",
      "epoch : 45 iter : 35 (2m 17s) 0.2871  / take off a hat/cap ✓\n",
      "epoch : 46 iter : 38 (2m 20s) 0.6769  / jump up ✓\n",
      "epoch : 47 iter : 41 (2m 23s) 0.1015  / jump up ✓\n",
      "epoch : 48 iter : 44 (2m 26s) 0.1285  / sitting down ✓\n",
      "epoch : 50 iter : 0 (2m 30s) 0.2303  / hand waving ✓\n",
      "epoch : 51 iter : 3 (2m 33s) 0.1242  / take off a hat/cap ✓\n",
      "epoch : 52 iter : 6 (2m 36s) 0.0893  / sitting down ✓\n",
      "epoch : 53 iter : 9 (2m 39s) 0.1673  / standing up ✓\n",
      "epoch : 54 iter : 12 (2m 42s) 0.1298  / jump up ✓\n",
      "epoch : 55 iter : 15 (2m 45s) 0.4527  / writing ✗, the answer is (reading)\n",
      "epoch : 56 iter : 18 (2m 49s) 0.4159  / take off a hat/cap ✓\n",
      "epoch : 57 iter : 21 (2m 52s) 0.2484  / reading ✗, the answer is (writing)\n",
      "epoch : 58 iter : 24 (2m 55s) 0.1468  / take off a hat/cap ✓\n",
      "epoch : 59 iter : 27 (2m 58s) 0.6082  / cheer up ✓\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "import time\n",
    "import math\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(rnn.parameters(),lr=learning_rate)\n",
    "\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "counter = 0\n",
    "for epoch in range(60):  \n",
    "    current_loss = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output = rnn(inputs.float())\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        category = LABELS[int(labels[0])]\n",
    "\n",
    "        if counter % 50 == 0:\n",
    "            guess, guess_i = categoryFromOutput(output)\n",
    "            correct = '✓' if guess == category else '✗, the answer is (%s)' % category\n",
    "            #####сделать более аккуратный вывод для каждой эпохии\n",
    "            ######сделать обновление графика loss по ходу обучению  \n",
    "            print('epoch : %d iter : %d (%s) %.4f  / %s %s' % (epoch, i, timeSince(start), loss, guess, correct))\n",
    "\n",
    "        \n",
    "        counter = counter + 1\n",
    "    if counter % 50 == 0:\n",
    "        all_losses.append(current_loss / 25)\n",
    "        current_loss = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 172063,
     "status": "ok",
     "timestamp": 1602575248348,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "noqeO9twqGTr",
    "outputId": "83cbfcd8-9830-4b07-fb54-67182a3369cb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(list(range(0,len(all_losses))),all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 172698,
     "status": "ok",
     "timestamp": 1602575249933,
     "user": {
      "displayName": "Анна Таганова",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjHgwdi0Iz540PXk1fqwmdIxdmUpLD937HqUGKFpQ=s64",
      "userId": "08800327143472939263"
     },
     "user_tz": -180
    },
    "id": "YE3_VGjlqGTt",
    "outputId": "92ee1f06-442a-4dd5-d398-835cc11232c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network:   83.87096774193549\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "right = 0\n",
    "counter = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        counter = counter + 1\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)   \n",
    "        output = rnn(inputs.float())\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        category = LABELS[int(labels[0])]\n",
    "        \n",
    "        if guess == category:\n",
    "            right = right + 1\n",
    "\n",
    "\n",
    "print('Accuracy of the network:  ',  (100 * right / counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzFjF5xEwbDD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pytorch_lstm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
