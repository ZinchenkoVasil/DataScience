{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считывание данных и вывод основной информации о наборе данных.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path: str\n",
    "        Название файла.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: pandas.core.frame.DataFrame\n",
    "        Загруженный набор данных в pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    base_path = \"geekbrains-competitive-data-analysis\"\n",
    "    data = pd.read_csv(f\"{base_path}/{data_path}\")\n",
    "    data.columns = [col.lower() for col in data.columns]\n",
    "    print(f\"{data_path}: shape = {data.shape[0]} rows, {data.shape[1]} cols\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def catboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train, categorical,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds\n",
    "\n",
    "\n",
    "def catboost_hold_out_validation(params, X, y, split_params = [0.7, 0.2, 0.1], categorical = None):\n",
    "    \"\"\"\n",
    "    Hold-Out валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    split_params: List[float], optional, default = [0.7, 0.2, 0.1]\n",
    "        Параметры (доли) разбиения выборки.\n",
    "        Опциональный параметр, по умолчанию, равен [0.7, 0.2, 0.1].\n",
    "    \n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimator: catboost.core.CatBoostClassifier\n",
    "        Обученный классификатор catboost.\n",
    "\n",
    "    test_prediction: np.array, optional\n",
    "        Вектор прогнозов для тестовой выборки.\n",
    "        Опциональный объект, возвращается только, если split_params\n",
    "        содержит 3 значения.\n",
    "\n",
    "    \"\"\"\n",
    "    numeric = list(set(x_train.columns) - set(categorical))\n",
    "    x_train, x_valid = train_test_split(\n",
    "        X, train_size=split_params[0], random_state=27\n",
    "    )\n",
    "    y_train, y_valid = train_test_split(\n",
    "        y, train_size=split_params[0], random_state=27\n",
    "    )\n",
    "\n",
    "    if len(split_params) == 3:\n",
    "        test_size = int(split_params[2] * X.shape[0])\n",
    "\n",
    "        x_valid, x_test = train_test_split(\n",
    "            x_valid, test_size=test_size, random_state=72\n",
    "        )\n",
    "        y_valid, y_test = train_test_split(\n",
    "            y_valid, test_size=test_size, random_state=72\n",
    "        )\n",
    "\n",
    "    model = cb.CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        x_train, y_train, categorical,\n",
    "        eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "    )\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    valid_score = roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])\n",
    "    print(f\"Valid Score = {round(valid_score, 4)}\")\n",
    "\n",
    "    if len(split_params) == 3:\n",
    "\n",
    "        test_prediction = model.predict_proba(x_test)[:, 1]\n",
    "        test_score = roc_auc_score(y_test, test_prediction)\n",
    "        print(f\"Test Score = {round(test_score, 4)}\")\n",
    "\n",
    "        return estimator, test_prediction\n",
    "\n",
    "    else:\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_profile_features(X: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создание признаков на основе профиля клиентов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков с исходным профилем клиента.\n",
    "\n",
    "    copy: bool, optional, default = True\n",
    "        Флаг использования копии датафрейма X.\n",
    "        Опциональный параметр, по умолчанию, равен True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed: pandas.core.frame.DataFrame\n",
    "        Расширенная матрица признаков с профилем клиентов.\n",
    "\n",
    "    \"\"\"\n",
    "    if copy:\n",
    "        X = X.copy()\n",
    "\n",
    "    X[\"days_on_last_job\"] = X[\"days_on_last_job\"].replace(365243, np.nan)\n",
    "    bki_flags = [flag for flag in X.columns if \"amt_req_credit_bureau\" in flag]\n",
    "    X[\"bki_requests_count\"] = X[bki_flags].sum(axis=1)\n",
    "    X[\"bki_kurtosis\"] = X[bki_flags].kurtosis(axis=1)\n",
    "\n",
    "    X[\"external_scoring_prod\"] = X[\"external_scoring_rating_1\"] * X[\"external_scoring_rating_2\"] * X[\"external_scoring_rating_3\"]\n",
    "    X[\"external_scoring_weighted\"] = X.external_scoring_rating_1 * 2 + X.external_scoring_rating_2 * 1 + X.external_scoring_rating_3 * 3\n",
    "\n",
    "    for function_name in [\"min\", \"max\", \"mean\", \"nanmedian\", \"var\"]:\n",
    "        feature_name = \"external_scoring_rating_{}\".format(function_name)\n",
    "        X[feature_name] = eval(\"np.{}\".format(function_name))(\n",
    "            X[[\"external_scoring_rating_1\", \"external_scoring_rating_2\", \"external_scoring_rating_3\"]], axis=1\n",
    "        )\n",
    "\n",
    "    # Отношение между основными фин. показателями\n",
    "    X['ratio_credit_to_annuity'] = X['amount_credit'] / X['amount_annuity']\n",
    "    X[\"ratio_annuity_to_salary\"] = X['amount_annuity'] / X['total_salary']\n",
    "    X['ratio_credit_to_salary'] = X['amount_credit'] / X['total_salary']\n",
    "    #X[\"total_salary_net\"] = X[\"total_salary\"] - X[\"amount_annuity\"]\n",
    "\n",
    "    # Отношение фин. показателей к возрасту и временным фичам\n",
    "    X[\"ratio_annuity_to_age\"] = X[\"amount_annuity\"] / X[\"age\"]\n",
    "    X[\"ratio_credit_to_age\"] = X[\"amount_credit\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_age\"] = X[\"total_salary\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_experience\"] = X[\"total_salary\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_credit_to_experience\"] = X[\"amount_credit\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_annuity_to_experience\"] = X[\"amount_annuity\"] / X[\"days_on_last_job\"]\n",
    "\n",
    "    # Отношение врменных признаков\n",
    "    X[\"ratio_age_to_experience\"] = X[\"age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_salary_to_region_population\"] = X[\"total_salary\"] * X[\"region_population\"]\n",
    "    X[\"ratio_car_to_experience\"] = X[\"own_car_age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_car_to_age\"] = X[\"own_car_age\"] / X[\"age\"]\n",
    "\n",
    "    # Произведение фин. показателей кредита на вероятность дефолта\n",
    "    # Такая штука называется математическим ожиданием дефолта или ожидаемыми потерями\n",
    "    X[\"expected_total_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_monthly_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_annuity\"]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "#    X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        #-----\n",
    "        dtrain = xgb.DMatrix(x_train, y_train)\n",
    "        dvalid = xgb.DMatrix(x_valid, y_valid)\n",
    "\n",
    "        model = xgb.train(\n",
    "          params=params,\n",
    "          dtrain=dtrain,\n",
    "          evals=[(dtrain, \"dtrain\"), (dvalid, \"dvalid\")],\n",
    "          early_stopping_rounds=25,\n",
    "          num_boost_round=1000,\n",
    "          verbose_eval=10,\n",
    "          maximize=True,\n",
    "        )\n",
    "        #____\n",
    "        \n",
    "        oof_preds[valid_idx] = model.predict(dvalid)\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv: shape = 110093 rows, 3 cols\n",
      "test.csv: shape = 165141 rows, 2 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>target</th>\n",
       "      <th>name_contract_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number  target name_contract_type\n",
       "0           123687442     0.0               Cash\n",
       "1           123597908     1.0               Cash"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_input(\"train.csv\")\n",
    "test = get_input(\"test.csv\")\n",
    "\n",
    "data = pd.concat([train, test], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## client_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_profile.csv: shape = 250000 rows, 24 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>gender</th>\n",
       "      <th>childrens</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>amount_credit</th>\n",
       "      <th>amount_annuity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>family_status</th>\n",
       "      <th>region_population</th>\n",
       "      <th>age</th>\n",
       "      <th>days_on_last_job</th>\n",
       "      <th>own_car_age</th>\n",
       "      <th>flag_phone</th>\n",
       "      <th>flag_email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_credit_to_age</th>\n",
       "      <th>ratio_salary_to_age</th>\n",
       "      <th>ratio_salary_to_experience</th>\n",
       "      <th>ratio_credit_to_experience</th>\n",
       "      <th>ratio_annuity_to_experience</th>\n",
       "      <th>ratio_age_to_experience</th>\n",
       "      <th>ratio_salary_to_region_population</th>\n",
       "      <th>ratio_car_to_experience</th>\n",
       "      <th>ratio_car_to_age</th>\n",
       "      <th>expected_total_loss_1</th>\n",
       "      <th>expected_total_loss_2</th>\n",
       "      <th>expected_total_loss_3</th>\n",
       "      <th>expected_monthly_loss_1</th>\n",
       "      <th>expected_monthly_loss_2</th>\n",
       "      <th>expected_monthly_loss_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123666076</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>8560</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.542056</td>\n",
       "      <td>18.399533</td>\n",
       "      <td>101.678502</td>\n",
       "      <td>174.306004</td>\n",
       "      <td>8.7153</td>\n",
       "      <td>5.526146</td>\n",
       "      <td>1270.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88957.124333</td>\n",
       "      <td>63804.966560</td>\n",
       "      <td>183213.275945</td>\n",
       "      <td>4447.856217</td>\n",
       "      <td>3190.248328</td>\n",
       "      <td>9160.663797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123423688</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>536917.5</td>\n",
       "      <td>28467.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>23187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.155971</td>\n",
       "      <td>11.644456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5466.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237475.743779</td>\n",
       "      <td>431008.094056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12590.802122</td>\n",
       "      <td>22851.755462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number gender  childrens  total_salary  amount_credit  \\\n",
       "0           123666076      F          0      157500.0       270000.0   \n",
       "1           123423688      F          0      270000.0       536917.5   \n",
       "\n",
       "   amount_annuity                education_level   family_status  \\\n",
       "0         13500.0              Incomplete higher  Civil marriage   \n",
       "1         28467.0  Secondary / secondary special         Married   \n",
       "\n",
       "   region_population    age  days_on_last_job  own_car_age  flag_phone  \\\n",
       "0           0.008068   8560            1549.0          NaN           1   \n",
       "1           0.020246  23187               NaN          NaN           0   \n",
       "\n",
       "   flag_email  family_size  ...  ratio_credit_to_age  ratio_salary_to_age  \\\n",
       "0           0          2.0  ...            31.542056            18.399533   \n",
       "1           0          2.0  ...            23.155971            11.644456   \n",
       "\n",
       "   ratio_salary_to_experience  ratio_credit_to_experience  \\\n",
       "0                  101.678502                  174.306004   \n",
       "1                         NaN                         NaN   \n",
       "\n",
       "   ratio_annuity_to_experience  ratio_age_to_experience  \\\n",
       "0                       8.7153                 5.526146   \n",
       "1                          NaN                      NaN   \n",
       "\n",
       "   ratio_salary_to_region_population  ratio_car_to_experience  \\\n",
       "0                            1270.71                      NaN   \n",
       "1                            5466.42                      NaN   \n",
       "\n",
       "   ratio_car_to_age  expected_total_loss_1  expected_total_loss_2  \\\n",
       "0               NaN           88957.124333           63804.966560   \n",
       "1               NaN                    NaN          237475.743779   \n",
       "\n",
       "   expected_total_loss_3  expected_monthly_loss_1  expected_monthly_loss_2  \\\n",
       "0          183213.275945              4447.856217              3190.248328   \n",
       "1          431008.094056                      NaN             12590.802122   \n",
       "\n",
       "   expected_monthly_loss_3  \n",
       "0              9160.663797  \n",
       "1             22851.755462  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_profile = get_input(\"client_profile.csv\")\n",
    "client_profile = create_client_profile_features(client_profile)\n",
    "client_profile.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(\n",
    "    client_profile, how=\"left\", on=\"application_number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cash</th>\n",
       "      <th>Credit Card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cash  Credit Card\n",
       "0     1            0\n",
       "1     1            0\n",
       "2     1            0\n",
       "3     1            0\n",
       "4     1            0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"name_contract_type\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>XNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  M  XNA\n",
       "0  0  1    0\n",
       "1  0  0    0\n",
       "2  1  0    0\n",
       "3  0  1    0\n",
       "4  0  0    0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"gender\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Academic degree</th>\n",
       "      <th>Higher education</th>\n",
       "      <th>Incomplete higher</th>\n",
       "      <th>Lower secondary</th>\n",
       "      <th>Secondary / secondary special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Academic degree  Higher education  Incomplete higher  Lower secondary  \\\n",
       "0                0                 0                  0                0   \n",
       "1                0                 0                  0                0   \n",
       "2                0                 1                  0                0   \n",
       "3                0                 0                  0                0   \n",
       "4                0                 0                  0                0   \n",
       "\n",
       "   Secondary / secondary special  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              1  \n",
       "4                              0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"education_level\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civil marriage</th>\n",
       "      <th>Married</th>\n",
       "      <th>Separated</th>\n",
       "      <th>Single / not married</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Civil marriage  Married  Separated  Single / not married  Unknown  Widow\n",
       "0               0        1          0                     0        0      0\n",
       "1               0        0          0                     0        0      0\n",
       "2               0        1          0                     0        0      0\n",
       "3               0        1          0                     0        0      0\n",
       "4               0        0          0                     0        0      0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"family_status\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education_level</th>\n",
       "      <th>education_level_freq_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.710221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 education_level  education_level_freq_enc\n",
       "0  Secondary / secondary special                  0.710221\n",
       "1                            NaN                       NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_encoder = data[\"education_level\"].value_counts(normalize=True)\n",
    "data[\"education_level_freq_enc\"] = data[\"education_level\"].map(freq_encoder)\n",
    "data[[\"education_level\", \"education_level_freq_enc\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"target\"].isnull()\n",
    "features_to_drop = [\"application_number\", \"target\"]\n",
    "\n",
    "train, test = data.loc[~mask], data.loc[mask]\n",
    "\n",
    "target, test_id = train[\"target\"], test[\"application_number\"]\n",
    "train = train.drop(features_to_drop, axis=1)\n",
    "test = test.drop(features_to_drop, axis=1)\n",
    "\n",
    "categorial = train.dtypes[train.dtypes == \"object\"].index\n",
    "numerical = list(set(train.columns) - set(categorial))\n",
    "\n",
    "train = train.replace(np.inf, np.nan)\n",
    "train = train.replace(-np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 29 17:26:28 2020, Cross-Validation, 110093 rows, 49 cols\n",
      "[0]\tdtrain-auc:0.70634\tdvalid-auc:0.69116\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71487\tdvalid-auc:0.69530\n",
      "[20]\tdtrain-auc:0.72095\tdvalid-auc:0.69808\n",
      "[30]\tdtrain-auc:0.72582\tdvalid-auc:0.69770\n",
      "[40]\tdtrain-auc:0.72748\tdvalid-auc:0.69812\n",
      "[50]\tdtrain-auc:0.72936\tdvalid-auc:0.69905\n",
      "[60]\tdtrain-auc:0.73148\tdvalid-auc:0.69939\n",
      "[70]\tdtrain-auc:0.73330\tdvalid-auc:0.69959\n",
      "[80]\tdtrain-auc:0.73441\tdvalid-auc:0.69940\n",
      "[90]\tdtrain-auc:0.73531\tdvalid-auc:0.69947\n",
      "Stopping. Best iteration:\n",
      "[72]\tdtrain-auc:0.73350\tdvalid-auc:0.69971\n",
      "\n",
      "Fold 1, Valid score = 0.69904\n",
      "[0]\tdtrain-auc:0.70376\tdvalid-auc:0.69418\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71684\tdvalid-auc:0.70192\n",
      "[20]\tdtrain-auc:0.72142\tdvalid-auc:0.70385\n",
      "[30]\tdtrain-auc:0.72447\tdvalid-auc:0.70569\n",
      "[40]\tdtrain-auc:0.72620\tdvalid-auc:0.70627\n",
      "[50]\tdtrain-auc:0.72745\tdvalid-auc:0.70674\n",
      "[60]\tdtrain-auc:0.72872\tdvalid-auc:0.70626\n",
      "[70]\tdtrain-auc:0.72945\tdvalid-auc:0.70618\n",
      "Stopping. Best iteration:\n",
      "[51]\tdtrain-auc:0.72748\tdvalid-auc:0.70682\n",
      "\n",
      "Fold 2, Valid score = 0.70624\n",
      "[0]\tdtrain-auc:0.70522\tdvalid-auc:0.69583\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71662\tdvalid-auc:0.70356\n",
      "[20]\tdtrain-auc:0.71903\tdvalid-auc:0.70344\n",
      "[30]\tdtrain-auc:0.72176\tdvalid-auc:0.70469\n",
      "[40]\tdtrain-auc:0.72355\tdvalid-auc:0.70502\n",
      "[50]\tdtrain-auc:0.72553\tdvalid-auc:0.70590\n",
      "[60]\tdtrain-auc:0.72683\tdvalid-auc:0.70679\n",
      "[70]\tdtrain-auc:0.72851\tdvalid-auc:0.70693\n",
      "[80]\tdtrain-auc:0.73018\tdvalid-auc:0.70755\n",
      "[90]\tdtrain-auc:0.73156\tdvalid-auc:0.70781\n",
      "[100]\tdtrain-auc:0.73339\tdvalid-auc:0.70882\n",
      "[110]\tdtrain-auc:0.73479\tdvalid-auc:0.70893\n",
      "[120]\tdtrain-auc:0.73584\tdvalid-auc:0.70931\n",
      "[130]\tdtrain-auc:0.73695\tdvalid-auc:0.70993\n",
      "[140]\tdtrain-auc:0.73830\tdvalid-auc:0.71098\n",
      "[150]\tdtrain-auc:0.73921\tdvalid-auc:0.71087\n",
      "[160]\tdtrain-auc:0.74043\tdvalid-auc:0.71118\n",
      "[170]\tdtrain-auc:0.74218\tdvalid-auc:0.71242\n",
      "[180]\tdtrain-auc:0.74310\tdvalid-auc:0.71266\n",
      "[190]\tdtrain-auc:0.74385\tdvalid-auc:0.71349\n",
      "[200]\tdtrain-auc:0.74460\tdvalid-auc:0.71401\n",
      "[210]\tdtrain-auc:0.74570\tdvalid-auc:0.71472\n",
      "[220]\tdtrain-auc:0.74725\tdvalid-auc:0.71496\n",
      "[230]\tdtrain-auc:0.74840\tdvalid-auc:0.71557\n",
      "[240]\tdtrain-auc:0.74960\tdvalid-auc:0.71608\n",
      "[250]\tdtrain-auc:0.75092\tdvalid-auc:0.71749\n",
      "[260]\tdtrain-auc:0.75217\tdvalid-auc:0.71770\n",
      "[270]\tdtrain-auc:0.75372\tdvalid-auc:0.71840\n",
      "[280]\tdtrain-auc:0.75537\tdvalid-auc:0.71940\n",
      "[290]\tdtrain-auc:0.75704\tdvalid-auc:0.72018\n",
      "[300]\tdtrain-auc:0.75856\tdvalid-auc:0.72064\n",
      "[310]\tdtrain-auc:0.76033\tdvalid-auc:0.72138\n",
      "[320]\tdtrain-auc:0.76179\tdvalid-auc:0.72180\n",
      "[330]\tdtrain-auc:0.76315\tdvalid-auc:0.72200\n",
      "[340]\tdtrain-auc:0.76466\tdvalid-auc:0.72238\n",
      "[350]\tdtrain-auc:0.76571\tdvalid-auc:0.72239\n",
      "[360]\tdtrain-auc:0.76713\tdvalid-auc:0.72346\n",
      "[370]\tdtrain-auc:0.76811\tdvalid-auc:0.72382\n",
      "[380]\tdtrain-auc:0.76951\tdvalid-auc:0.72502\n",
      "[390]\tdtrain-auc:0.77079\tdvalid-auc:0.72524\n",
      "[400]\tdtrain-auc:0.77221\tdvalid-auc:0.72589\n",
      "[410]\tdtrain-auc:0.77363\tdvalid-auc:0.72604\n",
      "[420]\tdtrain-auc:0.77479\tdvalid-auc:0.72652\n",
      "[430]\tdtrain-auc:0.77599\tdvalid-auc:0.72661\n",
      "[440]\tdtrain-auc:0.77726\tdvalid-auc:0.72688\n",
      "[450]\tdtrain-auc:0.77875\tdvalid-auc:0.72745\n",
      "[460]\tdtrain-auc:0.78012\tdvalid-auc:0.72812\n",
      "[470]\tdtrain-auc:0.78137\tdvalid-auc:0.72839\n",
      "[480]\tdtrain-auc:0.78245\tdvalid-auc:0.72875\n",
      "[490]\tdtrain-auc:0.78357\tdvalid-auc:0.72906\n",
      "[500]\tdtrain-auc:0.78465\tdvalid-auc:0.72912\n",
      "[510]\tdtrain-auc:0.78586\tdvalid-auc:0.72955\n",
      "[520]\tdtrain-auc:0.78700\tdvalid-auc:0.72999\n",
      "[530]\tdtrain-auc:0.78838\tdvalid-auc:0.73017\n",
      "[540]\tdtrain-auc:0.78963\tdvalid-auc:0.73040\n",
      "[550]\tdtrain-auc:0.79068\tdvalid-auc:0.73059\n",
      "[560]\tdtrain-auc:0.79194\tdvalid-auc:0.73067\n",
      "[570]\tdtrain-auc:0.79301\tdvalid-auc:0.73069\n",
      "[580]\tdtrain-auc:0.79397\tdvalid-auc:0.73111\n",
      "[590]\tdtrain-auc:0.79474\tdvalid-auc:0.73134\n",
      "[600]\tdtrain-auc:0.79568\tdvalid-auc:0.73169\n",
      "[610]\tdtrain-auc:0.79648\tdvalid-auc:0.73180\n",
      "[620]\tdtrain-auc:0.79700\tdvalid-auc:0.73181\n",
      "[630]\tdtrain-auc:0.79749\tdvalid-auc:0.73182\n",
      "Stopping. Best iteration:\n",
      "[613]\tdtrain-auc:0.79660\tdvalid-auc:0.73198\n",
      "\n",
      "Fold 3, Valid score = 0.73181\n",
      "[0]\tdtrain-auc:0.70739\tdvalid-auc:0.68971\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71987\tdvalid-auc:0.69884\n",
      "[20]\tdtrain-auc:0.72270\tdvalid-auc:0.70011\n",
      "[30]\tdtrain-auc:0.72527\tdvalid-auc:0.70112\n",
      "[40]\tdtrain-auc:0.72698\tdvalid-auc:0.70111\n",
      "[50]\tdtrain-auc:0.72856\tdvalid-auc:0.70127\n",
      "[60]\tdtrain-auc:0.72954\tdvalid-auc:0.70174\n",
      "[70]\tdtrain-auc:0.73045\tdvalid-auc:0.70157\n",
      "[80]\tdtrain-auc:0.73159\tdvalid-auc:0.70225\n",
      "[90]\tdtrain-auc:0.73279\tdvalid-auc:0.70254\n",
      "[100]\tdtrain-auc:0.73386\tdvalid-auc:0.70277\n",
      "[110]\tdtrain-auc:0.73489\tdvalid-auc:0.70369\n",
      "[120]\tdtrain-auc:0.73712\tdvalid-auc:0.70378\n",
      "[130]\tdtrain-auc:0.73846\tdvalid-auc:0.70374\n",
      "[140]\tdtrain-auc:0.73963\tdvalid-auc:0.70432\n",
      "[150]\tdtrain-auc:0.74074\tdvalid-auc:0.70529\n",
      "[160]\tdtrain-auc:0.74242\tdvalid-auc:0.70616\n",
      "[170]\tdtrain-auc:0.74393\tdvalid-auc:0.70627\n",
      "[180]\tdtrain-auc:0.74495\tdvalid-auc:0.70618\n",
      "[190]\tdtrain-auc:0.74613\tdvalid-auc:0.70652\n",
      "[200]\tdtrain-auc:0.74738\tdvalid-auc:0.70661\n",
      "[210]\tdtrain-auc:0.74871\tdvalid-auc:0.70674\n",
      "[220]\tdtrain-auc:0.75013\tdvalid-auc:0.70691\n",
      "[230]\tdtrain-auc:0.75133\tdvalid-auc:0.70744\n",
      "[240]\tdtrain-auc:0.75245\tdvalid-auc:0.70769\n",
      "[250]\tdtrain-auc:0.75345\tdvalid-auc:0.70774\n",
      "[260]\tdtrain-auc:0.75460\tdvalid-auc:0.70826\n",
      "[270]\tdtrain-auc:0.75562\tdvalid-auc:0.70860\n",
      "[280]\tdtrain-auc:0.75648\tdvalid-auc:0.70852\n",
      "[290]\tdtrain-auc:0.75755\tdvalid-auc:0.70923\n",
      "[300]\tdtrain-auc:0.75888\tdvalid-auc:0.70959\n",
      "[310]\tdtrain-auc:0.76017\tdvalid-auc:0.70970\n",
      "[320]\tdtrain-auc:0.76158\tdvalid-auc:0.71013\n",
      "[330]\tdtrain-auc:0.76283\tdvalid-auc:0.71067\n",
      "[340]\tdtrain-auc:0.76402\tdvalid-auc:0.71128\n",
      "[350]\tdtrain-auc:0.76511\tdvalid-auc:0.71211\n",
      "[360]\tdtrain-auc:0.76650\tdvalid-auc:0.71267\n",
      "[370]\tdtrain-auc:0.76786\tdvalid-auc:0.71309\n",
      "[380]\tdtrain-auc:0.76935\tdvalid-auc:0.71383\n",
      "[390]\tdtrain-auc:0.77070\tdvalid-auc:0.71388\n",
      "[400]\tdtrain-auc:0.77203\tdvalid-auc:0.71435\n",
      "[410]\tdtrain-auc:0.77358\tdvalid-auc:0.71473\n",
      "[420]\tdtrain-auc:0.77498\tdvalid-auc:0.71513\n",
      "[430]\tdtrain-auc:0.77624\tdvalid-auc:0.71567\n",
      "[440]\tdtrain-auc:0.77757\tdvalid-auc:0.71596\n",
      "[450]\tdtrain-auc:0.77865\tdvalid-auc:0.71632\n",
      "[460]\tdtrain-auc:0.78017\tdvalid-auc:0.71610\n",
      "[470]\tdtrain-auc:0.78156\tdvalid-auc:0.71627\n",
      "Stopping. Best iteration:\n",
      "[452]\tdtrain-auc:0.77902\tdvalid-auc:0.71637\n",
      "\n",
      "Fold 4, Valid score = 0.71633\n",
      "[0]\tdtrain-auc:0.70822\tdvalid-auc:0.69359\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71760\tdvalid-auc:0.69676\n",
      "[20]\tdtrain-auc:0.72218\tdvalid-auc:0.69773\n",
      "[30]\tdtrain-auc:0.72440\tdvalid-auc:0.69748\n",
      "[40]\tdtrain-auc:0.72580\tdvalid-auc:0.69806\n",
      "[50]\tdtrain-auc:0.72715\tdvalid-auc:0.69763\n",
      "[60]\tdtrain-auc:0.72864\tdvalid-auc:0.69736\n",
      "Stopping. Best iteration:\n",
      "[42]\tdtrain-auc:0.72622\tdvalid-auc:0.69825\n",
      "\n",
      "Fold 5, Valid score = 0.69809\n",
      "Score by each fold: [0.69904, 0.70624, 0.73181, 0.71633, 0.69809]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import BayesianOptimization\n",
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1234123, shuffle=True)\n",
    "new_train = train[numerical]\n",
    "estimators, oof_preds_xgb = xgboost_cross_validation(\n",
    "    params=xgb_params, X=new_train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.621\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_xgb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "#test[categorial] = test[categorial].astype(str)\n",
    "\n",
    "new_test = test[numerical]\n",
    "dtest = xgb.DMatrix(new_test)\n",
    "\n",
    "for estimator in estimators:\n",
    "    y_pred_xgb += estimator.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = y_pred_xgb / cv.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#N_FOLDS = 10\n",
    "#folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random\n",
    "    estimators = []\n",
    "    oof = np.zeros(len(X))\n",
    "    sub = np.zeros(len(test))\n",
    "    scores = [0 for _ in range(cv.n_splits)]\n",
    "    for fold_, (train_idx, val_idx) in enumerate(cv.split(X.values, y)):\n",
    "        X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "        X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val)\n",
    "        watchlist = [train_data, val_data]\n",
    "        clf = lgb.train(params, train_set = train_data, valid_sets=watchlist)\n",
    "        oof[val_idx] = clf.predict(X_val)\n",
    "        sub += clf.predict(new_test)/cv.n_splits\n",
    "        scores[fold_] = roc_auc_score(y[val_idx], oof[val_idx])\n",
    "        print(\"Fold {}: {}\".format(fold_+1, round(scores[fold_],5)))\n",
    "        estimators.append(clf)\n",
    "    \n",
    "    print(\"CV score(auc): {:<8.5f}, (std: {:<8.5f})\".format(roc_auc_score(y, oof), np.std(scores)))\n",
    "\n",
    "    print(\"=\"*65)\n",
    "    return estimators,oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.692479\tvalid_1's auc: 0.6879\n",
      "[2]\ttraining's auc: 0.714254\tvalid_1's auc: 0.706002\n",
      "[3]\ttraining's auc: 0.718834\tvalid_1's auc: 0.708941\n",
      "[4]\ttraining's auc: 0.723428\tvalid_1's auc: 0.711598\n",
      "[5]\ttraining's auc: 0.72835\tvalid_1's auc: 0.710765\n",
      "[6]\ttraining's auc: 0.732065\tvalid_1's auc: 0.71654\n",
      "[7]\ttraining's auc: 0.735002\tvalid_1's auc: 0.718728\n",
      "[8]\ttraining's auc: 0.739276\tvalid_1's auc: 0.723347\n",
      "[9]\ttraining's auc: 0.744997\tvalid_1's auc: 0.728337\n",
      "[10]\ttraining's auc: 0.747713\tvalid_1's auc: 0.729121\n",
      "[11]\ttraining's auc: 0.750703\tvalid_1's auc: 0.729655\n",
      "[12]\ttraining's auc: 0.754628\tvalid_1's auc: 0.73164\n",
      "[13]\ttraining's auc: 0.756518\tvalid_1's auc: 0.731583\n",
      "[14]\ttraining's auc: 0.758716\tvalid_1's auc: 0.730815\n",
      "[15]\ttraining's auc: 0.76073\tvalid_1's auc: 0.730998\n",
      "[16]\ttraining's auc: 0.763353\tvalid_1's auc: 0.729062\n",
      "[17]\ttraining's auc: 0.766178\tvalid_1's auc: 0.729275\n",
      "[18]\ttraining's auc: 0.768081\tvalid_1's auc: 0.728359\n",
      "[19]\ttraining's auc: 0.770743\tvalid_1's auc: 0.728256\n",
      "[20]\ttraining's auc: 0.772931\tvalid_1's auc: 0.728858\n",
      "[21]\ttraining's auc: 0.774942\tvalid_1's auc: 0.728697\n",
      "[22]\ttraining's auc: 0.776008\tvalid_1's auc: 0.729654\n",
      "[23]\ttraining's auc: 0.778661\tvalid_1's auc: 0.730216\n",
      "[24]\ttraining's auc: 0.779391\tvalid_1's auc: 0.730857\n",
      "[25]\ttraining's auc: 0.782115\tvalid_1's auc: 0.729899\n",
      "[26]\ttraining's auc: 0.784063\tvalid_1's auc: 0.729232\n",
      "[27]\ttraining's auc: 0.785454\tvalid_1's auc: 0.728624\n",
      "[28]\ttraining's auc: 0.787213\tvalid_1's auc: 0.728193\n",
      "[29]\ttraining's auc: 0.78891\tvalid_1's auc: 0.72815\n",
      "[30]\ttraining's auc: 0.790922\tvalid_1's auc: 0.728681\n",
      "[31]\ttraining's auc: 0.792749\tvalid_1's auc: 0.728282\n",
      "[32]\ttraining's auc: 0.794922\tvalid_1's auc: 0.728862\n",
      "[33]\ttraining's auc: 0.796721\tvalid_1's auc: 0.728529\n",
      "[34]\ttraining's auc: 0.798056\tvalid_1's auc: 0.728389\n",
      "[35]\ttraining's auc: 0.79989\tvalid_1's auc: 0.728777\n",
      "[36]\ttraining's auc: 0.801471\tvalid_1's auc: 0.728043\n",
      "[37]\ttraining's auc: 0.802833\tvalid_1's auc: 0.728511\n",
      "[38]\ttraining's auc: 0.804182\tvalid_1's auc: 0.728455\n",
      "[39]\ttraining's auc: 0.806037\tvalid_1's auc: 0.728526\n",
      "[40]\ttraining's auc: 0.807987\tvalid_1's auc: 0.727792\n",
      "[41]\ttraining's auc: 0.80931\tvalid_1's auc: 0.728156\n",
      "[42]\ttraining's auc: 0.81075\tvalid_1's auc: 0.72887\n",
      "[43]\ttraining's auc: 0.812003\tvalid_1's auc: 0.729196\n",
      "[44]\ttraining's auc: 0.81352\tvalid_1's auc: 0.729985\n",
      "[45]\ttraining's auc: 0.814885\tvalid_1's auc: 0.72918\n",
      "[46]\ttraining's auc: 0.81583\tvalid_1's auc: 0.728465\n",
      "[47]\ttraining's auc: 0.817467\tvalid_1's auc: 0.728755\n",
      "[48]\ttraining's auc: 0.818775\tvalid_1's auc: 0.729176\n",
      "[49]\ttraining's auc: 0.820095\tvalid_1's auc: 0.72801\n",
      "[50]\ttraining's auc: 0.821408\tvalid_1's auc: 0.727384\n",
      "[51]\ttraining's auc: 0.822362\tvalid_1's auc: 0.727212\n",
      "[52]\ttraining's auc: 0.824371\tvalid_1's auc: 0.72676\n",
      "[53]\ttraining's auc: 0.825409\tvalid_1's auc: 0.726967\n",
      "[54]\ttraining's auc: 0.826355\tvalid_1's auc: 0.72712\n",
      "[55]\ttraining's auc: 0.82764\tvalid_1's auc: 0.727904\n",
      "[56]\ttraining's auc: 0.829079\tvalid_1's auc: 0.728229\n",
      "[57]\ttraining's auc: 0.830265\tvalid_1's auc: 0.727562\n",
      "[58]\ttraining's auc: 0.831208\tvalid_1's auc: 0.727511\n",
      "[59]\ttraining's auc: 0.83253\tvalid_1's auc: 0.726963\n",
      "[60]\ttraining's auc: 0.833438\tvalid_1's auc: 0.727737\n",
      "[61]\ttraining's auc: 0.834533\tvalid_1's auc: 0.728198\n",
      "[62]\ttraining's auc: 0.835401\tvalid_1's auc: 0.728319\n",
      "[63]\ttraining's auc: 0.836617\tvalid_1's auc: 0.728214\n",
      "[64]\ttraining's auc: 0.837622\tvalid_1's auc: 0.72839\n",
      "[65]\ttraining's auc: 0.838209\tvalid_1's auc: 0.728965\n",
      "[66]\ttraining's auc: 0.838873\tvalid_1's auc: 0.72875\n",
      "[67]\ttraining's auc: 0.840598\tvalid_1's auc: 0.728716\n",
      "[68]\ttraining's auc: 0.841968\tvalid_1's auc: 0.728771\n",
      "[69]\ttraining's auc: 0.843064\tvalid_1's auc: 0.728083\n",
      "[70]\ttraining's auc: 0.844048\tvalid_1's auc: 0.727207\n",
      "[71]\ttraining's auc: 0.845301\tvalid_1's auc: 0.726505\n",
      "[72]\ttraining's auc: 0.846178\tvalid_1's auc: 0.727193\n",
      "[73]\ttraining's auc: 0.84674\tvalid_1's auc: 0.726609\n",
      "[74]\ttraining's auc: 0.847974\tvalid_1's auc: 0.726454\n",
      "[75]\ttraining's auc: 0.848621\tvalid_1's auc: 0.726524\n",
      "[76]\ttraining's auc: 0.849481\tvalid_1's auc: 0.726931\n",
      "[77]\ttraining's auc: 0.85092\tvalid_1's auc: 0.727039\n",
      "[78]\ttraining's auc: 0.851997\tvalid_1's auc: 0.727201\n",
      "[79]\ttraining's auc: 0.853271\tvalid_1's auc: 0.728091\n",
      "[80]\ttraining's auc: 0.854132\tvalid_1's auc: 0.729076\n",
      "[81]\ttraining's auc: 0.85537\tvalid_1's auc: 0.728159\n",
      "[82]\ttraining's auc: 0.856749\tvalid_1's auc: 0.728064\n",
      "[83]\ttraining's auc: 0.858078\tvalid_1's auc: 0.727337\n",
      "[84]\ttraining's auc: 0.859264\tvalid_1's auc: 0.727811\n",
      "[85]\ttraining's auc: 0.860322\tvalid_1's auc: 0.727359\n",
      "[86]\ttraining's auc: 0.861024\tvalid_1's auc: 0.726758\n",
      "[87]\ttraining's auc: 0.861962\tvalid_1's auc: 0.726578\n",
      "[88]\ttraining's auc: 0.863109\tvalid_1's auc: 0.726304\n",
      "[89]\ttraining's auc: 0.864272\tvalid_1's auc: 0.726154\n",
      "[90]\ttraining's auc: 0.865841\tvalid_1's auc: 0.725318\n",
      "[91]\ttraining's auc: 0.866428\tvalid_1's auc: 0.725385\n",
      "[92]\ttraining's auc: 0.867315\tvalid_1's auc: 0.724612\n",
      "[93]\ttraining's auc: 0.868341\tvalid_1's auc: 0.724096\n",
      "[94]\ttraining's auc: 0.869297\tvalid_1's auc: 0.723906\n",
      "[95]\ttraining's auc: 0.86998\tvalid_1's auc: 0.724115\n",
      "[96]\ttraining's auc: 0.870661\tvalid_1's auc: 0.723434\n",
      "[97]\ttraining's auc: 0.87129\tvalid_1's auc: 0.723436\n",
      "[98]\ttraining's auc: 0.87188\tvalid_1's auc: 0.723538\n",
      "[99]\ttraining's auc: 0.873099\tvalid_1's auc: 0.722801\n",
      "[100]\ttraining's auc: 0.873914\tvalid_1's auc: 0.72225\n",
      "Fold 1: 0.72225\n",
      "[1]\ttraining's auc: 0.694725\tvalid_1's auc: 0.687065\n",
      "[2]\ttraining's auc: 0.714738\tvalid_1's auc: 0.709039\n",
      "[3]\ttraining's auc: 0.721492\tvalid_1's auc: 0.710344\n",
      "[4]\ttraining's auc: 0.725668\tvalid_1's auc: 0.712633\n",
      "[5]\ttraining's auc: 0.72845\tvalid_1's auc: 0.716387\n",
      "[6]\ttraining's auc: 0.73289\tvalid_1's auc: 0.715596\n",
      "[7]\ttraining's auc: 0.735795\tvalid_1's auc: 0.716126\n",
      "[8]\ttraining's auc: 0.740134\tvalid_1's auc: 0.715454\n",
      "[9]\ttraining's auc: 0.744673\tvalid_1's auc: 0.718681\n",
      "[10]\ttraining's auc: 0.748283\tvalid_1's auc: 0.717748\n",
      "[11]\ttraining's auc: 0.750393\tvalid_1's auc: 0.718897\n",
      "[12]\ttraining's auc: 0.753859\tvalid_1's auc: 0.720271\n",
      "[13]\ttraining's auc: 0.756109\tvalid_1's auc: 0.718954\n",
      "[14]\ttraining's auc: 0.75837\tvalid_1's auc: 0.719041\n",
      "[15]\ttraining's auc: 0.760185\tvalid_1's auc: 0.718569\n",
      "[16]\ttraining's auc: 0.762733\tvalid_1's auc: 0.718956\n",
      "[17]\ttraining's auc: 0.765344\tvalid_1's auc: 0.719358\n",
      "[18]\ttraining's auc: 0.767273\tvalid_1's auc: 0.719536\n",
      "[19]\ttraining's auc: 0.77023\tvalid_1's auc: 0.718325\n",
      "[20]\ttraining's auc: 0.772665\tvalid_1's auc: 0.718567\n",
      "[21]\ttraining's auc: 0.775322\tvalid_1's auc: 0.717618\n",
      "[22]\ttraining's auc: 0.777482\tvalid_1's auc: 0.71841\n",
      "[23]\ttraining's auc: 0.779777\tvalid_1's auc: 0.717782\n",
      "[24]\ttraining's auc: 0.781447\tvalid_1's auc: 0.717036\n",
      "[25]\ttraining's auc: 0.782737\tvalid_1's auc: 0.715749\n",
      "[26]\ttraining's auc: 0.784431\tvalid_1's auc: 0.715174\n",
      "[27]\ttraining's auc: 0.786104\tvalid_1's auc: 0.715441\n",
      "[28]\ttraining's auc: 0.787873\tvalid_1's auc: 0.71553\n",
      "[29]\ttraining's auc: 0.789024\tvalid_1's auc: 0.716375\n",
      "[30]\ttraining's auc: 0.791472\tvalid_1's auc: 0.714775\n",
      "[31]\ttraining's auc: 0.792672\tvalid_1's auc: 0.714529\n",
      "[32]\ttraining's auc: 0.794983\tvalid_1's auc: 0.716059\n",
      "[33]\ttraining's auc: 0.797069\tvalid_1's auc: 0.715773\n",
      "[34]\ttraining's auc: 0.798944\tvalid_1's auc: 0.715919\n",
      "[35]\ttraining's auc: 0.800686\tvalid_1's auc: 0.715781\n",
      "[36]\ttraining's auc: 0.802418\tvalid_1's auc: 0.716456\n",
      "[37]\ttraining's auc: 0.803689\tvalid_1's auc: 0.716565\n",
      "[38]\ttraining's auc: 0.805089\tvalid_1's auc: 0.717705\n",
      "[39]\ttraining's auc: 0.806511\tvalid_1's auc: 0.717821\n",
      "[40]\ttraining's auc: 0.808111\tvalid_1's auc: 0.71825\n",
      "[41]\ttraining's auc: 0.808891\tvalid_1's auc: 0.717709\n",
      "[42]\ttraining's auc: 0.810258\tvalid_1's auc: 0.717157\n",
      "[43]\ttraining's auc: 0.810964\tvalid_1's auc: 0.717031\n",
      "[44]\ttraining's auc: 0.812029\tvalid_1's auc: 0.716821\n",
      "[45]\ttraining's auc: 0.813361\tvalid_1's auc: 0.716915\n",
      "[46]\ttraining's auc: 0.813788\tvalid_1's auc: 0.717066\n",
      "[47]\ttraining's auc: 0.815082\tvalid_1's auc: 0.716204\n",
      "[48]\ttraining's auc: 0.816724\tvalid_1's auc: 0.717646\n",
      "[49]\ttraining's auc: 0.819222\tvalid_1's auc: 0.717682\n",
      "[50]\ttraining's auc: 0.821073\tvalid_1's auc: 0.717324\n",
      "[51]\ttraining's auc: 0.822147\tvalid_1's auc: 0.71681\n",
      "[52]\ttraining's auc: 0.823817\tvalid_1's auc: 0.716108\n",
      "[53]\ttraining's auc: 0.825073\tvalid_1's auc: 0.715343\n",
      "[54]\ttraining's auc: 0.825903\tvalid_1's auc: 0.714843\n",
      "[55]\ttraining's auc: 0.826251\tvalid_1's auc: 0.715124\n",
      "[56]\ttraining's auc: 0.826986\tvalid_1's auc: 0.715857\n",
      "[57]\ttraining's auc: 0.828206\tvalid_1's auc: 0.715052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58]\ttraining's auc: 0.829308\tvalid_1's auc: 0.714164\n",
      "[59]\ttraining's auc: 0.830881\tvalid_1's auc: 0.713951\n",
      "[60]\ttraining's auc: 0.832399\tvalid_1's auc: 0.714264\n",
      "[61]\ttraining's auc: 0.834014\tvalid_1's auc: 0.714489\n",
      "[62]\ttraining's auc: 0.83491\tvalid_1's auc: 0.713923\n",
      "[63]\ttraining's auc: 0.83589\tvalid_1's auc: 0.714548\n",
      "[64]\ttraining's auc: 0.836884\tvalid_1's auc: 0.714648\n",
      "[65]\ttraining's auc: 0.838013\tvalid_1's auc: 0.715195\n",
      "[66]\ttraining's auc: 0.839161\tvalid_1's auc: 0.715138\n",
      "[67]\ttraining's auc: 0.840069\tvalid_1's auc: 0.716144\n",
      "[68]\ttraining's auc: 0.840928\tvalid_1's auc: 0.715811\n",
      "[69]\ttraining's auc: 0.841757\tvalid_1's auc: 0.715895\n",
      "[70]\ttraining's auc: 0.84278\tvalid_1's auc: 0.715584\n",
      "[71]\ttraining's auc: 0.843876\tvalid_1's auc: 0.715166\n",
      "[72]\ttraining's auc: 0.845653\tvalid_1's auc: 0.715228\n",
      "[73]\ttraining's auc: 0.84644\tvalid_1's auc: 0.714947\n",
      "[74]\ttraining's auc: 0.847158\tvalid_1's auc: 0.714515\n",
      "[75]\ttraining's auc: 0.848453\tvalid_1's auc: 0.714233\n",
      "[76]\ttraining's auc: 0.849276\tvalid_1's auc: 0.713452\n",
      "[77]\ttraining's auc: 0.850311\tvalid_1's auc: 0.713231\n",
      "[78]\ttraining's auc: 0.851244\tvalid_1's auc: 0.714514\n",
      "[79]\ttraining's auc: 0.852194\tvalid_1's auc: 0.713683\n",
      "[80]\ttraining's auc: 0.853352\tvalid_1's auc: 0.713903\n",
      "[81]\ttraining's auc: 0.85405\tvalid_1's auc: 0.714093\n",
      "[82]\ttraining's auc: 0.854878\tvalid_1's auc: 0.714246\n",
      "[83]\ttraining's auc: 0.856226\tvalid_1's auc: 0.714347\n",
      "[84]\ttraining's auc: 0.857354\tvalid_1's auc: 0.71425\n",
      "[85]\ttraining's auc: 0.857865\tvalid_1's auc: 0.714297\n",
      "[86]\ttraining's auc: 0.858813\tvalid_1's auc: 0.713925\n",
      "[87]\ttraining's auc: 0.859792\tvalid_1's auc: 0.713223\n",
      "[88]\ttraining's auc: 0.860491\tvalid_1's auc: 0.712241\n",
      "[89]\ttraining's auc: 0.861236\tvalid_1's auc: 0.712622\n",
      "[90]\ttraining's auc: 0.862369\tvalid_1's auc: 0.713003\n",
      "[91]\ttraining's auc: 0.8639\tvalid_1's auc: 0.713094\n",
      "[92]\ttraining's auc: 0.864788\tvalid_1's auc: 0.712155\n",
      "[93]\ttraining's auc: 0.865346\tvalid_1's auc: 0.711873\n",
      "[94]\ttraining's auc: 0.866265\tvalid_1's auc: 0.712224\n",
      "[95]\ttraining's auc: 0.867063\tvalid_1's auc: 0.711672\n",
      "[96]\ttraining's auc: 0.867527\tvalid_1's auc: 0.710866\n",
      "[97]\ttraining's auc: 0.867728\tvalid_1's auc: 0.711059\n",
      "[98]\ttraining's auc: 0.869347\tvalid_1's auc: 0.709793\n",
      "[99]\ttraining's auc: 0.870342\tvalid_1's auc: 0.710249\n",
      "[100]\ttraining's auc: 0.870628\tvalid_1's auc: 0.710086\n",
      "Fold 2: 0.71009\n",
      "[1]\ttraining's auc: 0.692796\tvalid_1's auc: 0.698741\n",
      "[2]\ttraining's auc: 0.712348\tvalid_1's auc: 0.71094\n",
      "[3]\ttraining's auc: 0.718435\tvalid_1's auc: 0.714542\n",
      "[4]\ttraining's auc: 0.724028\tvalid_1's auc: 0.715498\n",
      "[5]\ttraining's auc: 0.727533\tvalid_1's auc: 0.715448\n",
      "[6]\ttraining's auc: 0.732987\tvalid_1's auc: 0.717836\n",
      "[7]\ttraining's auc: 0.735702\tvalid_1's auc: 0.717564\n",
      "[8]\ttraining's auc: 0.741733\tvalid_1's auc: 0.722054\n",
      "[9]\ttraining's auc: 0.744023\tvalid_1's auc: 0.722634\n",
      "[10]\ttraining's auc: 0.746263\tvalid_1's auc: 0.721664\n",
      "[11]\ttraining's auc: 0.749464\tvalid_1's auc: 0.719886\n",
      "[12]\ttraining's auc: 0.751923\tvalid_1's auc: 0.721503\n",
      "[13]\ttraining's auc: 0.754242\tvalid_1's auc: 0.722055\n",
      "[14]\ttraining's auc: 0.755905\tvalid_1's auc: 0.722377\n",
      "[15]\ttraining's auc: 0.758623\tvalid_1's auc: 0.723223\n",
      "[16]\ttraining's auc: 0.761454\tvalid_1's auc: 0.721541\n",
      "[17]\ttraining's auc: 0.764679\tvalid_1's auc: 0.720507\n",
      "[18]\ttraining's auc: 0.767121\tvalid_1's auc: 0.720184\n",
      "[19]\ttraining's auc: 0.769097\tvalid_1's auc: 0.720105\n",
      "[20]\ttraining's auc: 0.770875\tvalid_1's auc: 0.720677\n",
      "[21]\ttraining's auc: 0.772471\tvalid_1's auc: 0.720194\n",
      "[22]\ttraining's auc: 0.774491\tvalid_1's auc: 0.721628\n",
      "[23]\ttraining's auc: 0.77824\tvalid_1's auc: 0.722195\n",
      "[24]\ttraining's auc: 0.779909\tvalid_1's auc: 0.721389\n",
      "[25]\ttraining's auc: 0.782221\tvalid_1's auc: 0.721378\n",
      "[26]\ttraining's auc: 0.78357\tvalid_1's auc: 0.721365\n",
      "[27]\ttraining's auc: 0.786016\tvalid_1's auc: 0.719968\n",
      "[28]\ttraining's auc: 0.787532\tvalid_1's auc: 0.71941\n",
      "[29]\ttraining's auc: 0.789004\tvalid_1's auc: 0.718233\n",
      "[30]\ttraining's auc: 0.789946\tvalid_1's auc: 0.717852\n",
      "[31]\ttraining's auc: 0.79174\tvalid_1's auc: 0.717488\n",
      "[32]\ttraining's auc: 0.793024\tvalid_1's auc: 0.717405\n",
      "[33]\ttraining's auc: 0.794511\tvalid_1's auc: 0.71785\n",
      "[34]\ttraining's auc: 0.796185\tvalid_1's auc: 0.717147\n",
      "[35]\ttraining's auc: 0.798653\tvalid_1's auc: 0.718116\n",
      "[36]\ttraining's auc: 0.800508\tvalid_1's auc: 0.717\n",
      "[37]\ttraining's auc: 0.802348\tvalid_1's auc: 0.716572\n",
      "[38]\ttraining's auc: 0.803927\tvalid_1's auc: 0.715997\n",
      "[39]\ttraining's auc: 0.804601\tvalid_1's auc: 0.715507\n",
      "[40]\ttraining's auc: 0.805529\tvalid_1's auc: 0.715537\n",
      "[41]\ttraining's auc: 0.807225\tvalid_1's auc: 0.715255\n",
      "[42]\ttraining's auc: 0.80942\tvalid_1's auc: 0.715155\n",
      "[43]\ttraining's auc: 0.811058\tvalid_1's auc: 0.714703\n",
      "[44]\ttraining's auc: 0.812787\tvalid_1's auc: 0.714226\n",
      "[45]\ttraining's auc: 0.814313\tvalid_1's auc: 0.712879\n",
      "[46]\ttraining's auc: 0.815815\tvalid_1's auc: 0.712446\n",
      "[47]\ttraining's auc: 0.816987\tvalid_1's auc: 0.711666\n",
      "[48]\ttraining's auc: 0.818531\tvalid_1's auc: 0.71144\n",
      "[49]\ttraining's auc: 0.819914\tvalid_1's auc: 0.711563\n",
      "[50]\ttraining's auc: 0.821262\tvalid_1's auc: 0.710444\n",
      "[51]\ttraining's auc: 0.822252\tvalid_1's auc: 0.710186\n",
      "[52]\ttraining's auc: 0.823856\tvalid_1's auc: 0.708293\n",
      "[53]\ttraining's auc: 0.824867\tvalid_1's auc: 0.708538\n",
      "[54]\ttraining's auc: 0.825593\tvalid_1's auc: 0.708993\n",
      "[55]\ttraining's auc: 0.826749\tvalid_1's auc: 0.709046\n",
      "[56]\ttraining's auc: 0.828335\tvalid_1's auc: 0.709259\n",
      "[57]\ttraining's auc: 0.829409\tvalid_1's auc: 0.708839\n",
      "[58]\ttraining's auc: 0.830468\tvalid_1's auc: 0.708589\n",
      "[59]\ttraining's auc: 0.83147\tvalid_1's auc: 0.708961\n",
      "[60]\ttraining's auc: 0.832989\tvalid_1's auc: 0.708621\n",
      "[61]\ttraining's auc: 0.834223\tvalid_1's auc: 0.708826\n",
      "[62]\ttraining's auc: 0.835231\tvalid_1's auc: 0.708546\n",
      "[63]\ttraining's auc: 0.83606\tvalid_1's auc: 0.708611\n",
      "[64]\ttraining's auc: 0.837009\tvalid_1's auc: 0.709113\n",
      "[65]\ttraining's auc: 0.838476\tvalid_1's auc: 0.709083\n",
      "[66]\ttraining's auc: 0.839897\tvalid_1's auc: 0.709616\n",
      "[67]\ttraining's auc: 0.840638\tvalid_1's auc: 0.709406\n",
      "[68]\ttraining's auc: 0.841447\tvalid_1's auc: 0.70971\n",
      "[69]\ttraining's auc: 0.842132\tvalid_1's auc: 0.710051\n",
      "[70]\ttraining's auc: 0.843546\tvalid_1's auc: 0.710033\n",
      "[71]\ttraining's auc: 0.844206\tvalid_1's auc: 0.710079\n",
      "[72]\ttraining's auc: 0.845137\tvalid_1's auc: 0.709741\n",
      "[73]\ttraining's auc: 0.846136\tvalid_1's auc: 0.709078\n",
      "[74]\ttraining's auc: 0.84732\tvalid_1's auc: 0.708431\n",
      "[75]\ttraining's auc: 0.849129\tvalid_1's auc: 0.708538\n",
      "[76]\ttraining's auc: 0.849809\tvalid_1's auc: 0.708532\n",
      "[77]\ttraining's auc: 0.850942\tvalid_1's auc: 0.708343\n",
      "[78]\ttraining's auc: 0.852401\tvalid_1's auc: 0.707561\n",
      "[79]\ttraining's auc: 0.852774\tvalid_1's auc: 0.707805\n",
      "[80]\ttraining's auc: 0.853715\tvalid_1's auc: 0.708626\n",
      "[81]\ttraining's auc: 0.854835\tvalid_1's auc: 0.708643\n",
      "[82]\ttraining's auc: 0.855771\tvalid_1's auc: 0.708554\n",
      "[83]\ttraining's auc: 0.856577\tvalid_1's auc: 0.708219\n",
      "[84]\ttraining's auc: 0.857452\tvalid_1's auc: 0.70827\n",
      "[85]\ttraining's auc: 0.858453\tvalid_1's auc: 0.708449\n",
      "[86]\ttraining's auc: 0.859346\tvalid_1's auc: 0.707783\n",
      "[87]\ttraining's auc: 0.860413\tvalid_1's auc: 0.707396\n",
      "[88]\ttraining's auc: 0.86157\tvalid_1's auc: 0.706314\n",
      "[89]\ttraining's auc: 0.862326\tvalid_1's auc: 0.705704\n",
      "[90]\ttraining's auc: 0.863487\tvalid_1's auc: 0.705125\n",
      "[91]\ttraining's auc: 0.864892\tvalid_1's auc: 0.704973\n",
      "[92]\ttraining's auc: 0.865856\tvalid_1's auc: 0.705394\n",
      "[93]\ttraining's auc: 0.866286\tvalid_1's auc: 0.705046\n",
      "[94]\ttraining's auc: 0.866702\tvalid_1's auc: 0.705194\n",
      "[95]\ttraining's auc: 0.867631\tvalid_1's auc: 0.705136\n",
      "[96]\ttraining's auc: 0.868317\tvalid_1's auc: 0.705225\n",
      "[97]\ttraining's auc: 0.86942\tvalid_1's auc: 0.705118\n",
      "[98]\ttraining's auc: 0.870219\tvalid_1's auc: 0.704652\n",
      "[99]\ttraining's auc: 0.870666\tvalid_1's auc: 0.704923\n",
      "[100]\ttraining's auc: 0.871446\tvalid_1's auc: 0.704817\n",
      "Fold 3: 0.70482\n",
      "[1]\ttraining's auc: 0.698283\tvalid_1's auc: 0.674379\n",
      "[2]\ttraining's auc: 0.715985\tvalid_1's auc: 0.686238\n",
      "[3]\ttraining's auc: 0.72128\tvalid_1's auc: 0.693433\n",
      "[4]\ttraining's auc: 0.724853\tvalid_1's auc: 0.694734\n",
      "[5]\ttraining's auc: 0.728269\tvalid_1's auc: 0.69634\n",
      "[6]\ttraining's auc: 0.73321\tvalid_1's auc: 0.702155\n",
      "[7]\ttraining's auc: 0.736564\tvalid_1's auc: 0.701577\n",
      "[8]\ttraining's auc: 0.740075\tvalid_1's auc: 0.706205\n",
      "[9]\ttraining's auc: 0.743051\tvalid_1's auc: 0.706932\n",
      "[10]\ttraining's auc: 0.746379\tvalid_1's auc: 0.706529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttraining's auc: 0.748717\tvalid_1's auc: 0.707625\n",
      "[12]\ttraining's auc: 0.751952\tvalid_1's auc: 0.709766\n",
      "[13]\ttraining's auc: 0.754768\tvalid_1's auc: 0.710129\n",
      "[14]\ttraining's auc: 0.756806\tvalid_1's auc: 0.709613\n",
      "[15]\ttraining's auc: 0.75883\tvalid_1's auc: 0.709914\n",
      "[16]\ttraining's auc: 0.761816\tvalid_1's auc: 0.71051\n",
      "[17]\ttraining's auc: 0.764515\tvalid_1's auc: 0.712027\n",
      "[18]\ttraining's auc: 0.766202\tvalid_1's auc: 0.711647\n",
      "[19]\ttraining's auc: 0.7684\tvalid_1's auc: 0.712446\n",
      "[20]\ttraining's auc: 0.770005\tvalid_1's auc: 0.712024\n",
      "[21]\ttraining's auc: 0.771739\tvalid_1's auc: 0.712299\n",
      "[22]\ttraining's auc: 0.773191\tvalid_1's auc: 0.712217\n",
      "[23]\ttraining's auc: 0.774968\tvalid_1's auc: 0.712337\n",
      "[24]\ttraining's auc: 0.777335\tvalid_1's auc: 0.711587\n",
      "[25]\ttraining's auc: 0.779384\tvalid_1's auc: 0.711773\n",
      "[26]\ttraining's auc: 0.781397\tvalid_1's auc: 0.711252\n",
      "[27]\ttraining's auc: 0.783373\tvalid_1's auc: 0.711274\n",
      "[28]\ttraining's auc: 0.785784\tvalid_1's auc: 0.711689\n",
      "[29]\ttraining's auc: 0.787785\tvalid_1's auc: 0.711408\n",
      "[30]\ttraining's auc: 0.789879\tvalid_1's auc: 0.712625\n",
      "[31]\ttraining's auc: 0.790711\tvalid_1's auc: 0.712399\n",
      "[32]\ttraining's auc: 0.793099\tvalid_1's auc: 0.712092\n",
      "[33]\ttraining's auc: 0.794351\tvalid_1's auc: 0.711728\n",
      "[34]\ttraining's auc: 0.795631\tvalid_1's auc: 0.712064\n",
      "[35]\ttraining's auc: 0.797117\tvalid_1's auc: 0.711957\n",
      "[36]\ttraining's auc: 0.798803\tvalid_1's auc: 0.711282\n",
      "[37]\ttraining's auc: 0.800303\tvalid_1's auc: 0.710959\n",
      "[38]\ttraining's auc: 0.802784\tvalid_1's auc: 0.712236\n",
      "[39]\ttraining's auc: 0.803935\tvalid_1's auc: 0.711376\n",
      "[40]\ttraining's auc: 0.805156\tvalid_1's auc: 0.710857\n",
      "[41]\ttraining's auc: 0.806792\tvalid_1's auc: 0.710595\n",
      "[42]\ttraining's auc: 0.807696\tvalid_1's auc: 0.711412\n",
      "[43]\ttraining's auc: 0.808861\tvalid_1's auc: 0.710708\n",
      "[44]\ttraining's auc: 0.810697\tvalid_1's auc: 0.710046\n",
      "[45]\ttraining's auc: 0.812356\tvalid_1's auc: 0.708255\n",
      "[46]\ttraining's auc: 0.81357\tvalid_1's auc: 0.707231\n",
      "[47]\ttraining's auc: 0.814942\tvalid_1's auc: 0.70761\n",
      "[48]\ttraining's auc: 0.8168\tvalid_1's auc: 0.707459\n",
      "[49]\ttraining's auc: 0.818281\tvalid_1's auc: 0.707546\n",
      "[50]\ttraining's auc: 0.819092\tvalid_1's auc: 0.70721\n",
      "[51]\ttraining's auc: 0.821854\tvalid_1's auc: 0.70775\n",
      "[52]\ttraining's auc: 0.823466\tvalid_1's auc: 0.708413\n",
      "[53]\ttraining's auc: 0.824656\tvalid_1's auc: 0.708515\n",
      "[54]\ttraining's auc: 0.825966\tvalid_1's auc: 0.707871\n",
      "[55]\ttraining's auc: 0.826888\tvalid_1's auc: 0.707374\n",
      "[56]\ttraining's auc: 0.827863\tvalid_1's auc: 0.707086\n",
      "[57]\ttraining's auc: 0.829567\tvalid_1's auc: 0.705686\n",
      "[58]\ttraining's auc: 0.831746\tvalid_1's auc: 0.70521\n",
      "[59]\ttraining's auc: 0.832939\tvalid_1's auc: 0.705732\n",
      "[60]\ttraining's auc: 0.834379\tvalid_1's auc: 0.705869\n",
      "[61]\ttraining's auc: 0.835451\tvalid_1's auc: 0.705041\n",
      "[62]\ttraining's auc: 0.836428\tvalid_1's auc: 0.704667\n",
      "[63]\ttraining's auc: 0.837727\tvalid_1's auc: 0.704496\n",
      "[64]\ttraining's auc: 0.838632\tvalid_1's auc: 0.703919\n",
      "[65]\ttraining's auc: 0.839328\tvalid_1's auc: 0.703972\n",
      "[66]\ttraining's auc: 0.840478\tvalid_1's auc: 0.703852\n",
      "[67]\ttraining's auc: 0.841866\tvalid_1's auc: 0.704544\n",
      "[68]\ttraining's auc: 0.8428\tvalid_1's auc: 0.704284\n",
      "[69]\ttraining's auc: 0.843862\tvalid_1's auc: 0.704587\n",
      "[70]\ttraining's auc: 0.845125\tvalid_1's auc: 0.704153\n",
      "[71]\ttraining's auc: 0.846367\tvalid_1's auc: 0.705328\n",
      "[72]\ttraining's auc: 0.846659\tvalid_1's auc: 0.705546\n",
      "[73]\ttraining's auc: 0.847617\tvalid_1's auc: 0.705992\n",
      "[74]\ttraining's auc: 0.848188\tvalid_1's auc: 0.70565\n",
      "[75]\ttraining's auc: 0.848609\tvalid_1's auc: 0.70605\n",
      "[76]\ttraining's auc: 0.850343\tvalid_1's auc: 0.706041\n",
      "[77]\ttraining's auc: 0.851131\tvalid_1's auc: 0.706083\n",
      "[78]\ttraining's auc: 0.852442\tvalid_1's auc: 0.705352\n",
      "[79]\ttraining's auc: 0.853648\tvalid_1's auc: 0.705322\n",
      "[80]\ttraining's auc: 0.854696\tvalid_1's auc: 0.704715\n",
      "[81]\ttraining's auc: 0.855367\tvalid_1's auc: 0.70397\n",
      "[82]\ttraining's auc: 0.856146\tvalid_1's auc: 0.703694\n",
      "[83]\ttraining's auc: 0.856993\tvalid_1's auc: 0.704114\n",
      "[84]\ttraining's auc: 0.85753\tvalid_1's auc: 0.704273\n",
      "[85]\ttraining's auc: 0.857887\tvalid_1's auc: 0.704132\n",
      "[86]\ttraining's auc: 0.858625\tvalid_1's auc: 0.703855\n",
      "[87]\ttraining's auc: 0.859058\tvalid_1's auc: 0.704349\n",
      "[88]\ttraining's auc: 0.859753\tvalid_1's auc: 0.70478\n",
      "[89]\ttraining's auc: 0.860584\tvalid_1's auc: 0.705019\n",
      "[90]\ttraining's auc: 0.861712\tvalid_1's auc: 0.704399\n",
      "[91]\ttraining's auc: 0.862793\tvalid_1's auc: 0.703474\n",
      "[92]\ttraining's auc: 0.864061\tvalid_1's auc: 0.704029\n",
      "[93]\ttraining's auc: 0.865167\tvalid_1's auc: 0.70251\n",
      "[94]\ttraining's auc: 0.865511\tvalid_1's auc: 0.702542\n",
      "[95]\ttraining's auc: 0.866166\tvalid_1's auc: 0.703102\n",
      "[96]\ttraining's auc: 0.86694\tvalid_1's auc: 0.703122\n",
      "[97]\ttraining's auc: 0.867955\tvalid_1's auc: 0.702859\n",
      "[98]\ttraining's auc: 0.868809\tvalid_1's auc: 0.702608\n",
      "[99]\ttraining's auc: 0.869443\tvalid_1's auc: 0.702754\n",
      "[100]\ttraining's auc: 0.870618\tvalid_1's auc: 0.70308\n",
      "Fold 4: 0.70308\n",
      "[1]\ttraining's auc: 0.692066\tvalid_1's auc: 0.699324\n",
      "[2]\ttraining's auc: 0.712706\tvalid_1's auc: 0.7177\n",
      "[3]\ttraining's auc: 0.717165\tvalid_1's auc: 0.721805\n",
      "[4]\ttraining's auc: 0.720618\tvalid_1's auc: 0.723139\n",
      "[5]\ttraining's auc: 0.72369\tvalid_1's auc: 0.723649\n",
      "[6]\ttraining's auc: 0.729335\tvalid_1's auc: 0.728186\n",
      "[7]\ttraining's auc: 0.732444\tvalid_1's auc: 0.728452\n",
      "[8]\ttraining's auc: 0.73632\tvalid_1's auc: 0.730887\n",
      "[9]\ttraining's auc: 0.739515\tvalid_1's auc: 0.732484\n",
      "[10]\ttraining's auc: 0.744007\tvalid_1's auc: 0.733178\n",
      "[11]\ttraining's auc: 0.746298\tvalid_1's auc: 0.73513\n",
      "[12]\ttraining's auc: 0.749014\tvalid_1's auc: 0.736658\n",
      "[13]\ttraining's auc: 0.751021\tvalid_1's auc: 0.736979\n",
      "[14]\ttraining's auc: 0.752967\tvalid_1's auc: 0.736858\n",
      "[15]\ttraining's auc: 0.755556\tvalid_1's auc: 0.736594\n",
      "[16]\ttraining's auc: 0.757179\tvalid_1's auc: 0.738083\n",
      "[17]\ttraining's auc: 0.760733\tvalid_1's auc: 0.740178\n",
      "[18]\ttraining's auc: 0.763769\tvalid_1's auc: 0.740384\n",
      "[19]\ttraining's auc: 0.766769\tvalid_1's auc: 0.740438\n",
      "[20]\ttraining's auc: 0.768869\tvalid_1's auc: 0.740187\n",
      "[21]\ttraining's auc: 0.771176\tvalid_1's auc: 0.739701\n",
      "[22]\ttraining's auc: 0.773688\tvalid_1's auc: 0.740047\n",
      "[23]\ttraining's auc: 0.775798\tvalid_1's auc: 0.739355\n",
      "[24]\ttraining's auc: 0.777166\tvalid_1's auc: 0.739782\n",
      "[25]\ttraining's auc: 0.780291\tvalid_1's auc: 0.740384\n",
      "[26]\ttraining's auc: 0.78215\tvalid_1's auc: 0.739398\n",
      "[27]\ttraining's auc: 0.784427\tvalid_1's auc: 0.741318\n",
      "[28]\ttraining's auc: 0.78669\tvalid_1's auc: 0.741492\n",
      "[29]\ttraining's auc: 0.789328\tvalid_1's auc: 0.741391\n",
      "[30]\ttraining's auc: 0.790837\tvalid_1's auc: 0.741016\n",
      "[31]\ttraining's auc: 0.792085\tvalid_1's auc: 0.740433\n",
      "[32]\ttraining's auc: 0.793838\tvalid_1's auc: 0.741187\n",
      "[33]\ttraining's auc: 0.795576\tvalid_1's auc: 0.741326\n",
      "[34]\ttraining's auc: 0.797717\tvalid_1's auc: 0.740852\n",
      "[35]\ttraining's auc: 0.79956\tvalid_1's auc: 0.740302\n",
      "[36]\ttraining's auc: 0.800708\tvalid_1's auc: 0.740085\n",
      "[37]\ttraining's auc: 0.80215\tvalid_1's auc: 0.739328\n",
      "[38]\ttraining's auc: 0.803626\tvalid_1's auc: 0.739513\n",
      "[39]\ttraining's auc: 0.805758\tvalid_1's auc: 0.738851\n",
      "[40]\ttraining's auc: 0.806668\tvalid_1's auc: 0.738447\n",
      "[41]\ttraining's auc: 0.807902\tvalid_1's auc: 0.738645\n",
      "[42]\ttraining's auc: 0.808332\tvalid_1's auc: 0.738781\n",
      "[43]\ttraining's auc: 0.809652\tvalid_1's auc: 0.738748\n",
      "[44]\ttraining's auc: 0.81094\tvalid_1's auc: 0.738567\n",
      "[45]\ttraining's auc: 0.812475\tvalid_1's auc: 0.738284\n",
      "[46]\ttraining's auc: 0.814399\tvalid_1's auc: 0.738443\n",
      "[47]\ttraining's auc: 0.815766\tvalid_1's auc: 0.738528\n",
      "[48]\ttraining's auc: 0.817384\tvalid_1's auc: 0.73855\n",
      "[49]\ttraining's auc: 0.818136\tvalid_1's auc: 0.738885\n",
      "[50]\ttraining's auc: 0.819659\tvalid_1's auc: 0.738349\n",
      "[51]\ttraining's auc: 0.821939\tvalid_1's auc: 0.738905\n",
      "[52]\ttraining's auc: 0.823863\tvalid_1's auc: 0.738823\n",
      "[53]\ttraining's auc: 0.825088\tvalid_1's auc: 0.73897\n",
      "[54]\ttraining's auc: 0.825951\tvalid_1's auc: 0.739207\n",
      "[55]\ttraining's auc: 0.826948\tvalid_1's auc: 0.738703\n",
      "[56]\ttraining's auc: 0.828752\tvalid_1's auc: 0.739208\n",
      "[57]\ttraining's auc: 0.829913\tvalid_1's auc: 0.73816\n",
      "[58]\ttraining's auc: 0.831197\tvalid_1's auc: 0.738516\n",
      "[59]\ttraining's auc: 0.832323\tvalid_1's auc: 0.738424\n",
      "[60]\ttraining's auc: 0.833871\tvalid_1's auc: 0.738524\n",
      "[61]\ttraining's auc: 0.835341\tvalid_1's auc: 0.738956\n",
      "[62]\ttraining's auc: 0.836238\tvalid_1's auc: 0.738918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\ttraining's auc: 0.836646\tvalid_1's auc: 0.739447\n",
      "[64]\ttraining's auc: 0.837589\tvalid_1's auc: 0.739379\n",
      "[65]\ttraining's auc: 0.83924\tvalid_1's auc: 0.739081\n",
      "[66]\ttraining's auc: 0.840979\tvalid_1's auc: 0.738679\n",
      "[67]\ttraining's auc: 0.841866\tvalid_1's auc: 0.736867\n",
      "[68]\ttraining's auc: 0.843143\tvalid_1's auc: 0.736311\n",
      "[69]\ttraining's auc: 0.84432\tvalid_1's auc: 0.735801\n",
      "[70]\ttraining's auc: 0.8454\tvalid_1's auc: 0.735208\n",
      "[71]\ttraining's auc: 0.846081\tvalid_1's auc: 0.734953\n",
      "[72]\ttraining's auc: 0.846911\tvalid_1's auc: 0.734606\n",
      "[73]\ttraining's auc: 0.847521\tvalid_1's auc: 0.733874\n",
      "[74]\ttraining's auc: 0.848701\tvalid_1's auc: 0.734624\n",
      "[75]\ttraining's auc: 0.849644\tvalid_1's auc: 0.734767\n",
      "[76]\ttraining's auc: 0.851185\tvalid_1's auc: 0.734426\n",
      "[77]\ttraining's auc: 0.852354\tvalid_1's auc: 0.733754\n",
      "[78]\ttraining's auc: 0.853096\tvalid_1's auc: 0.734931\n",
      "[79]\ttraining's auc: 0.855096\tvalid_1's auc: 0.734401\n",
      "[80]\ttraining's auc: 0.855854\tvalid_1's auc: 0.734255\n",
      "[81]\ttraining's auc: 0.85682\tvalid_1's auc: 0.73443\n",
      "[82]\ttraining's auc: 0.857638\tvalid_1's auc: 0.734197\n",
      "[83]\ttraining's auc: 0.85859\tvalid_1's auc: 0.733145\n",
      "[84]\ttraining's auc: 0.859615\tvalid_1's auc: 0.734124\n",
      "[85]\ttraining's auc: 0.860311\tvalid_1's auc: 0.734412\n",
      "[86]\ttraining's auc: 0.861213\tvalid_1's auc: 0.734344\n",
      "[87]\ttraining's auc: 0.862004\tvalid_1's auc: 0.733883\n",
      "[88]\ttraining's auc: 0.862651\tvalid_1's auc: 0.734089\n",
      "[89]\ttraining's auc: 0.863263\tvalid_1's auc: 0.73415\n",
      "[90]\ttraining's auc: 0.8641\tvalid_1's auc: 0.733309\n",
      "[91]\ttraining's auc: 0.86508\tvalid_1's auc: 0.733729\n",
      "[92]\ttraining's auc: 0.866251\tvalid_1's auc: 0.733635\n",
      "[93]\ttraining's auc: 0.86695\tvalid_1's auc: 0.733828\n",
      "[94]\ttraining's auc: 0.867869\tvalid_1's auc: 0.733795\n",
      "[95]\ttraining's auc: 0.868735\tvalid_1's auc: 0.734633\n",
      "[96]\ttraining's auc: 0.869653\tvalid_1's auc: 0.734618\n",
      "[97]\ttraining's auc: 0.870374\tvalid_1's auc: 0.735243\n",
      "[98]\ttraining's auc: 0.870971\tvalid_1's auc: 0.735298\n",
      "[99]\ttraining's auc: 0.871273\tvalid_1's auc: 0.735117\n",
      "[100]\ttraining's auc: 0.871872\tvalid_1's auc: 0.734908\n",
      "Fold 5: 0.73491\n",
      "[1]\ttraining's auc: 0.695926\tvalid_1's auc: 0.670201\n",
      "[2]\ttraining's auc: 0.715171\tvalid_1's auc: 0.692706\n",
      "[3]\ttraining's auc: 0.723047\tvalid_1's auc: 0.695464\n",
      "[4]\ttraining's auc: 0.726653\tvalid_1's auc: 0.699269\n",
      "[5]\ttraining's auc: 0.730176\tvalid_1's auc: 0.700412\n",
      "[6]\ttraining's auc: 0.734035\tvalid_1's auc: 0.699875\n",
      "[7]\ttraining's auc: 0.737217\tvalid_1's auc: 0.702406\n",
      "[8]\ttraining's auc: 0.740624\tvalid_1's auc: 0.704704\n",
      "[9]\ttraining's auc: 0.744134\tvalid_1's auc: 0.706551\n",
      "[10]\ttraining's auc: 0.747038\tvalid_1's auc: 0.707189\n",
      "[11]\ttraining's auc: 0.749926\tvalid_1's auc: 0.706812\n",
      "[12]\ttraining's auc: 0.752579\tvalid_1's auc: 0.706524\n",
      "[13]\ttraining's auc: 0.754491\tvalid_1's auc: 0.708235\n",
      "[14]\ttraining's auc: 0.756335\tvalid_1's auc: 0.708075\n",
      "[15]\ttraining's auc: 0.757695\tvalid_1's auc: 0.707479\n",
      "[16]\ttraining's auc: 0.759039\tvalid_1's auc: 0.706883\n",
      "[17]\ttraining's auc: 0.762103\tvalid_1's auc: 0.707784\n",
      "[18]\ttraining's auc: 0.76371\tvalid_1's auc: 0.70847\n",
      "[19]\ttraining's auc: 0.766447\tvalid_1's auc: 0.707531\n",
      "[20]\ttraining's auc: 0.768024\tvalid_1's auc: 0.707815\n",
      "[21]\ttraining's auc: 0.770324\tvalid_1's auc: 0.707601\n",
      "[22]\ttraining's auc: 0.772419\tvalid_1's auc: 0.708428\n",
      "[23]\ttraining's auc: 0.775021\tvalid_1's auc: 0.708409\n",
      "[24]\ttraining's auc: 0.777594\tvalid_1's auc: 0.707751\n",
      "[25]\ttraining's auc: 0.779444\tvalid_1's auc: 0.707145\n",
      "[26]\ttraining's auc: 0.781492\tvalid_1's auc: 0.706877\n",
      "[27]\ttraining's auc: 0.783383\tvalid_1's auc: 0.706581\n",
      "[28]\ttraining's auc: 0.785476\tvalid_1's auc: 0.706364\n",
      "[29]\ttraining's auc: 0.787094\tvalid_1's auc: 0.70521\n",
      "[30]\ttraining's auc: 0.788785\tvalid_1's auc: 0.705182\n",
      "[31]\ttraining's auc: 0.790432\tvalid_1's auc: 0.703863\n",
      "[32]\ttraining's auc: 0.792164\tvalid_1's auc: 0.703614\n",
      "[33]\ttraining's auc: 0.794452\tvalid_1's auc: 0.704388\n",
      "[34]\ttraining's auc: 0.795049\tvalid_1's auc: 0.704698\n",
      "[35]\ttraining's auc: 0.796332\tvalid_1's auc: 0.704426\n",
      "[36]\ttraining's auc: 0.796933\tvalid_1's auc: 0.70386\n",
      "[37]\ttraining's auc: 0.798191\tvalid_1's auc: 0.70564\n",
      "[38]\ttraining's auc: 0.800716\tvalid_1's auc: 0.704843\n",
      "[39]\ttraining's auc: 0.802684\tvalid_1's auc: 0.704292\n",
      "[40]\ttraining's auc: 0.804482\tvalid_1's auc: 0.704294\n",
      "[41]\ttraining's auc: 0.805647\tvalid_1's auc: 0.704153\n",
      "[42]\ttraining's auc: 0.806759\tvalid_1's auc: 0.703822\n",
      "[43]\ttraining's auc: 0.807979\tvalid_1's auc: 0.70406\n",
      "[44]\ttraining's auc: 0.809167\tvalid_1's auc: 0.704047\n",
      "[45]\ttraining's auc: 0.810553\tvalid_1's auc: 0.703941\n",
      "[46]\ttraining's auc: 0.812756\tvalid_1's auc: 0.703689\n",
      "[47]\ttraining's auc: 0.813799\tvalid_1's auc: 0.703321\n",
      "[48]\ttraining's auc: 0.81506\tvalid_1's auc: 0.703885\n",
      "[49]\ttraining's auc: 0.816827\tvalid_1's auc: 0.703563\n",
      "[50]\ttraining's auc: 0.817925\tvalid_1's auc: 0.703546\n",
      "[51]\ttraining's auc: 0.818743\tvalid_1's auc: 0.703623\n",
      "[52]\ttraining's auc: 0.820065\tvalid_1's auc: 0.70344\n",
      "[53]\ttraining's auc: 0.821102\tvalid_1's auc: 0.703531\n",
      "[54]\ttraining's auc: 0.822359\tvalid_1's auc: 0.703204\n",
      "[55]\ttraining's auc: 0.822945\tvalid_1's auc: 0.702211\n",
      "[56]\ttraining's auc: 0.824736\tvalid_1's auc: 0.70215\n",
      "[57]\ttraining's auc: 0.826096\tvalid_1's auc: 0.703259\n",
      "[58]\ttraining's auc: 0.826793\tvalid_1's auc: 0.704007\n",
      "[59]\ttraining's auc: 0.828142\tvalid_1's auc: 0.70362\n",
      "[60]\ttraining's auc: 0.829933\tvalid_1's auc: 0.704569\n",
      "[61]\ttraining's auc: 0.832039\tvalid_1's auc: 0.703922\n",
      "[62]\ttraining's auc: 0.833276\tvalid_1's auc: 0.703784\n",
      "[63]\ttraining's auc: 0.834761\tvalid_1's auc: 0.703849\n",
      "[64]\ttraining's auc: 0.835748\tvalid_1's auc: 0.703752\n",
      "[65]\ttraining's auc: 0.836904\tvalid_1's auc: 0.70294\n",
      "[66]\ttraining's auc: 0.83839\tvalid_1's auc: 0.702415\n",
      "[67]\ttraining's auc: 0.839093\tvalid_1's auc: 0.701944\n",
      "[68]\ttraining's auc: 0.840189\tvalid_1's auc: 0.701479\n",
      "[69]\ttraining's auc: 0.840829\tvalid_1's auc: 0.701892\n",
      "[70]\ttraining's auc: 0.842098\tvalid_1's auc: 0.701511\n",
      "[71]\ttraining's auc: 0.842954\tvalid_1's auc: 0.70153\n",
      "[72]\ttraining's auc: 0.844027\tvalid_1's auc: 0.702074\n",
      "[73]\ttraining's auc: 0.845157\tvalid_1's auc: 0.702221\n",
      "[74]\ttraining's auc: 0.84616\tvalid_1's auc: 0.702195\n",
      "[75]\ttraining's auc: 0.847344\tvalid_1's auc: 0.702252\n",
      "[76]\ttraining's auc: 0.848311\tvalid_1's auc: 0.702636\n",
      "[77]\ttraining's auc: 0.84952\tvalid_1's auc: 0.702892\n",
      "[78]\ttraining's auc: 0.850063\tvalid_1's auc: 0.703478\n",
      "[79]\ttraining's auc: 0.85131\tvalid_1's auc: 0.704492\n",
      "[80]\ttraining's auc: 0.852801\tvalid_1's auc: 0.704721\n",
      "[81]\ttraining's auc: 0.853875\tvalid_1's auc: 0.705126\n",
      "[82]\ttraining's auc: 0.854823\tvalid_1's auc: 0.704398\n",
      "[83]\ttraining's auc: 0.85592\tvalid_1's auc: 0.703607\n",
      "[84]\ttraining's auc: 0.856505\tvalid_1's auc: 0.703246\n",
      "[85]\ttraining's auc: 0.857474\tvalid_1's auc: 0.70285\n",
      "[86]\ttraining's auc: 0.858373\tvalid_1's auc: 0.702307\n",
      "[87]\ttraining's auc: 0.859382\tvalid_1's auc: 0.702198\n",
      "[88]\ttraining's auc: 0.860453\tvalid_1's auc: 0.701688\n",
      "[89]\ttraining's auc: 0.861139\tvalid_1's auc: 0.701291\n",
      "[90]\ttraining's auc: 0.861524\tvalid_1's auc: 0.700617\n",
      "[91]\ttraining's auc: 0.862274\tvalid_1's auc: 0.700609\n",
      "[92]\ttraining's auc: 0.863108\tvalid_1's auc: 0.701323\n",
      "[93]\ttraining's auc: 0.86387\tvalid_1's auc: 0.700637\n",
      "[94]\ttraining's auc: 0.864142\tvalid_1's auc: 0.700989\n",
      "[95]\ttraining's auc: 0.865371\tvalid_1's auc: 0.701631\n",
      "[96]\ttraining's auc: 0.866111\tvalid_1's auc: 0.701514\n",
      "[97]\ttraining's auc: 0.867063\tvalid_1's auc: 0.701076\n",
      "[98]\ttraining's auc: 0.867804\tvalid_1's auc: 0.701206\n",
      "[99]\ttraining's auc: 0.869263\tvalid_1's auc: 0.700438\n",
      "[100]\ttraining's auc: 0.870203\tvalid_1's auc: 0.699594\n",
      "Fold 6: 0.69959\n",
      "[1]\ttraining's auc: 0.694173\tvalid_1's auc: 0.691279\n",
      "[2]\ttraining's auc: 0.713051\tvalid_1's auc: 0.712388\n",
      "[3]\ttraining's auc: 0.717725\tvalid_1's auc: 0.716236\n",
      "[4]\ttraining's auc: 0.724903\tvalid_1's auc: 0.720234\n",
      "[5]\ttraining's auc: 0.728802\tvalid_1's auc: 0.721835\n",
      "[6]\ttraining's auc: 0.733003\tvalid_1's auc: 0.724518\n",
      "[7]\ttraining's auc: 0.736444\tvalid_1's auc: 0.726628\n",
      "[8]\ttraining's auc: 0.74018\tvalid_1's auc: 0.729262\n",
      "[9]\ttraining's auc: 0.743742\tvalid_1's auc: 0.732915\n",
      "[10]\ttraining's auc: 0.747192\tvalid_1's auc: 0.732781\n",
      "[11]\ttraining's auc: 0.749666\tvalid_1's auc: 0.732676\n",
      "[12]\ttraining's auc: 0.753045\tvalid_1's auc: 0.732072\n",
      "[13]\ttraining's auc: 0.755716\tvalid_1's auc: 0.731994\n",
      "[14]\ttraining's auc: 0.757381\tvalid_1's auc: 0.732485\n",
      "[15]\ttraining's auc: 0.759786\tvalid_1's auc: 0.732545\n",
      "[16]\ttraining's auc: 0.761568\tvalid_1's auc: 0.734614\n",
      "[17]\ttraining's auc: 0.76369\tvalid_1's auc: 0.734949\n",
      "[18]\ttraining's auc: 0.766098\tvalid_1's auc: 0.734922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttraining's auc: 0.768008\tvalid_1's auc: 0.734911\n",
      "[20]\ttraining's auc: 0.769492\tvalid_1's auc: 0.734766\n",
      "[21]\ttraining's auc: 0.771177\tvalid_1's auc: 0.734657\n",
      "[22]\ttraining's auc: 0.77338\tvalid_1's auc: 0.735137\n",
      "[23]\ttraining's auc: 0.775062\tvalid_1's auc: 0.734651\n",
      "[24]\ttraining's auc: 0.777707\tvalid_1's auc: 0.734213\n",
      "[25]\ttraining's auc: 0.779805\tvalid_1's auc: 0.734022\n",
      "[26]\ttraining's auc: 0.781937\tvalid_1's auc: 0.73308\n",
      "[27]\ttraining's auc: 0.783492\tvalid_1's auc: 0.732207\n",
      "[28]\ttraining's auc: 0.785297\tvalid_1's auc: 0.732769\n",
      "[29]\ttraining's auc: 0.787334\tvalid_1's auc: 0.731795\n",
      "[30]\ttraining's auc: 0.789305\tvalid_1's auc: 0.730938\n",
      "[31]\ttraining's auc: 0.791088\tvalid_1's auc: 0.730374\n",
      "[32]\ttraining's auc: 0.793145\tvalid_1's auc: 0.730996\n",
      "[33]\ttraining's auc: 0.794453\tvalid_1's auc: 0.73067\n",
      "[34]\ttraining's auc: 0.795469\tvalid_1's auc: 0.729694\n",
      "[35]\ttraining's auc: 0.796938\tvalid_1's auc: 0.729678\n",
      "[36]\ttraining's auc: 0.797993\tvalid_1's auc: 0.729903\n",
      "[37]\ttraining's auc: 0.799334\tvalid_1's auc: 0.729575\n",
      "[38]\ttraining's auc: 0.801029\tvalid_1's auc: 0.728811\n",
      "[39]\ttraining's auc: 0.802468\tvalid_1's auc: 0.728457\n",
      "[40]\ttraining's auc: 0.803724\tvalid_1's auc: 0.728161\n",
      "[41]\ttraining's auc: 0.805782\tvalid_1's auc: 0.727276\n",
      "[42]\ttraining's auc: 0.808207\tvalid_1's auc: 0.72815\n",
      "[43]\ttraining's auc: 0.809961\tvalid_1's auc: 0.728249\n",
      "[44]\ttraining's auc: 0.811239\tvalid_1's auc: 0.728039\n",
      "[45]\ttraining's auc: 0.812551\tvalid_1's auc: 0.728617\n",
      "[46]\ttraining's auc: 0.813393\tvalid_1's auc: 0.728375\n",
      "[47]\ttraining's auc: 0.814923\tvalid_1's auc: 0.728371\n",
      "[48]\ttraining's auc: 0.81649\tvalid_1's auc: 0.728775\n",
      "[49]\ttraining's auc: 0.817704\tvalid_1's auc: 0.728354\n",
      "[50]\ttraining's auc: 0.819734\tvalid_1's auc: 0.727962\n",
      "[51]\ttraining's auc: 0.821493\tvalid_1's auc: 0.727654\n",
      "[52]\ttraining's auc: 0.822923\tvalid_1's auc: 0.727711\n",
      "[53]\ttraining's auc: 0.824318\tvalid_1's auc: 0.726631\n",
      "[54]\ttraining's auc: 0.826014\tvalid_1's auc: 0.727391\n",
      "[55]\ttraining's auc: 0.827041\tvalid_1's auc: 0.727358\n",
      "[56]\ttraining's auc: 0.828212\tvalid_1's auc: 0.727677\n",
      "[57]\ttraining's auc: 0.829596\tvalid_1's auc: 0.727468\n",
      "[58]\ttraining's auc: 0.830511\tvalid_1's auc: 0.727295\n",
      "[59]\ttraining's auc: 0.831775\tvalid_1's auc: 0.725766\n",
      "[60]\ttraining's auc: 0.832566\tvalid_1's auc: 0.726084\n",
      "[61]\ttraining's auc: 0.834464\tvalid_1's auc: 0.725162\n",
      "[62]\ttraining's auc: 0.835431\tvalid_1's auc: 0.724178\n",
      "[63]\ttraining's auc: 0.836588\tvalid_1's auc: 0.723811\n",
      "[64]\ttraining's auc: 0.83742\tvalid_1's auc: 0.723634\n",
      "[65]\ttraining's auc: 0.838371\tvalid_1's auc: 0.723293\n",
      "[66]\ttraining's auc: 0.839635\tvalid_1's auc: 0.722777\n",
      "[67]\ttraining's auc: 0.840917\tvalid_1's auc: 0.722807\n",
      "[68]\ttraining's auc: 0.842018\tvalid_1's auc: 0.722931\n",
      "[69]\ttraining's auc: 0.842818\tvalid_1's auc: 0.723424\n",
      "[70]\ttraining's auc: 0.843737\tvalid_1's auc: 0.722329\n",
      "[71]\ttraining's auc: 0.844404\tvalid_1's auc: 0.721629\n",
      "[72]\ttraining's auc: 0.845411\tvalid_1's auc: 0.721279\n",
      "[73]\ttraining's auc: 0.845881\tvalid_1's auc: 0.721407\n",
      "[74]\ttraining's auc: 0.846806\tvalid_1's auc: 0.72127\n",
      "[75]\ttraining's auc: 0.848165\tvalid_1's auc: 0.721059\n",
      "[76]\ttraining's auc: 0.849811\tvalid_1's auc: 0.721087\n",
      "[77]\ttraining's auc: 0.850508\tvalid_1's auc: 0.72113\n",
      "[78]\ttraining's auc: 0.8515\tvalid_1's auc: 0.720957\n",
      "[79]\ttraining's auc: 0.852081\tvalid_1's auc: 0.721204\n",
      "[80]\ttraining's auc: 0.852711\tvalid_1's auc: 0.721184\n",
      "[81]\ttraining's auc: 0.853973\tvalid_1's auc: 0.720729\n",
      "[82]\ttraining's auc: 0.854637\tvalid_1's auc: 0.72061\n",
      "[83]\ttraining's auc: 0.855257\tvalid_1's auc: 0.720837\n",
      "[84]\ttraining's auc: 0.855899\tvalid_1's auc: 0.72107\n",
      "[85]\ttraining's auc: 0.856329\tvalid_1's auc: 0.721027\n",
      "[86]\ttraining's auc: 0.857274\tvalid_1's auc: 0.720941\n",
      "[87]\ttraining's auc: 0.858535\tvalid_1's auc: 0.723028\n",
      "[88]\ttraining's auc: 0.859062\tvalid_1's auc: 0.722676\n",
      "[89]\ttraining's auc: 0.860494\tvalid_1's auc: 0.721881\n",
      "[90]\ttraining's auc: 0.860954\tvalid_1's auc: 0.722157\n",
      "[91]\ttraining's auc: 0.861701\tvalid_1's auc: 0.721624\n",
      "[92]\ttraining's auc: 0.862889\tvalid_1's auc: 0.720943\n",
      "[93]\ttraining's auc: 0.863749\tvalid_1's auc: 0.720052\n",
      "[94]\ttraining's auc: 0.865379\tvalid_1's auc: 0.719718\n",
      "[95]\ttraining's auc: 0.866354\tvalid_1's auc: 0.720095\n",
      "[96]\ttraining's auc: 0.867555\tvalid_1's auc: 0.719312\n",
      "[97]\ttraining's auc: 0.868441\tvalid_1's auc: 0.719237\n",
      "[98]\ttraining's auc: 0.869695\tvalid_1's auc: 0.718305\n",
      "[99]\ttraining's auc: 0.870385\tvalid_1's auc: 0.718748\n",
      "[100]\ttraining's auc: 0.870743\tvalid_1's auc: 0.71863\n",
      "Fold 7: 0.71863\n",
      "[1]\ttraining's auc: 0.696339\tvalid_1's auc: 0.678431\n",
      "[2]\ttraining's auc: 0.716882\tvalid_1's auc: 0.698359\n",
      "[3]\ttraining's auc: 0.720805\tvalid_1's auc: 0.703067\n",
      "[4]\ttraining's auc: 0.725925\tvalid_1's auc: 0.70294\n",
      "[5]\ttraining's auc: 0.730193\tvalid_1's auc: 0.703562\n",
      "[6]\ttraining's auc: 0.734406\tvalid_1's auc: 0.706322\n",
      "[7]\ttraining's auc: 0.737012\tvalid_1's auc: 0.7078\n",
      "[8]\ttraining's auc: 0.741996\tvalid_1's auc: 0.710475\n",
      "[9]\ttraining's auc: 0.745714\tvalid_1's auc: 0.712405\n",
      "[10]\ttraining's auc: 0.74879\tvalid_1's auc: 0.713227\n",
      "[11]\ttraining's auc: 0.751377\tvalid_1's auc: 0.713548\n",
      "[12]\ttraining's auc: 0.753123\tvalid_1's auc: 0.713056\n",
      "[13]\ttraining's auc: 0.755687\tvalid_1's auc: 0.713343\n",
      "[14]\ttraining's auc: 0.75808\tvalid_1's auc: 0.71237\n",
      "[15]\ttraining's auc: 0.759985\tvalid_1's auc: 0.71197\n",
      "[16]\ttraining's auc: 0.761524\tvalid_1's auc: 0.71352\n",
      "[17]\ttraining's auc: 0.764054\tvalid_1's auc: 0.714652\n",
      "[18]\ttraining's auc: 0.765898\tvalid_1's auc: 0.715165\n",
      "[19]\ttraining's auc: 0.768247\tvalid_1's auc: 0.715674\n",
      "[20]\ttraining's auc: 0.769831\tvalid_1's auc: 0.716666\n",
      "[21]\ttraining's auc: 0.7712\tvalid_1's auc: 0.716522\n",
      "[22]\ttraining's auc: 0.773299\tvalid_1's auc: 0.714612\n",
      "[23]\ttraining's auc: 0.776048\tvalid_1's auc: 0.713373\n",
      "[24]\ttraining's auc: 0.779732\tvalid_1's auc: 0.713438\n",
      "[25]\ttraining's auc: 0.780882\tvalid_1's auc: 0.713506\n",
      "[26]\ttraining's auc: 0.782648\tvalid_1's auc: 0.713191\n",
      "[27]\ttraining's auc: 0.784033\tvalid_1's auc: 0.713357\n",
      "[28]\ttraining's auc: 0.786198\tvalid_1's auc: 0.713153\n",
      "[29]\ttraining's auc: 0.787914\tvalid_1's auc: 0.712688\n",
      "[30]\ttraining's auc: 0.789679\tvalid_1's auc: 0.713585\n",
      "[31]\ttraining's auc: 0.791661\tvalid_1's auc: 0.713613\n",
      "[32]\ttraining's auc: 0.793765\tvalid_1's auc: 0.712628\n",
      "[33]\ttraining's auc: 0.795489\tvalid_1's auc: 0.712564\n",
      "[34]\ttraining's auc: 0.797445\tvalid_1's auc: 0.711404\n",
      "[35]\ttraining's auc: 0.799057\tvalid_1's auc: 0.71086\n",
      "[36]\ttraining's auc: 0.800495\tvalid_1's auc: 0.710843\n",
      "[37]\ttraining's auc: 0.801672\tvalid_1's auc: 0.713007\n",
      "[38]\ttraining's auc: 0.80362\tvalid_1's auc: 0.711124\n",
      "[39]\ttraining's auc: 0.804775\tvalid_1's auc: 0.711206\n",
      "[40]\ttraining's auc: 0.806716\tvalid_1's auc: 0.711224\n",
      "[41]\ttraining's auc: 0.807894\tvalid_1's auc: 0.711098\n",
      "[42]\ttraining's auc: 0.808966\tvalid_1's auc: 0.710803\n",
      "[43]\ttraining's auc: 0.810012\tvalid_1's auc: 0.71073\n",
      "[44]\ttraining's auc: 0.811414\tvalid_1's auc: 0.71064\n",
      "[45]\ttraining's auc: 0.812446\tvalid_1's auc: 0.710706\n",
      "[46]\ttraining's auc: 0.813957\tvalid_1's auc: 0.709827\n",
      "[47]\ttraining's auc: 0.815423\tvalid_1's auc: 0.708905\n",
      "[48]\ttraining's auc: 0.816815\tvalid_1's auc: 0.709727\n",
      "[49]\ttraining's auc: 0.817746\tvalid_1's auc: 0.708942\n",
      "[50]\ttraining's auc: 0.820423\tvalid_1's auc: 0.707851\n",
      "[51]\ttraining's auc: 0.822282\tvalid_1's auc: 0.708307\n",
      "[52]\ttraining's auc: 0.82296\tvalid_1's auc: 0.708086\n",
      "[53]\ttraining's auc: 0.824059\tvalid_1's auc: 0.707719\n",
      "[54]\ttraining's auc: 0.825664\tvalid_1's auc: 0.706156\n",
      "[55]\ttraining's auc: 0.826839\tvalid_1's auc: 0.705807\n",
      "[56]\ttraining's auc: 0.828075\tvalid_1's auc: 0.706021\n",
      "[57]\ttraining's auc: 0.828897\tvalid_1's auc: 0.706324\n",
      "[58]\ttraining's auc: 0.830334\tvalid_1's auc: 0.70529\n",
      "[59]\ttraining's auc: 0.832193\tvalid_1's auc: 0.704431\n",
      "[60]\ttraining's auc: 0.833925\tvalid_1's auc: 0.703749\n",
      "[61]\ttraining's auc: 0.835487\tvalid_1's auc: 0.703757\n",
      "[62]\ttraining's auc: 0.836688\tvalid_1's auc: 0.703846\n",
      "[63]\ttraining's auc: 0.837654\tvalid_1's auc: 0.703293\n",
      "[64]\ttraining's auc: 0.838839\tvalid_1's auc: 0.703975\n",
      "[65]\ttraining's auc: 0.840254\tvalid_1's auc: 0.704284\n",
      "[66]\ttraining's auc: 0.841326\tvalid_1's auc: 0.704728\n",
      "[67]\ttraining's auc: 0.84251\tvalid_1's auc: 0.705184\n",
      "[68]\ttraining's auc: 0.843323\tvalid_1's auc: 0.705151\n",
      "[69]\ttraining's auc: 0.844322\tvalid_1's auc: 0.705058\n",
      "[70]\ttraining's auc: 0.845614\tvalid_1's auc: 0.704563\n",
      "[71]\ttraining's auc: 0.846818\tvalid_1's auc: 0.705217\n",
      "[72]\ttraining's auc: 0.847662\tvalid_1's auc: 0.704906\n",
      "[73]\ttraining's auc: 0.848741\tvalid_1's auc: 0.704096\n",
      "[74]\ttraining's auc: 0.84951\tvalid_1's auc: 0.703759\n",
      "[75]\ttraining's auc: 0.850617\tvalid_1's auc: 0.703239\n",
      "[76]\ttraining's auc: 0.851551\tvalid_1's auc: 0.702538\n",
      "[77]\ttraining's auc: 0.852237\tvalid_1's auc: 0.702355\n",
      "[78]\ttraining's auc: 0.853544\tvalid_1's auc: 0.70211\n",
      "[79]\ttraining's auc: 0.855218\tvalid_1's auc: 0.702829\n",
      "[80]\ttraining's auc: 0.855997\tvalid_1's auc: 0.702596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81]\ttraining's auc: 0.856807\tvalid_1's auc: 0.701981\n",
      "[82]\ttraining's auc: 0.857773\tvalid_1's auc: 0.702373\n",
      "[83]\ttraining's auc: 0.858426\tvalid_1's auc: 0.702117\n",
      "[84]\ttraining's auc: 0.859655\tvalid_1's auc: 0.701178\n",
      "[85]\ttraining's auc: 0.860567\tvalid_1's auc: 0.701373\n",
      "[86]\ttraining's auc: 0.861679\tvalid_1's auc: 0.700842\n",
      "[87]\ttraining's auc: 0.862297\tvalid_1's auc: 0.700009\n",
      "[88]\ttraining's auc: 0.862726\tvalid_1's auc: 0.700258\n",
      "[89]\ttraining's auc: 0.864174\tvalid_1's auc: 0.699901\n",
      "[90]\ttraining's auc: 0.865153\tvalid_1's auc: 0.700309\n",
      "[91]\ttraining's auc: 0.865977\tvalid_1's auc: 0.70013\n",
      "[92]\ttraining's auc: 0.866691\tvalid_1's auc: 0.699873\n",
      "[93]\ttraining's auc: 0.867593\tvalid_1's auc: 0.699067\n",
      "[94]\ttraining's auc: 0.868614\tvalid_1's auc: 0.699593\n",
      "[95]\ttraining's auc: 0.869911\tvalid_1's auc: 0.699559\n",
      "[96]\ttraining's auc: 0.870708\tvalid_1's auc: 0.699677\n",
      "[97]\ttraining's auc: 0.870918\tvalid_1's auc: 0.699487\n",
      "[98]\ttraining's auc: 0.87172\tvalid_1's auc: 0.700151\n",
      "[99]\ttraining's auc: 0.872138\tvalid_1's auc: 0.70068\n",
      "[100]\ttraining's auc: 0.872515\tvalid_1's auc: 0.700291\n",
      "Fold 8: 0.70029\n",
      "[1]\ttraining's auc: 0.695405\tvalid_1's auc: 0.685638\n",
      "[2]\ttraining's auc: 0.7159\tvalid_1's auc: 0.702246\n",
      "[3]\ttraining's auc: 0.721512\tvalid_1's auc: 0.70464\n",
      "[4]\ttraining's auc: 0.725466\tvalid_1's auc: 0.707914\n",
      "[5]\ttraining's auc: 0.728315\tvalid_1's auc: 0.709097\n",
      "[6]\ttraining's auc: 0.732905\tvalid_1's auc: 0.710768\n",
      "[7]\ttraining's auc: 0.736314\tvalid_1's auc: 0.711525\n",
      "[8]\ttraining's auc: 0.739768\tvalid_1's auc: 0.713552\n",
      "[9]\ttraining's auc: 0.744375\tvalid_1's auc: 0.714977\n",
      "[10]\ttraining's auc: 0.74729\tvalid_1's auc: 0.715513\n",
      "[11]\ttraining's auc: 0.7504\tvalid_1's auc: 0.715165\n",
      "[12]\ttraining's auc: 0.752598\tvalid_1's auc: 0.712718\n",
      "[13]\ttraining's auc: 0.75529\tvalid_1's auc: 0.712632\n",
      "[14]\ttraining's auc: 0.757446\tvalid_1's auc: 0.713113\n",
      "[15]\ttraining's auc: 0.759093\tvalid_1's auc: 0.714112\n",
      "[16]\ttraining's auc: 0.760231\tvalid_1's auc: 0.714423\n",
      "[17]\ttraining's auc: 0.76408\tvalid_1's auc: 0.717841\n",
      "[18]\ttraining's auc: 0.767331\tvalid_1's auc: 0.717519\n",
      "[19]\ttraining's auc: 0.769458\tvalid_1's auc: 0.718141\n",
      "[20]\ttraining's auc: 0.772137\tvalid_1's auc: 0.718996\n",
      "[21]\ttraining's auc: 0.773897\tvalid_1's auc: 0.718843\n",
      "[22]\ttraining's auc: 0.77572\tvalid_1's auc: 0.718323\n",
      "[23]\ttraining's auc: 0.778425\tvalid_1's auc: 0.719156\n",
      "[24]\ttraining's auc: 0.781574\tvalid_1's auc: 0.720076\n",
      "[25]\ttraining's auc: 0.783096\tvalid_1's auc: 0.720646\n",
      "[26]\ttraining's auc: 0.784686\tvalid_1's auc: 0.720803\n",
      "[27]\ttraining's auc: 0.786733\tvalid_1's auc: 0.72101\n",
      "[28]\ttraining's auc: 0.788747\tvalid_1's auc: 0.720077\n",
      "[29]\ttraining's auc: 0.789606\tvalid_1's auc: 0.720607\n",
      "[30]\ttraining's auc: 0.791508\tvalid_1's auc: 0.719325\n",
      "[31]\ttraining's auc: 0.792749\tvalid_1's auc: 0.720402\n",
      "[32]\ttraining's auc: 0.794714\tvalid_1's auc: 0.720386\n",
      "[33]\ttraining's auc: 0.796369\tvalid_1's auc: 0.720733\n",
      "[34]\ttraining's auc: 0.798241\tvalid_1's auc: 0.719565\n",
      "[35]\ttraining's auc: 0.799906\tvalid_1's auc: 0.719532\n",
      "[36]\ttraining's auc: 0.801132\tvalid_1's auc: 0.719331\n",
      "[37]\ttraining's auc: 0.803429\tvalid_1's auc: 0.719873\n",
      "[38]\ttraining's auc: 0.805436\tvalid_1's auc: 0.719869\n",
      "[39]\ttraining's auc: 0.807339\tvalid_1's auc: 0.719132\n",
      "[40]\ttraining's auc: 0.808376\tvalid_1's auc: 0.717839\n",
      "[41]\ttraining's auc: 0.809829\tvalid_1's auc: 0.717391\n",
      "[42]\ttraining's auc: 0.810497\tvalid_1's auc: 0.717188\n",
      "[43]\ttraining's auc: 0.812016\tvalid_1's auc: 0.717402\n",
      "[44]\ttraining's auc: 0.813627\tvalid_1's auc: 0.717097\n",
      "[45]\ttraining's auc: 0.815198\tvalid_1's auc: 0.717185\n",
      "[46]\ttraining's auc: 0.816336\tvalid_1's auc: 0.718495\n",
      "[47]\ttraining's auc: 0.817363\tvalid_1's auc: 0.718054\n",
      "[48]\ttraining's auc: 0.818955\tvalid_1's auc: 0.71815\n",
      "[49]\ttraining's auc: 0.820742\tvalid_1's auc: 0.717936\n",
      "[50]\ttraining's auc: 0.822305\tvalid_1's auc: 0.718129\n",
      "[51]\ttraining's auc: 0.823439\tvalid_1's auc: 0.718362\n",
      "[52]\ttraining's auc: 0.824556\tvalid_1's auc: 0.717916\n",
      "[53]\ttraining's auc: 0.825512\tvalid_1's auc: 0.717863\n",
      "[54]\ttraining's auc: 0.826678\tvalid_1's auc: 0.717757\n",
      "[55]\ttraining's auc: 0.827856\tvalid_1's auc: 0.716313\n",
      "[56]\ttraining's auc: 0.829231\tvalid_1's auc: 0.716103\n",
      "[57]\ttraining's auc: 0.830425\tvalid_1's auc: 0.71534\n",
      "[58]\ttraining's auc: 0.831495\tvalid_1's auc: 0.714598\n",
      "[59]\ttraining's auc: 0.833339\tvalid_1's auc: 0.714386\n",
      "[60]\ttraining's auc: 0.834824\tvalid_1's auc: 0.713686\n",
      "[61]\ttraining's auc: 0.836141\tvalid_1's auc: 0.714082\n",
      "[62]\ttraining's auc: 0.837027\tvalid_1's auc: 0.714178\n",
      "[63]\ttraining's auc: 0.838069\tvalid_1's auc: 0.713924\n",
      "[64]\ttraining's auc: 0.838939\tvalid_1's auc: 0.714411\n",
      "[65]\ttraining's auc: 0.84\tvalid_1's auc: 0.714587\n",
      "[66]\ttraining's auc: 0.841059\tvalid_1's auc: 0.714669\n",
      "[67]\ttraining's auc: 0.842712\tvalid_1's auc: 0.713832\n",
      "[68]\ttraining's auc: 0.84345\tvalid_1's auc: 0.714011\n",
      "[69]\ttraining's auc: 0.84416\tvalid_1's auc: 0.713486\n",
      "[70]\ttraining's auc: 0.844976\tvalid_1's auc: 0.714173\n",
      "[71]\ttraining's auc: 0.846061\tvalid_1's auc: 0.713183\n",
      "[72]\ttraining's auc: 0.847701\tvalid_1's auc: 0.713836\n",
      "[73]\ttraining's auc: 0.849469\tvalid_1's auc: 0.71394\n",
      "[74]\ttraining's auc: 0.850282\tvalid_1's auc: 0.71286\n",
      "[75]\ttraining's auc: 0.850763\tvalid_1's auc: 0.71275\n",
      "[76]\ttraining's auc: 0.851543\tvalid_1's auc: 0.712771\n",
      "[77]\ttraining's auc: 0.852595\tvalid_1's auc: 0.711471\n",
      "[78]\ttraining's auc: 0.853653\tvalid_1's auc: 0.712196\n",
      "[79]\ttraining's auc: 0.854928\tvalid_1's auc: 0.712021\n",
      "[80]\ttraining's auc: 0.856183\tvalid_1's auc: 0.713415\n",
      "[81]\ttraining's auc: 0.857344\tvalid_1's auc: 0.713681\n",
      "[82]\ttraining's auc: 0.858141\tvalid_1's auc: 0.713615\n",
      "[83]\ttraining's auc: 0.859434\tvalid_1's auc: 0.714632\n",
      "[84]\ttraining's auc: 0.860247\tvalid_1's auc: 0.715024\n",
      "[85]\ttraining's auc: 0.861302\tvalid_1's auc: 0.714758\n",
      "[86]\ttraining's auc: 0.861912\tvalid_1's auc: 0.714726\n",
      "[87]\ttraining's auc: 0.862789\tvalid_1's auc: 0.715049\n",
      "[88]\ttraining's auc: 0.863281\tvalid_1's auc: 0.715247\n",
      "[89]\ttraining's auc: 0.86394\tvalid_1's auc: 0.714905\n",
      "[90]\ttraining's auc: 0.864689\tvalid_1's auc: 0.715299\n",
      "[91]\ttraining's auc: 0.866185\tvalid_1's auc: 0.71419\n",
      "[92]\ttraining's auc: 0.867322\tvalid_1's auc: 0.713951\n",
      "[93]\ttraining's auc: 0.867888\tvalid_1's auc: 0.713188\n",
      "[94]\ttraining's auc: 0.868933\tvalid_1's auc: 0.713028\n",
      "[95]\ttraining's auc: 0.869887\tvalid_1's auc: 0.712424\n",
      "[96]\ttraining's auc: 0.87094\tvalid_1's auc: 0.712201\n",
      "[97]\ttraining's auc: 0.871762\tvalid_1's auc: 0.712431\n",
      "[98]\ttraining's auc: 0.872679\tvalid_1's auc: 0.712462\n",
      "[99]\ttraining's auc: 0.874067\tvalid_1's auc: 0.71264\n",
      "[100]\ttraining's auc: 0.874525\tvalid_1's auc: 0.713475\n",
      "Fold 9: 0.71347\n",
      "[1]\ttraining's auc: 0.695149\tvalid_1's auc: 0.678426\n",
      "[2]\ttraining's auc: 0.715811\tvalid_1's auc: 0.689125\n",
      "[3]\ttraining's auc: 0.721327\tvalid_1's auc: 0.694702\n",
      "[4]\ttraining's auc: 0.725296\tvalid_1's auc: 0.696568\n",
      "[5]\ttraining's auc: 0.728938\tvalid_1's auc: 0.699536\n",
      "[6]\ttraining's auc: 0.734193\tvalid_1's auc: 0.703995\n",
      "[7]\ttraining's auc: 0.7368\tvalid_1's auc: 0.703168\n",
      "[8]\ttraining's auc: 0.741719\tvalid_1's auc: 0.705977\n",
      "[9]\ttraining's auc: 0.744799\tvalid_1's auc: 0.707647\n",
      "[10]\ttraining's auc: 0.748529\tvalid_1's auc: 0.709976\n",
      "[11]\ttraining's auc: 0.750383\tvalid_1's auc: 0.711542\n",
      "[12]\ttraining's auc: 0.753478\tvalid_1's auc: 0.712795\n",
      "[13]\ttraining's auc: 0.75625\tvalid_1's auc: 0.712863\n",
      "[14]\ttraining's auc: 0.758664\tvalid_1's auc: 0.713555\n",
      "[15]\ttraining's auc: 0.759964\tvalid_1's auc: 0.714297\n",
      "[16]\ttraining's auc: 0.762137\tvalid_1's auc: 0.714677\n",
      "[17]\ttraining's auc: 0.765231\tvalid_1's auc: 0.717381\n",
      "[18]\ttraining's auc: 0.767144\tvalid_1's auc: 0.717355\n",
      "[19]\ttraining's auc: 0.769294\tvalid_1's auc: 0.71696\n",
      "[20]\ttraining's auc: 0.771544\tvalid_1's auc: 0.716625\n",
      "[21]\ttraining's auc: 0.773024\tvalid_1's auc: 0.716214\n",
      "[22]\ttraining's auc: 0.774574\tvalid_1's auc: 0.716702\n",
      "[23]\ttraining's auc: 0.776466\tvalid_1's auc: 0.717385\n",
      "[24]\ttraining's auc: 0.778789\tvalid_1's auc: 0.71736\n",
      "[25]\ttraining's auc: 0.781521\tvalid_1's auc: 0.716967\n",
      "[26]\ttraining's auc: 0.783944\tvalid_1's auc: 0.715486\n",
      "[27]\ttraining's auc: 0.785929\tvalid_1's auc: 0.715182\n",
      "[28]\ttraining's auc: 0.786955\tvalid_1's auc: 0.71498\n",
      "[29]\ttraining's auc: 0.788444\tvalid_1's auc: 0.715798\n",
      "[30]\ttraining's auc: 0.79009\tvalid_1's auc: 0.715146\n",
      "[31]\ttraining's auc: 0.791744\tvalid_1's auc: 0.715148\n",
      "[32]\ttraining's auc: 0.793574\tvalid_1's auc: 0.714591\n",
      "[33]\ttraining's auc: 0.79495\tvalid_1's auc: 0.713706\n",
      "[34]\ttraining's auc: 0.796092\tvalid_1's auc: 0.713492\n",
      "[35]\ttraining's auc: 0.797994\tvalid_1's auc: 0.713761\n",
      "[36]\ttraining's auc: 0.799548\tvalid_1's auc: 0.713822\n",
      "[37]\ttraining's auc: 0.801697\tvalid_1's auc: 0.713584\n",
      "[38]\ttraining's auc: 0.804287\tvalid_1's auc: 0.714566\n",
      "[39]\ttraining's auc: 0.805751\tvalid_1's auc: 0.713878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttraining's auc: 0.807818\tvalid_1's auc: 0.713739\n",
      "[41]\ttraining's auc: 0.80957\tvalid_1's auc: 0.713691\n",
      "[42]\ttraining's auc: 0.810567\tvalid_1's auc: 0.714515\n",
      "[43]\ttraining's auc: 0.811734\tvalid_1's auc: 0.714552\n",
      "[44]\ttraining's auc: 0.812986\tvalid_1's auc: 0.714185\n",
      "[45]\ttraining's auc: 0.814121\tvalid_1's auc: 0.713897\n",
      "[46]\ttraining's auc: 0.815402\tvalid_1's auc: 0.714249\n",
      "[47]\ttraining's auc: 0.817084\tvalid_1's auc: 0.713412\n",
      "[48]\ttraining's auc: 0.81822\tvalid_1's auc: 0.713142\n",
      "[49]\ttraining's auc: 0.818693\tvalid_1's auc: 0.713\n",
      "[50]\ttraining's auc: 0.820739\tvalid_1's auc: 0.712734\n",
      "[51]\ttraining's auc: 0.822126\tvalid_1's auc: 0.71249\n",
      "[52]\ttraining's auc: 0.823696\tvalid_1's auc: 0.712448\n",
      "[53]\ttraining's auc: 0.824937\tvalid_1's auc: 0.71296\n",
      "[54]\ttraining's auc: 0.826314\tvalid_1's auc: 0.712843\n",
      "[55]\ttraining's auc: 0.827889\tvalid_1's auc: 0.712165\n",
      "[56]\ttraining's auc: 0.829268\tvalid_1's auc: 0.711968\n",
      "[57]\ttraining's auc: 0.83091\tvalid_1's auc: 0.711745\n",
      "[58]\ttraining's auc: 0.832411\tvalid_1's auc: 0.7117\n",
      "[59]\ttraining's auc: 0.833694\tvalid_1's auc: 0.712107\n",
      "[60]\ttraining's auc: 0.835654\tvalid_1's auc: 0.71099\n",
      "[61]\ttraining's auc: 0.835932\tvalid_1's auc: 0.710903\n",
      "[62]\ttraining's auc: 0.836849\tvalid_1's auc: 0.710957\n",
      "[63]\ttraining's auc: 0.837533\tvalid_1's auc: 0.710675\n",
      "[64]\ttraining's auc: 0.83894\tvalid_1's auc: 0.711024\n",
      "[65]\ttraining's auc: 0.840431\tvalid_1's auc: 0.710542\n",
      "[66]\ttraining's auc: 0.841083\tvalid_1's auc: 0.710363\n",
      "[67]\ttraining's auc: 0.842555\tvalid_1's auc: 0.710695\n",
      "[68]\ttraining's auc: 0.843546\tvalid_1's auc: 0.710051\n",
      "[69]\ttraining's auc: 0.84459\tvalid_1's auc: 0.709634\n",
      "[70]\ttraining's auc: 0.845152\tvalid_1's auc: 0.709609\n",
      "[71]\ttraining's auc: 0.846044\tvalid_1's auc: 0.709865\n",
      "[72]\ttraining's auc: 0.847347\tvalid_1's auc: 0.710159\n",
      "[73]\ttraining's auc: 0.848578\tvalid_1's auc: 0.710629\n",
      "[74]\ttraining's auc: 0.849781\tvalid_1's auc: 0.710317\n",
      "[75]\ttraining's auc: 0.850841\tvalid_1's auc: 0.71056\n",
      "[76]\ttraining's auc: 0.851933\tvalid_1's auc: 0.710267\n",
      "[77]\ttraining's auc: 0.853384\tvalid_1's auc: 0.710087\n",
      "[78]\ttraining's auc: 0.854051\tvalid_1's auc: 0.709592\n",
      "[79]\ttraining's auc: 0.854757\tvalid_1's auc: 0.708684\n",
      "[80]\ttraining's auc: 0.8553\tvalid_1's auc: 0.708219\n",
      "[81]\ttraining's auc: 0.856833\tvalid_1's auc: 0.708017\n",
      "[82]\ttraining's auc: 0.857901\tvalid_1's auc: 0.707411\n",
      "[83]\ttraining's auc: 0.858927\tvalid_1's auc: 0.708151\n",
      "[84]\ttraining's auc: 0.859543\tvalid_1's auc: 0.70873\n",
      "[85]\ttraining's auc: 0.860286\tvalid_1's auc: 0.709344\n",
      "[86]\ttraining's auc: 0.8615\tvalid_1's auc: 0.708631\n",
      "[87]\ttraining's auc: 0.862222\tvalid_1's auc: 0.708451\n",
      "[88]\ttraining's auc: 0.862876\tvalid_1's auc: 0.708152\n",
      "[89]\ttraining's auc: 0.86359\tvalid_1's auc: 0.707738\n",
      "[90]\ttraining's auc: 0.864563\tvalid_1's auc: 0.70711\n",
      "[91]\ttraining's auc: 0.865575\tvalid_1's auc: 0.70729\n",
      "[92]\ttraining's auc: 0.866094\tvalid_1's auc: 0.706901\n",
      "[93]\ttraining's auc: 0.867116\tvalid_1's auc: 0.70731\n",
      "[94]\ttraining's auc: 0.868009\tvalid_1's auc: 0.707024\n",
      "[95]\ttraining's auc: 0.868966\tvalid_1's auc: 0.706861\n",
      "[96]\ttraining's auc: 0.869624\tvalid_1's auc: 0.707117\n",
      "[97]\ttraining's auc: 0.870484\tvalid_1's auc: 0.70707\n",
      "[98]\ttraining's auc: 0.871476\tvalid_1's auc: 0.706903\n",
      "[99]\ttraining's auc: 0.872066\tvalid_1's auc: 0.70647\n",
      "[100]\ttraining's auc: 0.872951\tvalid_1's auc: 0.706199\n",
      "Fold 10: 0.7062\n",
      "CV score(auc): 0.71040 , (std: 0.01063 )\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "lgb_params = {'learning_rate': 0.3,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "\n",
    "N_FOLDS = 10\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "new_train = train[numerical]\n",
    "new_test = test[numerical]\n",
    "estimators, oof_preds_lgb = lgboost_cross_validation(\n",
    "    params=lgb_params, X=new_train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.7104\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_lgb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оценить корреляцию прогнозов на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.02022145, 0.0863369 , 0.22426425, ..., 0.29279172, 0.21572646,\n",
       "        0.31558186]),\n",
       " array([0.05072209, 0.0828137 , 0.07258419, ..., 0.08374355, 0.01698941,\n",
       "        0.08168347])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = []\n",
    "oof_train.append(oof_preds_xgb)\n",
    "oof_train.append(oof_preds_lgb)\n",
    "#oof_train = np.array(oof_train)\n",
    "oof_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применить модели на тестовую выборку и оценить корреляцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "#test[categorial] = test[categorial].astype(str)\n",
    "new_test = test[numerical]\n",
    "for estimator in estimators:\n",
    "    y_pred_lgb += estimator.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = y_pred_lgb / cv.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07099927, 0.30240174, 0.14171314, ..., 0.082115  , 0.02035166,\n",
       "       0.03268883])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0916783 , 0.14018704, 0.14139074, ..., 0.09751794, 0.07562688,\n",
       "        0.08285133],\n",
       "       [0.07099927, 0.30240174, 0.14171314, ..., 0.082115  , 0.02035166,\n",
       "        0.03268883]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test = []\n",
    "oof_test.append(y_pred_xgb)\n",
    "oof_test.append(y_pred_lgb)\n",
    "oof_test = np.array(oof_test)\n",
    "oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>110078</th>\n",
       "      <th>110079</th>\n",
       "      <th>110080</th>\n",
       "      <th>110081</th>\n",
       "      <th>110082</th>\n",
       "      <th>110083</th>\n",
       "      <th>110084</th>\n",
       "      <th>110085</th>\n",
       "      <th>110086</th>\n",
       "      <th>110087</th>\n",
       "      <th>110088</th>\n",
       "      <th>110089</th>\n",
       "      <th>110090</th>\n",
       "      <th>110091</th>\n",
       "      <th>110092</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.086337</td>\n",
       "      <td>0.224264</td>\n",
       "      <td>0.341367</td>\n",
       "      <td>0.237372</td>\n",
       "      <td>0.325107</td>\n",
       "      <td>0.256032</td>\n",
       "      <td>0.143219</td>\n",
       "      <td>0.118276</td>\n",
       "      <td>0.242048</td>\n",
       "      <td>0.292792</td>\n",
       "      <td>0.250288</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.116746</td>\n",
       "      <td>0.332793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068753</td>\n",
       "      <td>0.052010</td>\n",
       "      <td>0.271971</td>\n",
       "      <td>0.097910</td>\n",
       "      <td>0.239915</td>\n",
       "      <td>0.058776</td>\n",
       "      <td>0.237372</td>\n",
       "      <td>0.086337</td>\n",
       "      <td>0.292792</td>\n",
       "      <td>0.083044</td>\n",
       "      <td>0.275635</td>\n",
       "      <td>0.280509</td>\n",
       "      <td>0.292792</td>\n",
       "      <td>0.215726</td>\n",
       "      <td>0.315582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050722</td>\n",
       "      <td>0.082814</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.143022</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.207038</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>0.046242</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.069975</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>0.187914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063456</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.050759</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.083016</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.066289</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.081683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 110093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.020221  0.086337  0.224264  0.341367  0.237372  0.325107  0.256032   \n",
       "1  0.050722  0.082814  0.072584  0.143022  0.083744  0.207038  0.011906   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.143219  0.118276  0.242048  0.292792  0.250288  0.020357  0.116746   \n",
       "1  0.046242  0.064347  0.069975  0.082045  0.024384  0.034073  0.095641   \n",
       "\n",
       "     14      ...    110078    110079    110080    110081    110082    110083  \\\n",
       "0  0.332793  ...  0.068753  0.052010  0.271971  0.097910  0.239915  0.058776   \n",
       "1  0.187914  ...  0.063456  0.051148  0.025271  0.050759  0.011411  0.036821   \n",
       "\n",
       "     110084    110085    110086    110087    110088    110089    110090  \\\n",
       "0  0.237372  0.086337  0.292792  0.083044  0.275635  0.280509  0.292792   \n",
       "1  0.081329  0.083016  0.081329  0.081329  0.083744  0.066289  0.083744   \n",
       "\n",
       "     110091    110092  \n",
       "0  0.215726  0.315582  \n",
       "1  0.016989  0.081683  \n",
       "\n",
       "[2 rows x 110093 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_train)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11507584187832222"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941266823907058"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>165126</th>\n",
       "      <th>165127</th>\n",
       "      <th>165128</th>\n",
       "      <th>165129</th>\n",
       "      <th>165130</th>\n",
       "      <th>165131</th>\n",
       "      <th>165132</th>\n",
       "      <th>165133</th>\n",
       "      <th>165134</th>\n",
       "      <th>165135</th>\n",
       "      <th>165136</th>\n",
       "      <th>165137</th>\n",
       "      <th>165138</th>\n",
       "      <th>165139</th>\n",
       "      <th>165140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091678</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.141391</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.077565</td>\n",
       "      <td>0.080674</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.123166</td>\n",
       "      <td>0.073240</td>\n",
       "      <td>0.078034</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.100131</td>\n",
       "      <td>0.078583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.102227</td>\n",
       "      <td>0.074599</td>\n",
       "      <td>0.073807</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.072948</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.079203</td>\n",
       "      <td>0.097518</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>0.082851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070999</td>\n",
       "      <td>0.302402</td>\n",
       "      <td>0.141713</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.105363</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.096948</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.053758</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.032689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.091678  0.140187  0.141391  0.097518  0.077565  0.080674  0.097518   \n",
       "1  0.070999  0.302402  0.141713  0.082115  0.020860  0.017728  0.082115   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.123166  0.073240  0.078034  0.097518  0.084682  0.082137  0.100131   \n",
       "1  0.105363  0.002564  0.018398  0.082115  0.043093  0.030792  0.096948   \n",
       "\n",
       "     14      ...    165126    165127    165128    165129    165130    165131  \\\n",
       "0  0.078583  ...  0.077121  0.102227  0.074599  0.073807  0.072255  0.097518   \n",
       "1  0.018875  ...  0.022888  0.069734  0.008201  0.007681  0.004247  0.082115   \n",
       "\n",
       "     165132    165133    165134    165135    165136    165137    165138  \\\n",
       "0  0.097518  0.097518  0.072948  0.097518  0.097518  0.079203  0.097518   \n",
       "1  0.082115  0.082115  0.006500  0.082115  0.082115  0.053758  0.082115   \n",
       "\n",
       "     165139    165140  \n",
       "0  0.075627  0.082851  \n",
       "1  0.020352  0.032689  \n",
       "\n",
       "[2 rows x 165141 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_test)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017855433748181063"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_test[0] - oof_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_arifm = (oof_preds_xgb + oof_preds_lgb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_geom = (oof_preds_xgb * oof_preds_lgb) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.67081\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_arifm\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.70184\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_geom\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 29 19:17:08 2020, Cross-Validation, 110093 rows, 53 cols\n",
      "0:\ttest: 0.6734332\ttest1: 0.6641824\tbest: 0.6641824 (0)\ttotal: 115ms\tremaining: 3m 50s\n",
      "10:\ttest: 0.7007889\ttest1: 0.6938119\tbest: 0.6938119 (10)\ttotal: 1.17s\tremaining: 3m 30s\n",
      "20:\ttest: 0.7029293\ttest1: 0.6963111\tbest: 0.6970105 (18)\ttotal: 2.19s\tremaining: 3m 26s\n",
      "30:\ttest: 0.7058306\ttest1: 0.6981630\tbest: 0.6985139 (29)\ttotal: 3.23s\tremaining: 3m 24s\n",
      "40:\ttest: 0.7068103\ttest1: 0.6994951\tbest: 0.6994951 (40)\ttotal: 4.29s\tremaining: 3m 24s\n",
      "50:\ttest: 0.7073623\ttest1: 0.7009414\tbest: 0.7010275 (46)\ttotal: 5.3s\tremaining: 3m 22s\n",
      "60:\ttest: 0.7083320\ttest1: 0.7028293\tbest: 0.7028614 (59)\ttotal: 6.3s\tremaining: 3m 20s\n",
      "70:\ttest: 0.7087590\ttest1: 0.7025761\tbest: 0.7029574 (64)\ttotal: 7.32s\tremaining: 3m 18s\n",
      "80:\ttest: 0.7094492\ttest1: 0.7035250\tbest: 0.7035250 (80)\ttotal: 8.35s\tremaining: 3m 17s\n",
      "90:\ttest: 0.7100618\ttest1: 0.7038065\tbest: 0.7038065 (90)\ttotal: 9.37s\tremaining: 3m 16s\n",
      "100:\ttest: 0.7107377\ttest1: 0.7049387\tbest: 0.7049387 (100)\ttotal: 10.4s\tremaining: 3m 15s\n",
      "110:\ttest: 0.7111525\ttest1: 0.7049380\tbest: 0.7051281 (107)\ttotal: 11.4s\tremaining: 3m 14s\n",
      "120:\ttest: 0.7119920\ttest1: 0.7055332\tbest: 0.7055332 (120)\ttotal: 12.4s\tremaining: 3m 13s\n",
      "130:\ttest: 0.7122432\ttest1: 0.7054498\tbest: 0.7056216 (121)\ttotal: 13.5s\tremaining: 3m 12s\n",
      "140:\ttest: 0.7127023\ttest1: 0.7062489\tbest: 0.7064070 (135)\ttotal: 14.5s\tremaining: 3m 11s\n",
      "150:\ttest: 0.7133704\ttest1: 0.7069288\tbest: 0.7070098 (149)\ttotal: 15.6s\tremaining: 3m 10s\n",
      "160:\ttest: 0.7141563\ttest1: 0.7077022\tbest: 0.7077022 (160)\ttotal: 16.6s\tremaining: 3m 9s\n",
      "170:\ttest: 0.7148194\ttest1: 0.7080918\tbest: 0.7080918 (170)\ttotal: 17.6s\tremaining: 3m 8s\n",
      "180:\ttest: 0.7154515\ttest1: 0.7087161\tbest: 0.7089049 (178)\ttotal: 18.6s\tremaining: 3m 7s\n",
      "190:\ttest: 0.7160740\ttest1: 0.7092477\tbest: 0.7092477 (190)\ttotal: 19.7s\tremaining: 3m 6s\n",
      "200:\ttest: 0.7166322\ttest1: 0.7095682\tbest: 0.7095682 (200)\ttotal: 20.6s\tremaining: 3m 4s\n",
      "210:\ttest: 0.7172854\ttest1: 0.7101848\tbest: 0.7101848 (210)\ttotal: 21.6s\tremaining: 3m 3s\n",
      "220:\ttest: 0.7177808\ttest1: 0.7105783\tbest: 0.7105783 (220)\ttotal: 22.6s\tremaining: 3m 2s\n",
      "230:\ttest: 0.7184580\ttest1: 0.7110290\tbest: 0.7110290 (230)\ttotal: 23.6s\tremaining: 3m\n",
      "240:\ttest: 0.7191693\ttest1: 0.7114830\tbest: 0.7114890 (239)\ttotal: 24.6s\tremaining: 2m 59s\n",
      "250:\ttest: 0.7195681\ttest1: 0.7116629\tbest: 0.7118355 (246)\ttotal: 25.5s\tremaining: 2m 57s\n",
      "260:\ttest: 0.7202435\ttest1: 0.7121051\tbest: 0.7121839 (259)\ttotal: 26.5s\tremaining: 2m 56s\n",
      "270:\ttest: 0.7207897\ttest1: 0.7125034\tbest: 0.7125034 (270)\ttotal: 27.5s\tremaining: 2m 55s\n",
      "280:\ttest: 0.7212173\ttest1: 0.7126202\tbest: 0.7127238 (278)\ttotal: 28.5s\tremaining: 2m 54s\n",
      "290:\ttest: 0.7219228\ttest1: 0.7130589\tbest: 0.7131766 (287)\ttotal: 29.5s\tremaining: 2m 53s\n",
      "300:\ttest: 0.7223899\ttest1: 0.7134356\tbest: 0.7134409 (298)\ttotal: 30.5s\tremaining: 2m 52s\n",
      "310:\ttest: 0.7228333\ttest1: 0.7137387\tbest: 0.7137387 (310)\ttotal: 31.6s\tremaining: 2m 51s\n",
      "320:\ttest: 0.7235418\ttest1: 0.7142380\tbest: 0.7143501 (317)\ttotal: 32.5s\tremaining: 2m 50s\n",
      "330:\ttest: 0.7242397\ttest1: 0.7144845\tbest: 0.7145854 (327)\ttotal: 33.5s\tremaining: 2m 49s\n",
      "340:\ttest: 0.7249435\ttest1: 0.7148921\tbest: 0.7148921 (340)\ttotal: 34.6s\tremaining: 2m 48s\n",
      "350:\ttest: 0.7255887\ttest1: 0.7149194\tbest: 0.7149684 (344)\ttotal: 35.6s\tremaining: 2m 47s\n",
      "360:\ttest: 0.7259327\ttest1: 0.7147954\tbest: 0.7149684 (344)\ttotal: 36.6s\tremaining: 2m 46s\n",
      "370:\ttest: 0.7264867\ttest1: 0.7153671\tbest: 0.7153671 (370)\ttotal: 37.6s\tremaining: 2m 45s\n",
      "380:\ttest: 0.7269707\ttest1: 0.7156422\tbest: 0.7156422 (380)\ttotal: 38.6s\tremaining: 2m 44s\n",
      "390:\ttest: 0.7274827\ttest1: 0.7160319\tbest: 0.7160319 (390)\ttotal: 39.6s\tremaining: 2m 42s\n",
      "400:\ttest: 0.7280692\ttest1: 0.7166016\tbest: 0.7166016 (400)\ttotal: 40.6s\tremaining: 2m 41s\n",
      "410:\ttest: 0.7283622\ttest1: 0.7165406\tbest: 0.7167026 (403)\ttotal: 41.6s\tremaining: 2m 40s\n",
      "420:\ttest: 0.7288832\ttest1: 0.7172522\tbest: 0.7172541 (419)\ttotal: 42.5s\tremaining: 2m 39s\n",
      "430:\ttest: 0.7292555\ttest1: 0.7175706\tbest: 0.7175706 (430)\ttotal: 43.5s\tremaining: 2m 38s\n",
      "440:\ttest: 0.7296645\ttest1: 0.7180394\tbest: 0.7180394 (440)\ttotal: 44.5s\tremaining: 2m 37s\n",
      "450:\ttest: 0.7301549\ttest1: 0.7181225\tbest: 0.7181225 (450)\ttotal: 45.5s\tremaining: 2m 36s\n",
      "460:\ttest: 0.7306147\ttest1: 0.7182364\tbest: 0.7183004 (453)\ttotal: 46.5s\tremaining: 2m 35s\n",
      "470:\ttest: 0.7310461\ttest1: 0.7181965\tbest: 0.7183114 (464)\ttotal: 47.5s\tremaining: 2m 34s\n",
      "480:\ttest: 0.7315438\ttest1: 0.7184128\tbest: 0.7184128 (480)\ttotal: 48.5s\tremaining: 2m 33s\n",
      "490:\ttest: 0.7319522\ttest1: 0.7185707\tbest: 0.7186113 (489)\ttotal: 49.5s\tremaining: 2m 32s\n",
      "500:\ttest: 0.7324091\ttest1: 0.7187848\tbest: 0.7187848 (500)\ttotal: 50.5s\tremaining: 2m 30s\n",
      "510:\ttest: 0.7327392\ttest1: 0.7188383\tbest: 0.7188661 (508)\ttotal: 51.5s\tremaining: 2m 30s\n",
      "520:\ttest: 0.7329758\ttest1: 0.7189537\tbest: 0.7189642 (517)\ttotal: 52.5s\tremaining: 2m 28s\n",
      "530:\ttest: 0.7333106\ttest1: 0.7188299\tbest: 0.7189642 (517)\ttotal: 53.5s\tremaining: 2m 27s\n",
      "540:\ttest: 0.7337116\ttest1: 0.7189690\tbest: 0.7190201 (535)\ttotal: 54.5s\tremaining: 2m 27s\n",
      "550:\ttest: 0.7340900\ttest1: 0.7191441\tbest: 0.7191888 (547)\ttotal: 55.6s\tremaining: 2m 26s\n",
      "560:\ttest: 0.7344330\ttest1: 0.7191197\tbest: 0.7193506 (555)\ttotal: 56.6s\tremaining: 2m 25s\n",
      "570:\ttest: 0.7346253\ttest1: 0.7192139\tbest: 0.7193519 (562)\ttotal: 57.5s\tremaining: 2m 23s\n",
      "580:\ttest: 0.7349916\ttest1: 0.7193011\tbest: 0.7193519 (562)\ttotal: 58.5s\tremaining: 2m 22s\n",
      "590:\ttest: 0.7352593\ttest1: 0.7194442\tbest: 0.7194627 (585)\ttotal: 59.5s\tremaining: 2m 21s\n",
      "600:\ttest: 0.7356128\ttest1: 0.7195533\tbest: 0.7195605 (599)\ttotal: 1m\tremaining: 2m 20s\n",
      "610:\ttest: 0.7360013\ttest1: 0.7198231\tbest: 0.7198231 (610)\ttotal: 1m 1s\tremaining: 2m 19s\n",
      "620:\ttest: 0.7363279\ttest1: 0.7198800\tbest: 0.7198906 (619)\ttotal: 1m 2s\tremaining: 2m 18s\n",
      "630:\ttest: 0.7367278\ttest1: 0.7199964\tbest: 0.7200481 (626)\ttotal: 1m 3s\tremaining: 2m 17s\n",
      "640:\ttest: 0.7370343\ttest1: 0.7200308\tbest: 0.7200976 (636)\ttotal: 1m 4s\tremaining: 2m 16s\n",
      "650:\ttest: 0.7373095\ttest1: 0.7199707\tbest: 0.7201306 (644)\ttotal: 1m 5s\tremaining: 2m 15s\n",
      "660:\ttest: 0.7377603\ttest1: 0.7201663\tbest: 0.7201663 (660)\ttotal: 1m 6s\tremaining: 2m 14s\n",
      "670:\ttest: 0.7379735\ttest1: 0.7199764\tbest: 0.7202037 (664)\ttotal: 1m 7s\tremaining: 2m 13s\n",
      "680:\ttest: 0.7382876\ttest1: 0.7200766\tbest: 0.7202037 (664)\ttotal: 1m 8s\tremaining: 2m 12s\n",
      "690:\ttest: 0.7386843\ttest1: 0.7203249\tbest: 0.7203821 (686)\ttotal: 1m 9s\tremaining: 2m 11s\n",
      "700:\ttest: 0.7388685\ttest1: 0.7203259\tbest: 0.7204211 (698)\ttotal: 1m 10s\tremaining: 2m 10s\n",
      "710:\ttest: 0.7392707\ttest1: 0.7205308\tbest: 0.7205535 (704)\ttotal: 1m 11s\tremaining: 2m 9s\n",
      "720:\ttest: 0.7394811\ttest1: 0.7203465\tbest: 0.7206844 (715)\ttotal: 1m 12s\tremaining: 2m 8s\n",
      "730:\ttest: 0.7397236\ttest1: 0.7203796\tbest: 0.7206844 (715)\ttotal: 1m 13s\tremaining: 2m 7s\n",
      "740:\ttest: 0.7398278\ttest1: 0.7204062\tbest: 0.7206844 (715)\ttotal: 1m 14s\tremaining: 2m 6s\n",
      "750:\ttest: 0.7400912\ttest1: 0.7203814\tbest: 0.7206844 (715)\ttotal: 1m 15s\tremaining: 2m 5s\n",
      "760:\ttest: 0.7404009\ttest1: 0.7203798\tbest: 0.7206844 (715)\ttotal: 1m 16s\tremaining: 2m 4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7206844311\n",
      "bestIteration = 715\n",
      "\n",
      "Shrink model to first 716 iterations.\n",
      "Fold 1, Valid score = 0.72068\n",
      "0:\ttest: 0.6729537\ttest1: 0.6735935\tbest: 0.6735935 (0)\ttotal: 116ms\tremaining: 3m 51s\n",
      "10:\ttest: 0.6989716\ttest1: 0.7006435\tbest: 0.7006435 (10)\ttotal: 1.16s\tremaining: 3m 30s\n",
      "20:\ttest: 0.7013279\ttest1: 0.7033123\tbest: 0.7035578 (18)\ttotal: 2.18s\tremaining: 3m 25s\n",
      "30:\ttest: 0.7040805\ttest1: 0.7062677\tbest: 0.7062677 (30)\ttotal: 3.15s\tremaining: 3m 19s\n",
      "40:\ttest: 0.7057435\ttest1: 0.7060585\tbest: 0.7066366 (31)\ttotal: 4.18s\tremaining: 3m 19s\n",
      "50:\ttest: 0.7064967\ttest1: 0.7072601\tbest: 0.7072601 (50)\ttotal: 5.18s\tremaining: 3m 18s\n",
      "60:\ttest: 0.7074875\ttest1: 0.7081247\tbest: 0.7086986 (58)\ttotal: 6.19s\tremaining: 3m 16s\n",
      "70:\ttest: 0.7076100\ttest1: 0.7085970\tbest: 0.7088267 (63)\ttotal: 7.21s\tremaining: 3m 16s\n",
      "80:\ttest: 0.7089362\ttest1: 0.7094219\tbest: 0.7094219 (80)\ttotal: 8.26s\tremaining: 3m 15s\n",
      "90:\ttest: 0.7090073\ttest1: 0.7092548\tbest: 0.7094219 (80)\ttotal: 9.28s\tremaining: 3m 14s\n",
      "100:\ttest: 0.7096141\ttest1: 0.7086761\tbest: 0.7094219 (80)\ttotal: 10.3s\tremaining: 3m 13s\n",
      "110:\ttest: 0.7096761\ttest1: 0.7089010\tbest: 0.7094219 (80)\ttotal: 11.3s\tremaining: 3m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120:\ttest: 0.7102942\ttest1: 0.7094887\tbest: 0.7094887 (120)\ttotal: 12.3s\tremaining: 3m 11s\n",
      "130:\ttest: 0.7109416\ttest1: 0.7096544\tbest: 0.7097525 (125)\ttotal: 13.4s\tremaining: 3m 10s\n",
      "140:\ttest: 0.7114409\ttest1: 0.7100903\tbest: 0.7101572 (138)\ttotal: 14.3s\tremaining: 3m 8s\n",
      "150:\ttest: 0.7124348\ttest1: 0.7114451\tbest: 0.7114451 (150)\ttotal: 15.3s\tremaining: 3m 7s\n",
      "160:\ttest: 0.7130634\ttest1: 0.7116085\tbest: 0.7116093 (156)\ttotal: 16.4s\tremaining: 3m 6s\n",
      "170:\ttest: 0.7134697\ttest1: 0.7120329\tbest: 0.7122668 (166)\ttotal: 17.4s\tremaining: 3m 6s\n",
      "180:\ttest: 0.7138800\ttest1: 0.7124840\tbest: 0.7125025 (179)\ttotal: 18.4s\tremaining: 3m 5s\n",
      "190:\ttest: 0.7145701\ttest1: 0.7128818\tbest: 0.7128818 (190)\ttotal: 19.4s\tremaining: 3m 4s\n",
      "200:\ttest: 0.7150727\ttest1: 0.7131927\tbest: 0.7131927 (200)\ttotal: 20.4s\tremaining: 3m 2s\n",
      "210:\ttest: 0.7157641\ttest1: 0.7139536\tbest: 0.7139536 (210)\ttotal: 21.4s\tremaining: 3m 1s\n",
      "220:\ttest: 0.7165304\ttest1: 0.7144560\tbest: 0.7144675 (218)\ttotal: 22.4s\tremaining: 3m\n",
      "230:\ttest: 0.7171534\ttest1: 0.7147089\tbest: 0.7148432 (229)\ttotal: 23.4s\tremaining: 2m 59s\n",
      "240:\ttest: 0.7177943\ttest1: 0.7154301\tbest: 0.7154301 (240)\ttotal: 24.4s\tremaining: 2m 58s\n",
      "250:\ttest: 0.7182470\ttest1: 0.7157308\tbest: 0.7157308 (250)\ttotal: 25.4s\tremaining: 2m 57s\n",
      "260:\ttest: 0.7190987\ttest1: 0.7162283\tbest: 0.7162754 (259)\ttotal: 26.5s\tremaining: 2m 56s\n",
      "270:\ttest: 0.7198572\ttest1: 0.7167724\tbest: 0.7167724 (270)\ttotal: 27.4s\tremaining: 2m 55s\n",
      "280:\ttest: 0.7207496\ttest1: 0.7171668\tbest: 0.7172521 (278)\ttotal: 28.5s\tremaining: 2m 54s\n",
      "290:\ttest: 0.7210790\ttest1: 0.7172724\tbest: 0.7172935 (281)\ttotal: 29.5s\tremaining: 2m 53s\n",
      "300:\ttest: 0.7215705\ttest1: 0.7174181\tbest: 0.7174181 (300)\ttotal: 30.5s\tremaining: 2m 52s\n",
      "310:\ttest: 0.7221183\ttest1: 0.7177691\tbest: 0.7177691 (310)\ttotal: 31.4s\tremaining: 2m 50s\n",
      "320:\ttest: 0.7227888\ttest1: 0.7178319\tbest: 0.7179135 (318)\ttotal: 32.4s\tremaining: 2m 49s\n",
      "330:\ttest: 0.7234525\ttest1: 0.7187307\tbest: 0.7187433 (329)\ttotal: 33.4s\tremaining: 2m 48s\n",
      "340:\ttest: 0.7238978\ttest1: 0.7193944\tbest: 0.7193944 (340)\ttotal: 34.4s\tremaining: 2m 47s\n",
      "350:\ttest: 0.7241585\ttest1: 0.7194943\tbest: 0.7195213 (348)\ttotal: 35.4s\tremaining: 2m 46s\n",
      "360:\ttest: 0.7247585\ttest1: 0.7199276\tbest: 0.7199394 (359)\ttotal: 36.5s\tremaining: 2m 45s\n",
      "370:\ttest: 0.7252420\ttest1: 0.7199964\tbest: 0.7200768 (367)\ttotal: 37.5s\tremaining: 2m 44s\n",
      "380:\ttest: 0.7258998\ttest1: 0.7203251\tbest: 0.7203329 (379)\ttotal: 38.4s\tremaining: 2m 43s\n",
      "390:\ttest: 0.7264302\ttest1: 0.7203454\tbest: 0.7203832 (383)\ttotal: 39.4s\tremaining: 2m 42s\n",
      "400:\ttest: 0.7270677\ttest1: 0.7202680\tbest: 0.7203832 (383)\ttotal: 40.5s\tremaining: 2m 41s\n",
      "410:\ttest: 0.7274660\ttest1: 0.7205593\tbest: 0.7205716 (409)\ttotal: 41.6s\tremaining: 2m 40s\n",
      "420:\ttest: 0.7280182\ttest1: 0.7210087\tbest: 0.7210087 (420)\ttotal: 42.6s\tremaining: 2m 39s\n",
      "430:\ttest: 0.7284578\ttest1: 0.7211857\tbest: 0.7211857 (430)\ttotal: 43.6s\tremaining: 2m 38s\n",
      "440:\ttest: 0.7287109\ttest1: 0.7216433\tbest: 0.7216433 (440)\ttotal: 44.6s\tremaining: 2m 37s\n",
      "450:\ttest: 0.7291227\ttest1: 0.7218723\tbest: 0.7219674 (447)\ttotal: 45.6s\tremaining: 2m 36s\n",
      "460:\ttest: 0.7293782\ttest1: 0.7220309\tbest: 0.7220481 (456)\ttotal: 46.5s\tremaining: 2m 35s\n",
      "470:\ttest: 0.7299461\ttest1: 0.7222769\tbest: 0.7223351 (467)\ttotal: 47.5s\tremaining: 2m 34s\n",
      "480:\ttest: 0.7304093\ttest1: 0.7222747\tbest: 0.7223351 (467)\ttotal: 48.5s\tremaining: 2m 33s\n",
      "490:\ttest: 0.7308276\ttest1: 0.7226942\tbest: 0.7226942 (490)\ttotal: 49.5s\tremaining: 2m 32s\n",
      "500:\ttest: 0.7312631\ttest1: 0.7230880\tbest: 0.7230880 (500)\ttotal: 50.5s\tremaining: 2m 31s\n",
      "510:\ttest: 0.7316653\ttest1: 0.7229223\tbest: 0.7231571 (506)\ttotal: 51.5s\tremaining: 2m 29s\n",
      "520:\ttest: 0.7319172\ttest1: 0.7231412\tbest: 0.7231571 (506)\ttotal: 52.4s\tremaining: 2m 28s\n",
      "530:\ttest: 0.7323090\ttest1: 0.7231557\tbest: 0.7234089 (527)\ttotal: 53.5s\tremaining: 2m 28s\n",
      "540:\ttest: 0.7326211\ttest1: 0.7234743\tbest: 0.7234797 (539)\ttotal: 54.6s\tremaining: 2m 27s\n",
      "550:\ttest: 0.7329078\ttest1: 0.7232189\tbest: 0.7235016 (541)\ttotal: 55.5s\tremaining: 2m 26s\n",
      "560:\ttest: 0.7331075\ttest1: 0.7234510\tbest: 0.7236134 (558)\ttotal: 56.6s\tremaining: 2m 25s\n",
      "570:\ttest: 0.7334413\ttest1: 0.7233922\tbest: 0.7236134 (558)\ttotal: 57.6s\tremaining: 2m 24s\n",
      "580:\ttest: 0.7337765\ttest1: 0.7235420\tbest: 0.7236134 (558)\ttotal: 58.6s\tremaining: 2m 23s\n",
      "590:\ttest: 0.7340567\ttest1: 0.7236596\tbest: 0.7236726 (589)\ttotal: 59.6s\tremaining: 2m 22s\n",
      "600:\ttest: 0.7343325\ttest1: 0.7240886\tbest: 0.7240886 (600)\ttotal: 1m\tremaining: 2m 21s\n",
      "610:\ttest: 0.7345614\ttest1: 0.7242589\tbest: 0.7242589 (610)\ttotal: 1m 1s\tremaining: 2m 20s\n",
      "620:\ttest: 0.7348334\ttest1: 0.7243915\tbest: 0.7243967 (619)\ttotal: 1m 2s\tremaining: 2m 19s\n",
      "630:\ttest: 0.7350954\ttest1: 0.7245939\tbest: 0.7245939 (630)\ttotal: 1m 3s\tremaining: 2m 18s\n",
      "640:\ttest: 0.7353334\ttest1: 0.7246288\tbest: 0.7246288 (640)\ttotal: 1m 4s\tremaining: 2m 17s\n",
      "650:\ttest: 0.7357057\ttest1: 0.7249991\tbest: 0.7250207 (648)\ttotal: 1m 5s\tremaining: 2m 16s\n",
      "660:\ttest: 0.7360495\ttest1: 0.7250664\tbest: 0.7251563 (652)\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "670:\ttest: 0.7362493\ttest1: 0.7251620\tbest: 0.7253236 (669)\ttotal: 1m 7s\tremaining: 2m 14s\n",
      "680:\ttest: 0.7364059\ttest1: 0.7252468\tbest: 0.7253337 (678)\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "690:\ttest: 0.7367133\ttest1: 0.7252218\tbest: 0.7253621 (682)\ttotal: 1m 10s\tremaining: 2m 12s\n",
      "700:\ttest: 0.7369946\ttest1: 0.7254962\tbest: 0.7254962 (700)\ttotal: 1m 11s\tremaining: 2m 12s\n",
      "710:\ttest: 0.7372294\ttest1: 0.7255468\tbest: 0.7255468 (710)\ttotal: 1m 12s\tremaining: 2m 11s\n",
      "720:\ttest: 0.7375412\ttest1: 0.7257414\tbest: 0.7257414 (720)\ttotal: 1m 13s\tremaining: 2m 10s\n",
      "730:\ttest: 0.7378568\ttest1: 0.7260274\tbest: 0.7260274 (730)\ttotal: 1m 14s\tremaining: 2m 9s\n",
      "740:\ttest: 0.7381249\ttest1: 0.7260241\tbest: 0.7260913 (736)\ttotal: 1m 15s\tremaining: 2m 8s\n",
      "750:\ttest: 0.7384743\ttest1: 0.7263468\tbest: 0.7263468 (750)\ttotal: 1m 16s\tremaining: 2m 7s\n",
      "760:\ttest: 0.7387317\ttest1: 0.7262128\tbest: 0.7263832 (751)\ttotal: 1m 17s\tremaining: 2m 6s\n",
      "770:\ttest: 0.7389075\ttest1: 0.7260742\tbest: 0.7263832 (751)\ttotal: 1m 18s\tremaining: 2m 5s\n",
      "780:\ttest: 0.7392286\ttest1: 0.7261983\tbest: 0.7263832 (751)\ttotal: 1m 19s\tremaining: 2m 4s\n",
      "790:\ttest: 0.7394173\ttest1: 0.7263192\tbest: 0.7263832 (751)\ttotal: 1m 20s\tremaining: 2m 3s\n",
      "800:\ttest: 0.7395949\ttest1: 0.7263050\tbest: 0.7263832 (751)\ttotal: 1m 21s\tremaining: 2m 2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7263831921\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Fold 2, Valid score = 0.72638\n",
      "0:\ttest: 0.6726414\ttest1: 0.6762924\tbest: 0.6762924 (0)\ttotal: 118ms\tremaining: 3m 55s\n",
      "10:\ttest: 0.6997830\ttest1: 0.7009374\tbest: 0.7009374 (10)\ttotal: 1.16s\tremaining: 3m 30s\n",
      "20:\ttest: 0.7021615\ttest1: 0.7040370\tbest: 0.7044587 (19)\ttotal: 2.17s\tremaining: 3m 24s\n",
      "30:\ttest: 0.7049362\ttest1: 0.7053683\tbest: 0.7057209 (29)\ttotal: 3.19s\tremaining: 3m 22s\n",
      "40:\ttest: 0.7056281\ttest1: 0.7064705\tbest: 0.7064705 (40)\ttotal: 4.25s\tremaining: 3m 22s\n",
      "50:\ttest: 0.7063439\ttest1: 0.7073457\tbest: 0.7075734 (49)\ttotal: 5.49s\tremaining: 3m 29s\n",
      "60:\ttest: 0.7073357\ttest1: 0.7072643\tbest: 0.7079201 (55)\ttotal: 6.53s\tremaining: 3m 27s\n",
      "70:\ttest: 0.7079443\ttest1: 0.7083653\tbest: 0.7084416 (67)\ttotal: 7.68s\tremaining: 3m 28s\n",
      "80:\ttest: 0.7080791\ttest1: 0.7086654\tbest: 0.7086654 (80)\ttotal: 8.86s\tremaining: 3m 29s\n",
      "90:\ttest: 0.7084104\ttest1: 0.7083440\tbest: 0.7087246 (85)\ttotal: 9.9s\tremaining: 3m 27s\n",
      "100:\ttest: 0.7088160\ttest1: 0.7087412\tbest: 0.7089566 (99)\ttotal: 11.1s\tremaining: 3m 28s\n",
      "110:\ttest: 0.7090396\ttest1: 0.7088011\tbest: 0.7089978 (101)\ttotal: 12.2s\tremaining: 3m 27s\n",
      "120:\ttest: 0.7099367\ttest1: 0.7096591\tbest: 0.7096591 (120)\ttotal: 13.2s\tremaining: 3m 25s\n",
      "130:\ttest: 0.7102321\ttest1: 0.7098475\tbest: 0.7098475 (130)\ttotal: 14.2s\tremaining: 3m 22s\n",
      "140:\ttest: 0.7109256\ttest1: 0.7104185\tbest: 0.7105045 (135)\ttotal: 15.2s\tremaining: 3m 20s\n",
      "150:\ttest: 0.7116690\ttest1: 0.7111999\tbest: 0.7111999 (150)\ttotal: 16.3s\tremaining: 3m 19s\n",
      "160:\ttest: 0.7124006\ttest1: 0.7122916\tbest: 0.7122916 (160)\ttotal: 17.3s\tremaining: 3m 17s\n",
      "170:\ttest: 0.7131494\ttest1: 0.7131576\tbest: 0.7131576 (170)\ttotal: 18.3s\tremaining: 3m 15s\n",
      "180:\ttest: 0.7135253\ttest1: 0.7132151\tbest: 0.7135057 (179)\ttotal: 19.3s\tremaining: 3m 13s\n",
      "190:\ttest: 0.7143193\ttest1: 0.7141821\tbest: 0.7141821 (190)\ttotal: 20.4s\tremaining: 3m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200:\ttest: 0.7148753\ttest1: 0.7147597\tbest: 0.7150023 (198)\ttotal: 21.4s\tremaining: 3m 11s\n",
      "210:\ttest: 0.7155343\ttest1: 0.7160551\tbest: 0.7160551 (210)\ttotal: 22.5s\tremaining: 3m 10s\n",
      "220:\ttest: 0.7162537\ttest1: 0.7163370\tbest: 0.7163370 (220)\ttotal: 23.6s\tremaining: 3m 10s\n",
      "230:\ttest: 0.7170317\ttest1: 0.7167893\tbest: 0.7168715 (229)\ttotal: 24.7s\tremaining: 3m 8s\n",
      "240:\ttest: 0.7176536\ttest1: 0.7172015\tbest: 0.7172213 (239)\ttotal: 25.6s\tremaining: 3m 7s\n",
      "250:\ttest: 0.7183309\ttest1: 0.7181379\tbest: 0.7181379 (250)\ttotal: 26.6s\tremaining: 3m 5s\n",
      "260:\ttest: 0.7188662\ttest1: 0.7184569\tbest: 0.7184569 (260)\ttotal: 27.7s\tremaining: 3m 4s\n",
      "270:\ttest: 0.7195983\ttest1: 0.7190029\tbest: 0.7190029 (270)\ttotal: 28.7s\tremaining: 3m 3s\n",
      "280:\ttest: 0.7200566\ttest1: 0.7191380\tbest: 0.7191650 (279)\ttotal: 29.6s\tremaining: 3m\n",
      "290:\ttest: 0.7205093\ttest1: 0.7196423\tbest: 0.7198270 (289)\ttotal: 30.6s\tremaining: 2m 59s\n",
      "300:\ttest: 0.7211720\ttest1: 0.7199142\tbest: 0.7200460 (299)\ttotal: 31.7s\tremaining: 2m 58s\n",
      "310:\ttest: 0.7216494\ttest1: 0.7206488\tbest: 0.7206488 (310)\ttotal: 32.6s\tremaining: 2m 57s\n",
      "320:\ttest: 0.7222380\ttest1: 0.7209790\tbest: 0.7209790 (320)\ttotal: 33.7s\tremaining: 2m 56s\n",
      "330:\ttest: 0.7224354\ttest1: 0.7213458\tbest: 0.7213458 (330)\ttotal: 34.7s\tremaining: 2m 54s\n",
      "340:\ttest: 0.7229978\ttest1: 0.7219649\tbest: 0.7219649 (340)\ttotal: 35.7s\tremaining: 2m 53s\n",
      "350:\ttest: 0.7236650\ttest1: 0.7225761\tbest: 0.7225761 (350)\ttotal: 36.6s\tremaining: 2m 52s\n",
      "360:\ttest: 0.7240249\ttest1: 0.7228962\tbest: 0.7229222 (358)\ttotal: 37.7s\tremaining: 2m 50s\n",
      "370:\ttest: 0.7245342\ttest1: 0.7234455\tbest: 0.7234634 (369)\ttotal: 38.7s\tremaining: 2m 49s\n",
      "380:\ttest: 0.7251510\ttest1: 0.7238145\tbest: 0.7238145 (380)\ttotal: 39.7s\tremaining: 2m 48s\n",
      "390:\ttest: 0.7257247\ttest1: 0.7241841\tbest: 0.7241841 (390)\ttotal: 40.7s\tremaining: 2m 47s\n",
      "400:\ttest: 0.7261637\ttest1: 0.7241854\tbest: 0.7242970 (391)\ttotal: 41.7s\tremaining: 2m 46s\n",
      "410:\ttest: 0.7266689\ttest1: 0.7244539\tbest: 0.7244727 (409)\ttotal: 42.6s\tremaining: 2m 44s\n",
      "420:\ttest: 0.7271217\ttest1: 0.7246872\tbest: 0.7247806 (419)\ttotal: 43.5s\tremaining: 2m 43s\n",
      "430:\ttest: 0.7276873\ttest1: 0.7250593\tbest: 0.7250593 (430)\ttotal: 44.6s\tremaining: 2m 42s\n",
      "440:\ttest: 0.7280662\ttest1: 0.7249555\tbest: 0.7250593 (430)\ttotal: 45.6s\tremaining: 2m 41s\n",
      "450:\ttest: 0.7286214\ttest1: 0.7252649\tbest: 0.7252649 (450)\ttotal: 46.6s\tremaining: 2m 39s\n",
      "460:\ttest: 0.7288523\ttest1: 0.7255501\tbest: 0.7255501 (460)\ttotal: 47.6s\tremaining: 2m 38s\n",
      "470:\ttest: 0.7293380\ttest1: 0.7258358\tbest: 0.7258358 (470)\ttotal: 48.6s\tremaining: 2m 37s\n",
      "480:\ttest: 0.7297731\ttest1: 0.7261665\tbest: 0.7261665 (480)\ttotal: 49.5s\tremaining: 2m 36s\n",
      "490:\ttest: 0.7300418\ttest1: 0.7263156\tbest: 0.7263156 (490)\ttotal: 50.5s\tremaining: 2m 35s\n",
      "500:\ttest: 0.7302964\ttest1: 0.7265782\tbest: 0.7266344 (495)\ttotal: 51.5s\tremaining: 2m 34s\n",
      "510:\ttest: 0.7306580\ttest1: 0.7266064\tbest: 0.7266344 (495)\ttotal: 52.5s\tremaining: 2m 32s\n",
      "520:\ttest: 0.7310627\ttest1: 0.7269031\tbest: 0.7269031 (520)\ttotal: 53.4s\tremaining: 2m 31s\n",
      "530:\ttest: 0.7313125\ttest1: 0.7269993\tbest: 0.7270122 (525)\ttotal: 54.4s\tremaining: 2m 30s\n",
      "540:\ttest: 0.7315649\ttest1: 0.7271999\tbest: 0.7272416 (538)\ttotal: 55.4s\tremaining: 2m 29s\n",
      "550:\ttest: 0.7318961\ttest1: 0.7272454\tbest: 0.7272598 (549)\ttotal: 56.4s\tremaining: 2m 28s\n",
      "560:\ttest: 0.7321542\ttest1: 0.7274054\tbest: 0.7274054 (560)\ttotal: 57.4s\tremaining: 2m 27s\n",
      "570:\ttest: 0.7325461\ttest1: 0.7276021\tbest: 0.7276085 (569)\ttotal: 58.3s\tremaining: 2m 25s\n",
      "580:\ttest: 0.7328047\ttest1: 0.7275495\tbest: 0.7276085 (569)\ttotal: 59.2s\tremaining: 2m 24s\n",
      "590:\ttest: 0.7332104\ttest1: 0.7276977\tbest: 0.7276977 (590)\ttotal: 1m\tremaining: 2m 23s\n",
      "600:\ttest: 0.7335526\ttest1: 0.7278027\tbest: 0.7278027 (600)\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "610:\ttest: 0.7337685\ttest1: 0.7279825\tbest: 0.7280338 (607)\ttotal: 1m 2s\tremaining: 2m 21s\n",
      "620:\ttest: 0.7338536\ttest1: 0.7280266\tbest: 0.7281141 (619)\ttotal: 1m 3s\tremaining: 2m 20s\n",
      "630:\ttest: 0.7342534\ttest1: 0.7280537\tbest: 0.7281584 (629)\ttotal: 1m 4s\tremaining: 2m 18s\n",
      "640:\ttest: 0.7345236\ttest1: 0.7284848\tbest: 0.7284848 (640)\ttotal: 1m 5s\tremaining: 2m 17s\n",
      "650:\ttest: 0.7347829\ttest1: 0.7284567\tbest: 0.7285822 (645)\ttotal: 1m 5s\tremaining: 2m 16s\n",
      "660:\ttest: 0.7350669\ttest1: 0.7287850\tbest: 0.7288780 (657)\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "670:\ttest: 0.7353504\ttest1: 0.7288115\tbest: 0.7288780 (657)\ttotal: 1m 7s\tremaining: 2m 14s\n",
      "680:\ttest: 0.7354992\ttest1: 0.7286148\tbest: 0.7288780 (657)\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "690:\ttest: 0.7358093\ttest1: 0.7288478\tbest: 0.7288780 (657)\ttotal: 1m 9s\tremaining: 2m 12s\n",
      "700:\ttest: 0.7359138\ttest1: 0.7287637\tbest: 0.7289210 (692)\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "710:\ttest: 0.7362092\ttest1: 0.7291145\tbest: 0.7291167 (709)\ttotal: 1m 11s\tremaining: 2m 9s\n",
      "720:\ttest: 0.7364073\ttest1: 0.7291081\tbest: 0.7291301 (713)\ttotal: 1m 12s\tremaining: 2m 8s\n",
      "730:\ttest: 0.7366021\ttest1: 0.7294286\tbest: 0.7294286 (730)\ttotal: 1m 13s\tremaining: 2m 7s\n",
      "740:\ttest: 0.7368685\ttest1: 0.7295583\tbest: 0.7296629 (738)\ttotal: 1m 14s\tremaining: 2m 6s\n",
      "750:\ttest: 0.7370825\ttest1: 0.7296724\tbest: 0.7297100 (745)\ttotal: 1m 15s\tremaining: 2m 5s\n",
      "760:\ttest: 0.7372901\ttest1: 0.7297059\tbest: 0.7297941 (758)\ttotal: 1m 16s\tremaining: 2m 4s\n",
      "770:\ttest: 0.7374281\ttest1: 0.7298017\tbest: 0.7299082 (768)\ttotal: 1m 17s\tremaining: 2m 3s\n",
      "780:\ttest: 0.7377077\ttest1: 0.7298979\tbest: 0.7299082 (768)\ttotal: 1m 18s\tremaining: 2m 2s\n",
      "790:\ttest: 0.7380512\ttest1: 0.7297357\tbest: 0.7299825 (785)\ttotal: 1m 19s\tremaining: 2m 1s\n",
      "800:\ttest: 0.7383285\ttest1: 0.7297170\tbest: 0.7299825 (785)\ttotal: 1m 20s\tremaining: 1m 59s\n",
      "810:\ttest: 0.7385071\ttest1: 0.7297445\tbest: 0.7299825 (785)\ttotal: 1m 20s\tremaining: 1m 58s\n",
      "820:\ttest: 0.7387739\ttest1: 0.7298995\tbest: 0.7299825 (785)\ttotal: 1m 21s\tremaining: 1m 57s\n",
      "830:\ttest: 0.7389965\ttest1: 0.7298716\tbest: 0.7299825 (785)\ttotal: 1m 22s\tremaining: 1m 56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7299825118\n",
      "bestIteration = 785\n",
      "\n",
      "Shrink model to first 786 iterations.\n",
      "Fold 3, Valid score = 0.72999\n",
      "0:\ttest: 0.6573217\ttest1: 0.6580999\tbest: 0.6580999 (0)\ttotal: 113ms\tremaining: 3m 45s\n",
      "10:\ttest: 0.7023566\ttest1: 0.7005952\tbest: 0.7005952 (10)\ttotal: 1.16s\tremaining: 3m 29s\n",
      "20:\ttest: 0.7063989\ttest1: 0.7033976\tbest: 0.7033976 (20)\ttotal: 2.2s\tremaining: 3m 27s\n",
      "30:\ttest: 0.7077686\ttest1: 0.7045898\tbest: 0.7048647 (25)\ttotal: 3.24s\tremaining: 3m 26s\n",
      "40:\ttest: 0.7089650\ttest1: 0.7049052\tbest: 0.7050581 (33)\ttotal: 4.24s\tremaining: 3m 22s\n",
      "50:\ttest: 0.7093678\ttest1: 0.7052295\tbest: 0.7052295 (50)\ttotal: 5.29s\tremaining: 3m 22s\n",
      "60:\ttest: 0.7091589\ttest1: 0.7044208\tbest: 0.7052295 (50)\ttotal: 6.33s\tremaining: 3m 21s\n",
      "70:\ttest: 0.7099171\ttest1: 0.7052124\tbest: 0.7052295 (50)\ttotal: 7.38s\tremaining: 3m 20s\n",
      "80:\ttest: 0.7105284\ttest1: 0.7053662\tbest: 0.7055553 (75)\ttotal: 8.43s\tremaining: 3m 19s\n",
      "90:\ttest: 0.7111164\ttest1: 0.7057485\tbest: 0.7060127 (88)\ttotal: 9.46s\tremaining: 3m 18s\n",
      "100:\ttest: 0.7113888\ttest1: 0.7057735\tbest: 0.7060127 (88)\ttotal: 10.5s\tremaining: 3m 16s\n",
      "110:\ttest: 0.7123408\ttest1: 0.7055978\tbest: 0.7060127 (88)\ttotal: 11.5s\tremaining: 3m 15s\n",
      "120:\ttest: 0.7128014\ttest1: 0.7061260\tbest: 0.7061260 (120)\ttotal: 12.6s\tremaining: 3m 15s\n",
      "130:\ttest: 0.7132835\ttest1: 0.7056935\tbest: 0.7061260 (120)\ttotal: 13.6s\tremaining: 3m 13s\n",
      "140:\ttest: 0.7137711\ttest1: 0.7059854\tbest: 0.7063963 (137)\ttotal: 14.6s\tremaining: 3m 13s\n",
      "150:\ttest: 0.7137883\ttest1: 0.7058228\tbest: 0.7063963 (137)\ttotal: 15.7s\tremaining: 3m 12s\n",
      "160:\ttest: 0.7145233\ttest1: 0.7062594\tbest: 0.7065452 (159)\ttotal: 16.7s\tremaining: 3m 11s\n",
      "170:\ttest: 0.7154737\ttest1: 0.7064568\tbest: 0.7069169 (169)\ttotal: 17.8s\tremaining: 3m 10s\n",
      "180:\ttest: 0.7161208\ttest1: 0.7074509\tbest: 0.7075414 (177)\ttotal: 18.8s\tremaining: 3m 9s\n",
      "190:\ttest: 0.7169542\ttest1: 0.7082626\tbest: 0.7082626 (190)\ttotal: 19.8s\tremaining: 3m 7s\n",
      "200:\ttest: 0.7176999\ttest1: 0.7085971\tbest: 0.7086065 (198)\ttotal: 20.8s\tremaining: 3m 6s\n",
      "210:\ttest: 0.7184388\ttest1: 0.7085024\tbest: 0.7086065 (198)\ttotal: 21.9s\tremaining: 3m 5s\n",
      "220:\ttest: 0.7188438\ttest1: 0.7085304\tbest: 0.7086065 (198)\ttotal: 22.9s\tremaining: 3m 3s\n",
      "230:\ttest: 0.7194945\ttest1: 0.7090919\tbest: 0.7091109 (227)\ttotal: 23.9s\tremaining: 3m 2s\n",
      "240:\ttest: 0.7200520\ttest1: 0.7092569\tbest: 0.7093088 (238)\ttotal: 24.9s\tremaining: 3m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250:\ttest: 0.7205258\ttest1: 0.7090452\tbest: 0.7093088 (238)\ttotal: 26s\tremaining: 3m 1s\n",
      "260:\ttest: 0.7211952\ttest1: 0.7094150\tbest: 0.7094454 (258)\ttotal: 27.1s\tremaining: 3m\n",
      "270:\ttest: 0.7217562\ttest1: 0.7098355\tbest: 0.7098355 (270)\ttotal: 28.2s\tremaining: 2m 59s\n",
      "280:\ttest: 0.7224329\ttest1: 0.7102272\tbest: 0.7102272 (280)\ttotal: 29.2s\tremaining: 2m 58s\n",
      "290:\ttest: 0.7230225\ttest1: 0.7106736\tbest: 0.7107217 (289)\ttotal: 30.1s\tremaining: 2m 56s\n",
      "300:\ttest: 0.7236039\ttest1: 0.7109276\tbest: 0.7110676 (292)\ttotal: 31.1s\tremaining: 2m 55s\n",
      "310:\ttest: 0.7241218\ttest1: 0.7112946\tbest: 0.7114504 (309)\ttotal: 32.2s\tremaining: 2m 54s\n",
      "320:\ttest: 0.7245276\ttest1: 0.7117339\tbest: 0.7117339 (320)\ttotal: 33.2s\tremaining: 2m 53s\n",
      "330:\ttest: 0.7249405\ttest1: 0.7118951\tbest: 0.7118951 (330)\ttotal: 34.2s\tremaining: 2m 52s\n",
      "340:\ttest: 0.7255719\ttest1: 0.7123632\tbest: 0.7123632 (340)\ttotal: 35.2s\tremaining: 2m 51s\n",
      "350:\ttest: 0.7260102\ttest1: 0.7125803\tbest: 0.7127009 (347)\ttotal: 36.2s\tremaining: 2m 50s\n",
      "360:\ttest: 0.7265095\ttest1: 0.7128512\tbest: 0.7128512 (360)\ttotal: 37.2s\tremaining: 2m 48s\n",
      "370:\ttest: 0.7271592\ttest1: 0.7128640\tbest: 0.7129598 (367)\ttotal: 38.2s\tremaining: 2m 47s\n",
      "380:\ttest: 0.7275709\ttest1: 0.7131303\tbest: 0.7132514 (379)\ttotal: 39.2s\tremaining: 2m 46s\n",
      "390:\ttest: 0.7282129\ttest1: 0.7132440\tbest: 0.7133435 (387)\ttotal: 40.3s\tremaining: 2m 45s\n",
      "400:\ttest: 0.7288168\ttest1: 0.7136196\tbest: 0.7136196 (400)\ttotal: 41.4s\tremaining: 2m 44s\n",
      "410:\ttest: 0.7292111\ttest1: 0.7138783\tbest: 0.7139004 (408)\ttotal: 42.4s\tremaining: 2m 43s\n",
      "420:\ttest: 0.7296840\ttest1: 0.7142707\tbest: 0.7142731 (419)\ttotal: 43.4s\tremaining: 2m 42s\n",
      "430:\ttest: 0.7300291\ttest1: 0.7143098\tbest: 0.7143773 (428)\ttotal: 44.4s\tremaining: 2m 41s\n",
      "440:\ttest: 0.7302431\ttest1: 0.7145689\tbest: 0.7145761 (438)\ttotal: 45.4s\tremaining: 2m 40s\n",
      "450:\ttest: 0.7304778\ttest1: 0.7147586\tbest: 0.7147586 (450)\ttotal: 46.3s\tremaining: 2m 39s\n",
      "460:\ttest: 0.7309633\ttest1: 0.7149487\tbest: 0.7149487 (460)\ttotal: 47.3s\tremaining: 2m 37s\n",
      "470:\ttest: 0.7314212\ttest1: 0.7150973\tbest: 0.7151766 (469)\ttotal: 48.3s\tremaining: 2m 36s\n",
      "480:\ttest: 0.7318350\ttest1: 0.7152567\tbest: 0.7154430 (477)\ttotal: 49.4s\tremaining: 2m 35s\n",
      "490:\ttest: 0.7320549\ttest1: 0.7157591\tbest: 0.7157591 (490)\ttotal: 50.3s\tremaining: 2m 34s\n",
      "500:\ttest: 0.7324143\ttest1: 0.7158293\tbest: 0.7160056 (498)\ttotal: 51.4s\tremaining: 2m 33s\n",
      "510:\ttest: 0.7328522\ttest1: 0.7158224\tbest: 0.7160605 (505)\ttotal: 52.4s\tremaining: 2m 32s\n",
      "520:\ttest: 0.7330508\ttest1: 0.7159549\tbest: 0.7160701 (516)\ttotal: 53.4s\tremaining: 2m 31s\n",
      "530:\ttest: 0.7333461\ttest1: 0.7160879\tbest: 0.7161744 (527)\ttotal: 54.3s\tremaining: 2m 30s\n",
      "540:\ttest: 0.7337099\ttest1: 0.7161708\tbest: 0.7163584 (538)\ttotal: 55.3s\tremaining: 2m 29s\n",
      "550:\ttest: 0.7340209\ttest1: 0.7164498\tbest: 0.7165191 (546)\ttotal: 56.2s\tremaining: 2m 27s\n",
      "560:\ttest: 0.7344352\ttest1: 0.7167794\tbest: 0.7167794 (560)\ttotal: 57.2s\tremaining: 2m 26s\n",
      "570:\ttest: 0.7346916\ttest1: 0.7170151\tbest: 0.7170306 (569)\ttotal: 58.1s\tremaining: 2m 25s\n",
      "580:\ttest: 0.7350340\ttest1: 0.7170724\tbest: 0.7172800 (576)\ttotal: 59.1s\tremaining: 2m 24s\n",
      "590:\ttest: 0.7352320\ttest1: 0.7171787\tbest: 0.7172800 (576)\ttotal: 1m\tremaining: 2m 23s\n",
      "600:\ttest: 0.7355126\ttest1: 0.7174615\tbest: 0.7174638 (599)\ttotal: 1m 1s\tremaining: 2m 22s\n",
      "610:\ttest: 0.7359226\ttest1: 0.7176298\tbest: 0.7176298 (610)\ttotal: 1m 1s\tremaining: 2m 20s\n",
      "620:\ttest: 0.7360795\ttest1: 0.7176281\tbest: 0.7177066 (614)\ttotal: 1m 2s\tremaining: 2m 19s\n",
      "630:\ttest: 0.7363092\ttest1: 0.7176779\tbest: 0.7177066 (614)\ttotal: 1m 3s\tremaining: 2m 18s\n",
      "640:\ttest: 0.7366108\ttest1: 0.7178586\tbest: 0.7179756 (636)\ttotal: 1m 4s\tremaining: 2m 17s\n",
      "650:\ttest: 0.7368732\ttest1: 0.7180732\tbest: 0.7180732 (650)\ttotal: 1m 5s\tremaining: 2m 16s\n",
      "660:\ttest: 0.7369743\ttest1: 0.7180869\tbest: 0.7183094 (658)\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "670:\ttest: 0.7372236\ttest1: 0.7184888\tbest: 0.7185410 (669)\ttotal: 1m 7s\tremaining: 2m 14s\n",
      "680:\ttest: 0.7375955\ttest1: 0.7188943\tbest: 0.7189860 (679)\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "690:\ttest: 0.7378618\ttest1: 0.7189090\tbest: 0.7190986 (689)\ttotal: 1m 9s\tremaining: 2m 12s\n",
      "700:\ttest: 0.7381364\ttest1: 0.7189914\tbest: 0.7191103 (699)\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "710:\ttest: 0.7385371\ttest1: 0.7191121\tbest: 0.7192201 (709)\ttotal: 1m 11s\tremaining: 2m 9s\n",
      "720:\ttest: 0.7387763\ttest1: 0.7190963\tbest: 0.7194055 (716)\ttotal: 1m 12s\tremaining: 2m 8s\n",
      "730:\ttest: 0.7390345\ttest1: 0.7192508\tbest: 0.7194055 (716)\ttotal: 1m 13s\tremaining: 2m 7s\n",
      "740:\ttest: 0.7392857\ttest1: 0.7192702\tbest: 0.7194055 (716)\ttotal: 1m 14s\tremaining: 2m 6s\n",
      "750:\ttest: 0.7394839\ttest1: 0.7194544\tbest: 0.7195024 (748)\ttotal: 1m 15s\tremaining: 2m 5s\n",
      "760:\ttest: 0.7397890\ttest1: 0.7196983\tbest: 0.7197294 (757)\ttotal: 1m 16s\tremaining: 2m 4s\n",
      "770:\ttest: 0.7399422\ttest1: 0.7198487\tbest: 0.7198487 (770)\ttotal: 1m 17s\tremaining: 2m 3s\n",
      "780:\ttest: 0.7402014\ttest1: 0.7197652\tbest: 0.7198487 (770)\ttotal: 1m 18s\tremaining: 2m 2s\n",
      "790:\ttest: 0.7404250\ttest1: 0.7198285\tbest: 0.7198487 (770)\ttotal: 1m 19s\tremaining: 2m 1s\n",
      "800:\ttest: 0.7405385\ttest1: 0.7198020\tbest: 0.7199265 (791)\ttotal: 1m 20s\tremaining: 2m\n",
      "810:\ttest: 0.7408445\ttest1: 0.7199397\tbest: 0.7199397 (810)\ttotal: 1m 21s\tremaining: 1m 59s\n",
      "820:\ttest: 0.7411585\ttest1: 0.7199706\tbest: 0.7199799 (819)\ttotal: 1m 22s\tremaining: 1m 58s\n",
      "830:\ttest: 0.7413639\ttest1: 0.7201025\tbest: 0.7201025 (830)\ttotal: 1m 23s\tremaining: 1m 57s\n",
      "840:\ttest: 0.7415693\ttest1: 0.7201815\tbest: 0.7201943 (839)\ttotal: 1m 24s\tremaining: 1m 56s\n",
      "850:\ttest: 0.7417378\ttest1: 0.7201442\tbest: 0.7202027 (844)\ttotal: 1m 25s\tremaining: 1m 55s\n",
      "860:\ttest: 0.7419210\ttest1: 0.7202736\tbest: 0.7202920 (859)\ttotal: 1m 26s\tremaining: 1m 54s\n",
      "870:\ttest: 0.7421562\ttest1: 0.7202119\tbest: 0.7203187 (862)\ttotal: 1m 27s\tremaining: 1m 53s\n",
      "880:\ttest: 0.7423899\ttest1: 0.7202133\tbest: 0.7203187 (862)\ttotal: 1m 28s\tremaining: 1m 52s\n",
      "890:\ttest: 0.7425022\ttest1: 0.7204477\tbest: 0.7204477 (890)\ttotal: 1m 29s\tremaining: 1m 51s\n",
      "900:\ttest: 0.7426749\ttest1: 0.7203346\tbest: 0.7204771 (895)\ttotal: 1m 30s\tremaining: 1m 50s\n",
      "910:\ttest: 0.7429121\ttest1: 0.7204965\tbest: 0.7204965 (910)\ttotal: 1m 31s\tremaining: 1m 49s\n",
      "920:\ttest: 0.7430804\ttest1: 0.7204201\tbest: 0.7204965 (910)\ttotal: 1m 32s\tremaining: 1m 47s\n",
      "930:\ttest: 0.7432739\ttest1: 0.7204466\tbest: 0.7204965 (910)\ttotal: 1m 33s\tremaining: 1m 46s\n",
      "940:\ttest: 0.7434460\ttest1: 0.7204374\tbest: 0.7204965 (910)\ttotal: 1m 34s\tremaining: 1m 45s\n",
      "950:\ttest: 0.7436445\ttest1: 0.7204735\tbest: 0.7204965 (910)\ttotal: 1m 35s\tremaining: 1m 44s\n",
      "960:\ttest: 0.7438336\ttest1: 0.7204716\tbest: 0.7205722 (955)\ttotal: 1m 35s\tremaining: 1m 43s\n",
      "970:\ttest: 0.7441681\ttest1: 0.7206588\tbest: 0.7206588 (970)\ttotal: 1m 36s\tremaining: 1m 42s\n",
      "980:\ttest: 0.7442300\ttest1: 0.7207202\tbest: 0.7207358 (977)\ttotal: 1m 37s\tremaining: 1m 41s\n",
      "990:\ttest: 0.7444173\ttest1: 0.7208026\tbest: 0.7208026 (990)\ttotal: 1m 38s\tremaining: 1m 40s\n",
      "1000:\ttest: 0.7446543\ttest1: 0.7207631\tbest: 0.7208026 (990)\ttotal: 1m 39s\tremaining: 1m 39s\n",
      "1010:\ttest: 0.7448270\ttest1: 0.7208216\tbest: 0.7208216 (1010)\ttotal: 1m 40s\tremaining: 1m 38s\n",
      "1020:\ttest: 0.7449413\ttest1: 0.7208322\tbest: 0.7208354 (1014)\ttotal: 1m 41s\tremaining: 1m 37s\n",
      "1030:\ttest: 0.7450517\ttest1: 0.7207719\tbest: 0.7208659 (1025)\ttotal: 1m 42s\tremaining: 1m 36s\n",
      "1040:\ttest: 0.7453217\ttest1: 0.7207388\tbest: 0.7208659 (1025)\ttotal: 1m 43s\tremaining: 1m 35s\n",
      "1050:\ttest: 0.7455176\ttest1: 0.7207693\tbest: 0.7208659 (1025)\ttotal: 1m 44s\tremaining: 1m 34s\n",
      "1060:\ttest: 0.7455843\ttest1: 0.7208013\tbest: 0.7208659 (1025)\ttotal: 1m 45s\tremaining: 1m 33s\n",
      "1070:\ttest: 0.7458564\ttest1: 0.7209119\tbest: 0.7209711 (1065)\ttotal: 1m 46s\tremaining: 1m 32s\n",
      "1080:\ttest: 0.7460461\ttest1: 0.7209831\tbest: 0.7209831 (1080)\ttotal: 1m 47s\tremaining: 1m 31s\n",
      "1090:\ttest: 0.7463325\ttest1: 0.7209573\tbest: 0.7210023 (1087)\ttotal: 1m 48s\tremaining: 1m 30s\n",
      "1100:\ttest: 0.7464948\ttest1: 0.7210011\tbest: 0.7210023 (1087)\ttotal: 1m 49s\tremaining: 1m 29s\n",
      "1110:\ttest: 0.7466883\ttest1: 0.7210921\tbest: 0.7210921 (1110)\ttotal: 1m 50s\tremaining: 1m 28s\n",
      "1120:\ttest: 0.7468466\ttest1: 0.7211327\tbest: 0.7211475 (1118)\ttotal: 1m 51s\tremaining: 1m 27s\n",
      "1130:\ttest: 0.7472120\ttest1: 0.7212430\tbest: 0.7212544 (1129)\ttotal: 1m 52s\tremaining: 1m 26s\n",
      "1140:\ttest: 0.7474644\ttest1: 0.7211953\tbest: 0.7213218 (1136)\ttotal: 1m 53s\tremaining: 1m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150:\ttest: 0.7476175\ttest1: 0.7213730\tbest: 0.7213793 (1149)\ttotal: 1m 54s\tremaining: 1m 24s\n",
      "1160:\ttest: 0.7478340\ttest1: 0.7212903\tbest: 0.7213793 (1149)\ttotal: 1m 55s\tremaining: 1m 23s\n",
      "1170:\ttest: 0.7479798\ttest1: 0.7213998\tbest: 0.7214150 (1168)\ttotal: 1m 56s\tremaining: 1m 22s\n",
      "1180:\ttest: 0.7480866\ttest1: 0.7214179\tbest: 0.7214179 (1180)\ttotal: 1m 57s\tremaining: 1m 21s\n",
      "1190:\ttest: 0.7482241\ttest1: 0.7213467\tbest: 0.7215495 (1184)\ttotal: 1m 58s\tremaining: 1m 20s\n",
      "1200:\ttest: 0.7485157\ttest1: 0.7213675\tbest: 0.7215495 (1184)\ttotal: 1m 59s\tremaining: 1m 19s\n",
      "1210:\ttest: 0.7486463\ttest1: 0.7213554\tbest: 0.7215495 (1184)\ttotal: 2m\tremaining: 1m 18s\n",
      "1220:\ttest: 0.7488918\ttest1: 0.7213513\tbest: 0.7215495 (1184)\ttotal: 2m 1s\tremaining: 1m 17s\n",
      "1230:\ttest: 0.7490701\ttest1: 0.7214572\tbest: 0.7215495 (1184)\ttotal: 2m 2s\tremaining: 1m 16s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7215494853\n",
      "bestIteration = 1184\n",
      "\n",
      "Shrink model to first 1185 iterations.\n",
      "Fold 4, Valid score = 0.72155\n",
      "0:\ttest: 0.6586125\ttest1: 0.6529867\tbest: 0.6529867 (0)\ttotal: 116ms\tremaining: 3m 50s\n",
      "10:\ttest: 0.7027386\ttest1: 0.7012382\tbest: 0.7012382 (10)\ttotal: 1.16s\tremaining: 3m 28s\n",
      "20:\ttest: 0.7064282\ttest1: 0.7053068\tbest: 0.7054341 (19)\ttotal: 2.19s\tremaining: 3m 26s\n",
      "30:\ttest: 0.7079968\ttest1: 0.7054703\tbest: 0.7057276 (21)\ttotal: 3.24s\tremaining: 3m 25s\n",
      "40:\ttest: 0.7080088\ttest1: 0.7058867\tbest: 0.7058867 (40)\ttotal: 4.27s\tremaining: 3m 23s\n",
      "50:\ttest: 0.7081481\ttest1: 0.7049770\tbest: 0.7058867 (40)\ttotal: 5.34s\tremaining: 3m 24s\n",
      "60:\ttest: 0.7084777\ttest1: 0.7055965\tbest: 0.7058867 (40)\ttotal: 6.41s\tremaining: 3m 23s\n",
      "70:\ttest: 0.7091508\ttest1: 0.7062349\tbest: 0.7064577 (64)\ttotal: 7.43s\tremaining: 3m 21s\n",
      "80:\ttest: 0.7092932\ttest1: 0.7068407\tbest: 0.7068504 (78)\ttotal: 8.46s\tremaining: 3m 20s\n",
      "90:\ttest: 0.7101593\ttest1: 0.7070081\tbest: 0.7073790 (85)\ttotal: 9.5s\tremaining: 3m 19s\n",
      "100:\ttest: 0.7103357\ttest1: 0.7067539\tbest: 0.7073790 (85)\ttotal: 10.6s\tremaining: 3m 18s\n",
      "110:\ttest: 0.7106039\ttest1: 0.7068742\tbest: 0.7073790 (85)\ttotal: 11.6s\tremaining: 3m 17s\n",
      "120:\ttest: 0.7111959\ttest1: 0.7073775\tbest: 0.7074239 (117)\ttotal: 12.6s\tremaining: 3m 16s\n",
      "130:\ttest: 0.7116965\ttest1: 0.7078743\tbest: 0.7078743 (130)\ttotal: 13.7s\tremaining: 3m 14s\n",
      "140:\ttest: 0.7120956\ttest1: 0.7082923\tbest: 0.7082923 (140)\ttotal: 14.7s\tremaining: 3m 14s\n",
      "150:\ttest: 0.7130043\ttest1: 0.7086099\tbest: 0.7086513 (149)\ttotal: 15.8s\tremaining: 3m 13s\n",
      "160:\ttest: 0.7136241\ttest1: 0.7089472\tbest: 0.7089472 (160)\ttotal: 16.8s\tremaining: 3m 12s\n",
      "170:\ttest: 0.7142857\ttest1: 0.7097210\tbest: 0.7097834 (169)\ttotal: 17.9s\tremaining: 3m 10s\n",
      "180:\ttest: 0.7145830\ttest1: 0.7097748\tbest: 0.7097834 (169)\ttotal: 18.9s\tremaining: 3m 10s\n",
      "190:\ttest: 0.7155444\ttest1: 0.7102284\tbest: 0.7102284 (190)\ttotal: 19.9s\tremaining: 3m 8s\n",
      "200:\ttest: 0.7159736\ttest1: 0.7101383\tbest: 0.7102284 (190)\ttotal: 20.9s\tremaining: 3m 7s\n",
      "210:\ttest: 0.7165866\ttest1: 0.7107116\tbest: 0.7107729 (209)\ttotal: 21.9s\tremaining: 3m 5s\n",
      "220:\ttest: 0.7170589\ttest1: 0.7111545\tbest: 0.7111545 (219)\ttotal: 22.8s\tremaining: 3m 3s\n",
      "230:\ttest: 0.7177040\ttest1: 0.7119791\tbest: 0.7119791 (230)\ttotal: 23.8s\tremaining: 3m 2s\n",
      "240:\ttest: 0.7183580\ttest1: 0.7126206\tbest: 0.7126206 (240)\ttotal: 24.8s\tremaining: 3m 1s\n",
      "250:\ttest: 0.7187798\ttest1: 0.7129755\tbest: 0.7129755 (250)\ttotal: 25.9s\tremaining: 3m\n",
      "260:\ttest: 0.7194550\ttest1: 0.7136682\tbest: 0.7136682 (260)\ttotal: 26.9s\tremaining: 2m 59s\n",
      "270:\ttest: 0.7201450\ttest1: 0.7142377\tbest: 0.7143312 (268)\ttotal: 27.9s\tremaining: 2m 58s\n",
      "280:\ttest: 0.7206338\ttest1: 0.7144841\tbest: 0.7144841 (280)\ttotal: 28.9s\tremaining: 2m 57s\n",
      "290:\ttest: 0.7212907\ttest1: 0.7151145\tbest: 0.7151145 (290)\ttotal: 29.9s\tremaining: 2m 55s\n",
      "300:\ttest: 0.7219761\ttest1: 0.7152641\tbest: 0.7153163 (297)\ttotal: 30.9s\tremaining: 2m 54s\n",
      "310:\ttest: 0.7222182\ttest1: 0.7155316\tbest: 0.7155316 (310)\ttotal: 31.8s\tremaining: 2m 52s\n",
      "320:\ttest: 0.7228345\ttest1: 0.7162248\tbest: 0.7163479 (319)\ttotal: 32.8s\tremaining: 2m 51s\n",
      "330:\ttest: 0.7232027\ttest1: 0.7165813\tbest: 0.7165813 (330)\ttotal: 33.9s\tremaining: 2m 50s\n",
      "340:\ttest: 0.7238114\ttest1: 0.7170770\tbest: 0.7170770 (340)\ttotal: 34.9s\tremaining: 2m 49s\n",
      "350:\ttest: 0.7241123\ttest1: 0.7174981\tbest: 0.7174981 (350)\ttotal: 35.9s\tremaining: 2m 48s\n",
      "360:\ttest: 0.7245825\ttest1: 0.7177581\tbest: 0.7177874 (359)\ttotal: 36.9s\tremaining: 2m 47s\n",
      "370:\ttest: 0.7252198\ttest1: 0.7182279\tbest: 0.7182279 (370)\ttotal: 37.9s\tremaining: 2m 46s\n",
      "380:\ttest: 0.7256558\ttest1: 0.7182969\tbest: 0.7182969 (380)\ttotal: 38.9s\tremaining: 2m 45s\n",
      "390:\ttest: 0.7262384\ttest1: 0.7186552\tbest: 0.7186552 (390)\ttotal: 39.8s\tremaining: 2m 43s\n",
      "400:\ttest: 0.7266878\ttest1: 0.7191505\tbest: 0.7191505 (400)\ttotal: 40.8s\tremaining: 2m 42s\n",
      "410:\ttest: 0.7272268\ttest1: 0.7193283\tbest: 0.7193283 (410)\ttotal: 41.8s\tremaining: 2m 41s\n",
      "420:\ttest: 0.7278787\ttest1: 0.7194945\tbest: 0.7194945 (420)\ttotal: 42.8s\tremaining: 2m 40s\n",
      "430:\ttest: 0.7283131\ttest1: 0.7196742\tbest: 0.7196742 (430)\ttotal: 43.8s\tremaining: 2m 39s\n",
      "440:\ttest: 0.7288764\ttest1: 0.7199345\tbest: 0.7199345 (440)\ttotal: 44.8s\tremaining: 2m 38s\n",
      "450:\ttest: 0.7293090\ttest1: 0.7203680\tbest: 0.7203883 (449)\ttotal: 45.8s\tremaining: 2m 37s\n",
      "460:\ttest: 0.7296419\ttest1: 0.7205766\tbest: 0.7205868 (459)\ttotal: 46.8s\tremaining: 2m 36s\n",
      "470:\ttest: 0.7299984\ttest1: 0.7206430\tbest: 0.7206723 (469)\ttotal: 47.9s\tremaining: 2m 35s\n",
      "480:\ttest: 0.7303642\ttest1: 0.7209294\tbest: 0.7209294 (480)\ttotal: 49s\tremaining: 2m 34s\n",
      "490:\ttest: 0.7307467\ttest1: 0.7211072\tbest: 0.7211072 (490)\ttotal: 50s\tremaining: 2m 33s\n",
      "500:\ttest: 0.7310360\ttest1: 0.7212260\tbest: 0.7212260 (500)\ttotal: 51s\tremaining: 2m 32s\n",
      "510:\ttest: 0.7314952\ttest1: 0.7213905\tbest: 0.7213975 (509)\ttotal: 52s\tremaining: 2m 31s\n",
      "520:\ttest: 0.7317011\ttest1: 0.7213869\tbest: 0.7214085 (518)\ttotal: 53s\tremaining: 2m 30s\n",
      "530:\ttest: 0.7319705\ttest1: 0.7214804\tbest: 0.7214944 (527)\ttotal: 54s\tremaining: 2m 29s\n",
      "540:\ttest: 0.7323522\ttest1: 0.7215934\tbest: 0.7216683 (539)\ttotal: 55s\tremaining: 2m 28s\n",
      "550:\ttest: 0.7327117\ttest1: 0.7216864\tbest: 0.7216874 (548)\ttotal: 56s\tremaining: 2m 27s\n",
      "560:\ttest: 0.7331275\ttest1: 0.7217753\tbest: 0.7217904 (559)\ttotal: 56.9s\tremaining: 2m 25s\n",
      "570:\ttest: 0.7333668\ttest1: 0.7218103\tbest: 0.7218439 (563)\ttotal: 57.9s\tremaining: 2m 24s\n",
      "580:\ttest: 0.7335103\ttest1: 0.7217274\tbest: 0.7218439 (563)\ttotal: 58.9s\tremaining: 2m 23s\n",
      "590:\ttest: 0.7338644\ttest1: 0.7218720\tbest: 0.7219292 (585)\ttotal: 59.9s\tremaining: 2m 22s\n",
      "600:\ttest: 0.7341157\ttest1: 0.7220214\tbest: 0.7220214 (600)\ttotal: 1m\tremaining: 2m 21s\n",
      "610:\ttest: 0.7343540\ttest1: 0.7221283\tbest: 0.7222220 (609)\ttotal: 1m 1s\tremaining: 2m 20s\n",
      "620:\ttest: 0.7347805\ttest1: 0.7224172\tbest: 0.7224172 (620)\ttotal: 1m 2s\tremaining: 2m 19s\n",
      "630:\ttest: 0.7351175\ttest1: 0.7223595\tbest: 0.7224172 (620)\ttotal: 1m 3s\tremaining: 2m 18s\n",
      "640:\ttest: 0.7352893\ttest1: 0.7225386\tbest: 0.7225386 (640)\ttotal: 1m 4s\tremaining: 2m 17s\n",
      "650:\ttest: 0.7358001\ttest1: 0.7227210\tbest: 0.7227795 (644)\ttotal: 1m 5s\tremaining: 2m 16s\n",
      "660:\ttest: 0.7360701\ttest1: 0.7227309\tbest: 0.7228317 (656)\ttotal: 1m 6s\tremaining: 2m 15s\n",
      "670:\ttest: 0.7362331\ttest1: 0.7226827\tbest: 0.7229283 (665)\ttotal: 1m 7s\tremaining: 2m 14s\n",
      "680:\ttest: 0.7364120\ttest1: 0.7228401\tbest: 0.7229283 (665)\ttotal: 1m 8s\tremaining: 2m 13s\n",
      "690:\ttest: 0.7366460\ttest1: 0.7230162\tbest: 0.7230972 (683)\ttotal: 1m 9s\tremaining: 2m 12s\n",
      "700:\ttest: 0.7369845\ttest1: 0.7231900\tbest: 0.7231900 (700)\ttotal: 1m 10s\tremaining: 2m 11s\n",
      "710:\ttest: 0.7371297\ttest1: 0.7232468\tbest: 0.7232468 (710)\ttotal: 1m 12s\tremaining: 2m 10s\n",
      "720:\ttest: 0.7374031\ttest1: 0.7232478\tbest: 0.7232661 (711)\ttotal: 1m 12s\tremaining: 2m 9s\n",
      "730:\ttest: 0.7377033\ttest1: 0.7233457\tbest: 0.7233578 (729)\ttotal: 1m 14s\tremaining: 2m 8s\n",
      "740:\ttest: 0.7379341\ttest1: 0.7233476\tbest: 0.7234837 (737)\ttotal: 1m 14s\tremaining: 2m 7s\n",
      "750:\ttest: 0.7380989\ttest1: 0.7235060\tbest: 0.7235158 (748)\ttotal: 1m 16s\tremaining: 2m 6s\n",
      "760:\ttest: 0.7384387\ttest1: 0.7236478\tbest: 0.7236688 (756)\ttotal: 1m 17s\tremaining: 2m 5s\n",
      "770:\ttest: 0.7386128\ttest1: 0.7236979\tbest: 0.7237225 (769)\ttotal: 1m 18s\tremaining: 2m 4s\n",
      "780:\ttest: 0.7388421\ttest1: 0.7238086\tbest: 0.7238894 (776)\ttotal: 1m 19s\tremaining: 2m 3s\n",
      "790:\ttest: 0.7390250\ttest1: 0.7236963\tbest: 0.7238894 (776)\ttotal: 1m 20s\tremaining: 2m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800:\ttest: 0.7393180\ttest1: 0.7236731\tbest: 0.7238894 (776)\ttotal: 1m 21s\tremaining: 2m 1s\n",
      "810:\ttest: 0.7397406\ttest1: 0.7237608\tbest: 0.7238894 (776)\ttotal: 1m 22s\tremaining: 2m\n",
      "820:\ttest: 0.7400769\ttest1: 0.7240972\tbest: 0.7240972 (820)\ttotal: 1m 23s\tremaining: 1m 59s\n",
      "830:\ttest: 0.7401985\ttest1: 0.7240538\tbest: 0.7241155 (821)\ttotal: 1m 24s\tremaining: 1m 58s\n",
      "840:\ttest: 0.7403660\ttest1: 0.7241150\tbest: 0.7241158 (839)\ttotal: 1m 25s\tremaining: 1m 57s\n",
      "850:\ttest: 0.7405366\ttest1: 0.7241955\tbest: 0.7242106 (847)\ttotal: 1m 26s\tremaining: 1m 56s\n",
      "860:\ttest: 0.7407310\ttest1: 0.7240821\tbest: 0.7242293 (854)\ttotal: 1m 27s\tremaining: 1m 55s\n",
      "870:\ttest: 0.7409686\ttest1: 0.7239965\tbest: 0.7242293 (854)\ttotal: 1m 28s\tremaining: 1m 54s\n",
      "880:\ttest: 0.7412699\ttest1: 0.7241222\tbest: 0.7242293 (854)\ttotal: 1m 29s\tremaining: 1m 53s\n",
      "890:\ttest: 0.7414287\ttest1: 0.7240674\tbest: 0.7242293 (854)\ttotal: 1m 30s\tremaining: 1m 52s\n",
      "900:\ttest: 0.7416672\ttest1: 0.7241307\tbest: 0.7242531 (898)\ttotal: 1m 31s\tremaining: 1m 51s\n",
      "910:\ttest: 0.7419715\ttest1: 0.7242128\tbest: 0.7242531 (898)\ttotal: 1m 32s\tremaining: 1m 50s\n",
      "920:\ttest: 0.7422154\ttest1: 0.7241995\tbest: 0.7242531 (898)\ttotal: 1m 33s\tremaining: 1m 49s\n",
      "930:\ttest: 0.7424042\ttest1: 0.7242195\tbest: 0.7242531 (898)\ttotal: 1m 34s\tremaining: 1m 48s\n",
      "940:\ttest: 0.7425616\ttest1: 0.7241381\tbest: 0.7242531 (898)\ttotal: 1m 35s\tremaining: 1m 47s\n",
      "950:\ttest: 0.7428547\ttest1: 0.7242777\tbest: 0.7243073 (949)\ttotal: 1m 36s\tremaining: 1m 46s\n",
      "960:\ttest: 0.7430520\ttest1: 0.7242991\tbest: 0.7243354 (952)\ttotal: 1m 37s\tremaining: 1m 45s\n",
      "970:\ttest: 0.7433726\ttest1: 0.7242275\tbest: 0.7243383 (965)\ttotal: 1m 38s\tremaining: 1m 44s\n",
      "980:\ttest: 0.7435985\ttest1: 0.7244519\tbest: 0.7244519 (980)\ttotal: 1m 39s\tremaining: 1m 43s\n",
      "990:\ttest: 0.7438396\ttest1: 0.7245988\tbest: 0.7246029 (987)\ttotal: 1m 40s\tremaining: 1m 42s\n",
      "1000:\ttest: 0.7440238\ttest1: 0.7245792\tbest: 0.7246351 (999)\ttotal: 1m 41s\tremaining: 1m 41s\n",
      "1010:\ttest: 0.7441484\ttest1: 0.7246538\tbest: 0.7246538 (1010)\ttotal: 1m 42s\tremaining: 1m 40s\n",
      "1020:\ttest: 0.7442537\ttest1: 0.7245303\tbest: 0.7247922 (1016)\ttotal: 1m 43s\tremaining: 1m 39s\n",
      "1030:\ttest: 0.7444438\ttest1: 0.7246783\tbest: 0.7247922 (1016)\ttotal: 1m 44s\tremaining: 1m 38s\n",
      "1040:\ttest: 0.7445621\ttest1: 0.7248156\tbest: 0.7248229 (1033)\ttotal: 1m 45s\tremaining: 1m 37s\n",
      "1050:\ttest: 0.7448269\ttest1: 0.7247370\tbest: 0.7248229 (1033)\ttotal: 1m 46s\tremaining: 1m 36s\n",
      "1060:\ttest: 0.7451507\ttest1: 0.7248299\tbest: 0.7249234 (1057)\ttotal: 1m 47s\tremaining: 1m 35s\n",
      "1070:\ttest: 0.7453000\ttest1: 0.7249367\tbest: 0.7250246 (1069)\ttotal: 1m 48s\tremaining: 1m 34s\n",
      "1080:\ttest: 0.7455720\ttest1: 0.7249906\tbest: 0.7250748 (1079)\ttotal: 1m 49s\tremaining: 1m 33s\n",
      "1090:\ttest: 0.7457237\ttest1: 0.7250102\tbest: 0.7250748 (1079)\ttotal: 1m 50s\tremaining: 1m 32s\n",
      "1100:\ttest: 0.7459833\ttest1: 0.7248925\tbest: 0.7251397 (1091)\ttotal: 1m 51s\tremaining: 1m 31s\n",
      "1110:\ttest: 0.7460582\ttest1: 0.7248530\tbest: 0.7251397 (1091)\ttotal: 1m 52s\tremaining: 1m 30s\n",
      "1120:\ttest: 0.7462865\ttest1: 0.7250106\tbest: 0.7251397 (1091)\ttotal: 1m 54s\tremaining: 1m 29s\n",
      "1130:\ttest: 0.7464100\ttest1: 0.7250172\tbest: 0.7251397 (1091)\ttotal: 1m 55s\tremaining: 1m 28s\n",
      "1140:\ttest: 0.7466523\ttest1: 0.7251355\tbest: 0.7251397 (1091)\ttotal: 1m 56s\tremaining: 1m 27s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7251396814\n",
      "bestIteration = 1091\n",
      "\n",
      "Shrink model to first 1092 iterations.\n",
      "Fold 5, Valid score = 0.72514\n",
      "Score by each fold: [0.72068, 0.72638, 0.72999, 0.72155, 0.72514]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "cb_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"verbose\": 10,\n",
    "    \"max_depth\": 6,\n",
    "    \"l2_leaf_reg\": 10,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 6,\n",
    "    \"random_seed\": 42\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1234123, shuffle=True)\n",
    "\n",
    "estimators, oof_preds = catboost_cross_validation(\n",
    "    params=cb_params, X=train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72378\n"
     ]
    }
   ],
   "source": [
    "oof_preds_cb = oof_preds\n",
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_cb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оценить корреляцию прогнозов на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.05072209, 0.0828137 , 0.07258419, ..., 0.08374355, 0.01698941,\n",
       "        0.08168347]),\n",
       " array([0.02397243, 0.08568921, 0.06078126, ..., 0.08364594, 0.03411563,\n",
       "        0.06130429])]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = []\n",
    "oof_train.append(oof_preds_lgb)\n",
    "oof_train.append(oof_preds_cb)\n",
    "#oof_train = np.array(oof_train)\n",
    "oof_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применить модели на тестовую выборку и оценить корреляцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test[numerical]\n",
    "y_pred_cb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "test[categorial] = test[categorial].astype(str)\n",
    "\n",
    "for estimator in estimators:\n",
    "    y_pred_cb += estimator.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0579011 , 0.21880019, 0.19389816, ..., 0.08437272, 0.02094533,\n",
       "       0.05025549])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cb = y_pred_cb / cv.n_splits\n",
    "y_pred_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07099927, 0.30240174, 0.14171314, ..., 0.082115  , 0.02035166,\n",
       "        0.03268883],\n",
       "       [0.0579011 , 0.21880019, 0.19389816, ..., 0.08437272, 0.02094533,\n",
       "        0.05025549]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test = []\n",
    "oof_test.append(y_pred_lgb)\n",
    "oof_test.append(y_pred_cb)\n",
    "oof_test = np.array(oof_test)\n",
    "oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>110078</th>\n",
       "      <th>110079</th>\n",
       "      <th>110080</th>\n",
       "      <th>110081</th>\n",
       "      <th>110082</th>\n",
       "      <th>110083</th>\n",
       "      <th>110084</th>\n",
       "      <th>110085</th>\n",
       "      <th>110086</th>\n",
       "      <th>110087</th>\n",
       "      <th>110088</th>\n",
       "      <th>110089</th>\n",
       "      <th>110090</th>\n",
       "      <th>110091</th>\n",
       "      <th>110092</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050722</td>\n",
       "      <td>0.082814</td>\n",
       "      <td>0.072584</td>\n",
       "      <td>0.143022</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.207038</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>0.046242</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>0.069975</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>0.034073</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>0.187914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063456</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.050759</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.083016</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.081329</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.066289</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.016989</td>\n",
       "      <td>0.081683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.060781</td>\n",
       "      <td>0.202907</td>\n",
       "      <td>0.082412</td>\n",
       "      <td>0.157971</td>\n",
       "      <td>0.036464</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>0.108352</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>0.083646</td>\n",
       "      <td>0.066941</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.107796</td>\n",
       "      <td>0.246632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>0.099185</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.040882</td>\n",
       "      <td>0.082412</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.063469</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.083646</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>0.061304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 110093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.050722  0.082814  0.072584  0.143022  0.083744  0.207038  0.011906   \n",
       "1  0.023972  0.085689  0.060781  0.202907  0.082412  0.157971  0.036464   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.046242  0.064347  0.069975  0.082045  0.024384  0.034073  0.095641   \n",
       "1  0.106675  0.108352  0.072403  0.083646  0.066941  0.021256  0.107796   \n",
       "\n",
       "     14      ...    110078    110079    110080    110081    110082    110083  \\\n",
       "0  0.187914  ...  0.063456  0.051148  0.025271  0.050759  0.011411  0.036821   \n",
       "1  0.246632  ...  0.066901  0.044671  0.066687  0.099185  0.019749  0.040882   \n",
       "\n",
       "     110084    110085    110086    110087    110088    110089    110090  \\\n",
       "0  0.081329  0.083016  0.081329  0.081329  0.083744  0.066289  0.083744   \n",
       "1  0.082412  0.085689  0.063469  0.084203  0.085914  0.054190  0.083646   \n",
       "\n",
       "     110091    110092  \n",
       "0  0.016989  0.081683  \n",
       "1  0.034116  0.061304  \n",
       "\n",
       "[2 rows x 110093 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_train)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001524957304519215"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606265476139571"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>165126</th>\n",
       "      <th>165127</th>\n",
       "      <th>165128</th>\n",
       "      <th>165129</th>\n",
       "      <th>165130</th>\n",
       "      <th>165131</th>\n",
       "      <th>165132</th>\n",
       "      <th>165133</th>\n",
       "      <th>165134</th>\n",
       "      <th>165135</th>\n",
       "      <th>165136</th>\n",
       "      <th>165137</th>\n",
       "      <th>165138</th>\n",
       "      <th>165139</th>\n",
       "      <th>165140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070999</td>\n",
       "      <td>0.302402</td>\n",
       "      <td>0.141713</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.020860</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.105363</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.018398</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.030792</td>\n",
       "      <td>0.096948</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.053758</td>\n",
       "      <td>0.082115</td>\n",
       "      <td>0.020352</td>\n",
       "      <td>0.032689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.193898</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.121554</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.032082</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.053428</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.104590</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>0.093394</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.045271</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.050255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.070999  0.302402  0.141713  0.082115  0.020860  0.017728  0.082115   \n",
       "1  0.057901  0.218800  0.193898  0.084373  0.021954  0.027600  0.062838   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.105363  0.002564  0.018398  0.082115  0.043093  0.030792  0.096948   \n",
       "1  0.121554  0.013626  0.032082  0.084373  0.053428  0.041428  0.104590   \n",
       "\n",
       "     14      ...    165126    165127    165128    165129    165130    165131  \\\n",
       "0  0.018875  ...  0.022888  0.069734  0.008201  0.007681  0.004247  0.082115   \n",
       "1  0.035006  ...  0.027869  0.093394  0.012650  0.021012  0.011818  0.084373   \n",
       "\n",
       "     165132    165133    165134    165135    165136    165137    165138  \\\n",
       "0  0.082115  0.082115  0.006500  0.082115  0.082115  0.053758  0.082115   \n",
       "1  0.084373  0.084373  0.010979  0.084373  0.084373  0.045271  0.084373   \n",
       "\n",
       "     165139    165140  \n",
       "0  0.020352  0.032689  \n",
       "1  0.020945  0.050255  \n",
       "\n",
       "[2 rows x 165141 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_test)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0013118593506077378"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_test[0] - oof_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_arifm = (oof_preds_lgb + oof_preds_cb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_geom = (oof_preds_lgb * oof_preds_cb) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72378\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_arifm\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.7243\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_geom\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего с геперпараметрами из коробки работает catBoost. Он показал результат 72%. LightGBM занял 2 место и показал результат 71%, но зато модель обучалась значительно быстрее. XGBoost показал плохой результат, но возможно требуется тюнинг гиперпараметров. Ансамбль моделей catBoost и lgb не привел к улучшению результата. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
