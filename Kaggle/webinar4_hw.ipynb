{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Считывание данных и вывод основной информации о наборе данных.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path: str\n",
    "        Название файла.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data: pandas.core.frame.DataFrame\n",
    "        Загруженный набор данных в pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    base_path = \"geekbrains-competitive-data-analysis\"\n",
    "    data = pd.read_csv(f\"{base_path}/{data_path}\")\n",
    "    data.columns = [col.lower() for col in data.columns]\n",
    "    print(f\"{data_path}: shape = {data.shape[0]} rows, {data.shape[1]} cols\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def catboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "    X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        model.fit(\n",
    "            x_train, y_train, categorical,\n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "        )\n",
    "        oof_preds[valid_idx] = model.predict_proba(x_valid)[:, 1]\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds\n",
    "\n",
    "\n",
    "def catboost_hold_out_validation(params, X, y, split_params = [0.7, 0.2, 0.1], categorical = None):\n",
    "    \"\"\"\n",
    "    Hold-Out валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    split_params: List[float], optional, default = [0.7, 0.2, 0.1]\n",
    "        Параметры (доли) разбиения выборки.\n",
    "        Опциональный параметр, по умолчанию, равен [0.7, 0.2, 0.1].\n",
    "    \n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimator: catboost.core.CatBoostClassifier\n",
    "        Обученный классификатор catboost.\n",
    "\n",
    "    test_prediction: np.array, optional\n",
    "        Вектор прогнозов для тестовой выборки.\n",
    "        Опциональный объект, возвращается только, если split_params\n",
    "        содержит 3 значения.\n",
    "\n",
    "    \"\"\"\n",
    "    numeric = list(set(x_train.columns) - set(categorical))\n",
    "    x_train, x_valid = train_test_split(\n",
    "        X, train_size=split_params[0], random_state=27\n",
    "    )\n",
    "    y_train, y_valid = train_test_split(\n",
    "        y, train_size=split_params[0], random_state=27\n",
    "    )\n",
    "\n",
    "    if len(split_params) == 3:\n",
    "        test_size = int(split_params[2] * X.shape[0])\n",
    "\n",
    "        x_valid, x_test = train_test_split(\n",
    "            x_valid, test_size=test_size, random_state=72\n",
    "        )\n",
    "        y_valid, y_test = train_test_split(\n",
    "            y_valid, test_size=test_size, random_state=72\n",
    "        )\n",
    "\n",
    "    model = cb.CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        x_train, y_train, categorical,\n",
    "        eval_set=[(x_train, y_train), (x_valid, y_valid)]\n",
    "    )\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    valid_score = roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])\n",
    "    print(f\"Valid Score = {round(valid_score, 4)}\")\n",
    "\n",
    "    if len(split_params) == 3:\n",
    "\n",
    "        test_prediction = model.predict_proba(x_test)[:, 1]\n",
    "        test_score = roc_auc_score(y_test, test_prediction)\n",
    "        print(f\"Test Score = {round(test_score, 4)}\")\n",
    "\n",
    "        return estimator, test_prediction\n",
    "\n",
    "    else:\n",
    "        return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_profile_features(X: pd.DataFrame, copy: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Создание признаков на основе профиля клиентов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признаков с исходным профилем клиента.\n",
    "\n",
    "    copy: bool, optional, default = True\n",
    "        Флаг использования копии датафрейма X.\n",
    "        Опциональный параметр, по умолчанию, равен True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed: pandas.core.frame.DataFrame\n",
    "        Расширенная матрица признаков с профилем клиентов.\n",
    "\n",
    "    \"\"\"\n",
    "    if copy:\n",
    "        X = X.copy()\n",
    "\n",
    "    X[\"days_on_last_job\"] = X[\"days_on_last_job\"].replace(365243, np.nan)\n",
    "    bki_flags = [flag for flag in X.columns if \"amt_req_credit_bureau\" in flag]\n",
    "    X[\"bki_requests_count\"] = X[bki_flags].sum(axis=1)\n",
    "    X[\"bki_kurtosis\"] = X[bki_flags].kurtosis(axis=1)\n",
    "\n",
    "    X[\"external_scoring_prod\"] = X[\"external_scoring_rating_1\"] * X[\"external_scoring_rating_2\"] * X[\"external_scoring_rating_3\"]\n",
    "    X[\"external_scoring_weighted\"] = X.external_scoring_rating_1 * 2 + X.external_scoring_rating_2 * 1 + X.external_scoring_rating_3 * 3\n",
    "\n",
    "    for function_name in [\"min\", \"max\", \"mean\", \"nanmedian\", \"var\"]:\n",
    "        feature_name = \"external_scoring_rating_{}\".format(function_name)\n",
    "        X[feature_name] = eval(\"np.{}\".format(function_name))(\n",
    "            X[[\"external_scoring_rating_1\", \"external_scoring_rating_2\", \"external_scoring_rating_3\"]], axis=1\n",
    "        )\n",
    "\n",
    "    # Отношение между основными фин. показателями\n",
    "    X['ratio_credit_to_annuity'] = X['amount_credit'] / X['amount_annuity']\n",
    "    X[\"ratio_annuity_to_salary\"] = X['amount_annuity'] / X['total_salary']\n",
    "    X['ratio_credit_to_salary'] = X['amount_credit'] / X['total_salary']\n",
    "    #X[\"total_salary_net\"] = X[\"total_salary\"] - X[\"amount_annuity\"]\n",
    "\n",
    "    # Отношение фин. показателей к возрасту и временным фичам\n",
    "    X[\"ratio_annuity_to_age\"] = X[\"amount_annuity\"] / X[\"age\"]\n",
    "    X[\"ratio_credit_to_age\"] = X[\"amount_credit\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_age\"] = X[\"total_salary\"] / X[\"age\"]\n",
    "    X[\"ratio_salary_to_experience\"] = X[\"total_salary\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_credit_to_experience\"] = X[\"amount_credit\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_annuity_to_experience\"] = X[\"amount_annuity\"] / X[\"days_on_last_job\"]\n",
    "\n",
    "    # Отношение врменных признаков\n",
    "    X[\"ratio_age_to_experience\"] = X[\"age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_salary_to_region_population\"] = X[\"total_salary\"] * X[\"region_population\"]\n",
    "    X[\"ratio_car_to_experience\"] = X[\"own_car_age\"] / X[\"days_on_last_job\"]\n",
    "    X[\"ratio_car_to_age\"] = X[\"own_car_age\"] / X[\"age\"]\n",
    "\n",
    "    # Произведение фин. показателей кредита на вероятность дефолта\n",
    "    # Такая штука называется математическим ожиданием дефолта или ожидаемыми потерями\n",
    "    X[\"expected_total_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_total_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_credit\"]\n",
    "    X[\"expected_monthly_loss_1\"] = X[\"external_scoring_rating_1\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_2\"] = X[\"external_scoring_rating_2\"] * X[\"amount_annuity\"]\n",
    "    X[\"expected_monthly_loss_3\"] = X[\"external_scoring_rating_3\"] * X[\"amount_annuity\"]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "    \"\"\"\n",
    "    Кросс-валидация для модели catbooost.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        Словарь гиперпараметров модели.\n",
    "\n",
    "    X: pandas.core.frame.DataFrame\n",
    "        Матрица признако для обучения модели.\n",
    "\n",
    "    y: pandas.core.frame.Series\n",
    "        Вектор целевой переменной для обучения модели.\n",
    "\n",
    "    cv: KFold or StratifiedKFold generator.\n",
    "        Объект KFold / StratifiedKFold для определения\n",
    "        стратегии кросс-валидации модели.\n",
    "\n",
    "    categorical: str, optional, default = None\n",
    "        Список категориальных признаков.\n",
    "        Опциональный параметр, по умолчанию, не используется.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    estimators: list\n",
    "        Список с объектами обученной модели.\n",
    "\n",
    "    oof_preds: np.array\n",
    "        Вектор OOF-прогнозов.\n",
    "\n",
    "    \"\"\"\n",
    "    estimators, folds_scores = [], []\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "\n",
    "    print(f\"{time.ctime()}, Cross-Validation, {X.shape[0]} rows, {X.shape[1]} cols\")\n",
    "#    X[categorical] = X[categorical].astype(str)\n",
    "\n",
    "    for fold, (train_idx, valid_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        x_train, x_valid = X.loc[train_idx], X.loc[valid_idx]\n",
    "        y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "        \n",
    "        #-----\n",
    "        dtrain = xgb.DMatrix(x_train, y_train)\n",
    "        dvalid = xgb.DMatrix(x_valid, y_valid)\n",
    "\n",
    "        model = xgb.train(\n",
    "          params=params,\n",
    "          dtrain=dtrain,\n",
    "          evals=[(dtrain, \"dtrain\"), (dvalid, \"dvalid\")],\n",
    "          early_stopping_rounds=25,\n",
    "          num_boost_round=1000,\n",
    "          verbose_eval=10,\n",
    "          maximize=True,\n",
    "        )\n",
    "        #____\n",
    "        \n",
    "        oof_preds[valid_idx] = model.predict(dvalid)\n",
    "        score = roc_auc_score(y_valid, oof_preds[valid_idx])\n",
    "        print(f\"Fold {fold+1}, Valid score = {round(score, 5)}\")\n",
    "        folds_scores.append(round(score, 5))\n",
    "        estimators.append(model)\n",
    "\n",
    "    print(f\"Score by each fold: {folds_scores}\")\n",
    "    print(\"=\"*65)\n",
    "    return estimators, oof_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv: shape = 110093 rows, 3 cols\n",
      "test.csv: shape = 165141 rows, 2 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>target</th>\n",
       "      <th>name_contract_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123687442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123597908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number  target name_contract_type\n",
       "0           123687442     0.0               Cash\n",
       "1           123597908     1.0               Cash"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = get_input(\"train.csv\")\n",
    "test = get_input(\"test.csv\")\n",
    "\n",
    "data = pd.concat([train, test], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## client_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_profile.csv: shape = 250000 rows, 24 cols\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1116: RuntimeWarning: All-NaN slice encountered\n",
      "  overwrite_input=overwrite_input)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>gender</th>\n",
       "      <th>childrens</th>\n",
       "      <th>total_salary</th>\n",
       "      <th>amount_credit</th>\n",
       "      <th>amount_annuity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>family_status</th>\n",
       "      <th>region_population</th>\n",
       "      <th>age</th>\n",
       "      <th>days_on_last_job</th>\n",
       "      <th>own_car_age</th>\n",
       "      <th>flag_phone</th>\n",
       "      <th>flag_email</th>\n",
       "      <th>family_size</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_credit_to_age</th>\n",
       "      <th>ratio_salary_to_age</th>\n",
       "      <th>ratio_salary_to_experience</th>\n",
       "      <th>ratio_credit_to_experience</th>\n",
       "      <th>ratio_annuity_to_experience</th>\n",
       "      <th>ratio_age_to_experience</th>\n",
       "      <th>ratio_salary_to_region_population</th>\n",
       "      <th>ratio_car_to_experience</th>\n",
       "      <th>ratio_car_to_age</th>\n",
       "      <th>expected_total_loss_1</th>\n",
       "      <th>expected_total_loss_2</th>\n",
       "      <th>expected_total_loss_3</th>\n",
       "      <th>expected_monthly_loss_1</th>\n",
       "      <th>expected_monthly_loss_2</th>\n",
       "      <th>expected_monthly_loss_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123666076</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>Incomplete higher</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>0.008068</td>\n",
       "      <td>8560</td>\n",
       "      <td>1549.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.542056</td>\n",
       "      <td>18.399533</td>\n",
       "      <td>101.678502</td>\n",
       "      <td>174.306004</td>\n",
       "      <td>8.7153</td>\n",
       "      <td>5.526146</td>\n",
       "      <td>1270.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88957.124333</td>\n",
       "      <td>63804.966560</td>\n",
       "      <td>183213.275945</td>\n",
       "      <td>4447.856217</td>\n",
       "      <td>3190.248328</td>\n",
       "      <td>9160.663797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123423688</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>536917.5</td>\n",
       "      <td>28467.0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>23187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.155971</td>\n",
       "      <td>11.644456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5466.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237475.743779</td>\n",
       "      <td>431008.094056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12590.802122</td>\n",
       "      <td>22851.755462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   application_number gender  childrens  total_salary  amount_credit  \\\n",
       "0           123666076      F          0      157500.0       270000.0   \n",
       "1           123423688      F          0      270000.0       536917.5   \n",
       "\n",
       "   amount_annuity                education_level   family_status  \\\n",
       "0         13500.0              Incomplete higher  Civil marriage   \n",
       "1         28467.0  Secondary / secondary special         Married   \n",
       "\n",
       "   region_population    age  days_on_last_job  own_car_age  flag_phone  \\\n",
       "0           0.008068   8560            1549.0          NaN           1   \n",
       "1           0.020246  23187               NaN          NaN           0   \n",
       "\n",
       "   flag_email  family_size  ...  ratio_credit_to_age  ratio_salary_to_age  \\\n",
       "0           0          2.0  ...            31.542056            18.399533   \n",
       "1           0          2.0  ...            23.155971            11.644456   \n",
       "\n",
       "   ratio_salary_to_experience  ratio_credit_to_experience  \\\n",
       "0                  101.678502                  174.306004   \n",
       "1                         NaN                         NaN   \n",
       "\n",
       "   ratio_annuity_to_experience  ratio_age_to_experience  \\\n",
       "0                       8.7153                 5.526146   \n",
       "1                          NaN                      NaN   \n",
       "\n",
       "   ratio_salary_to_region_population  ratio_car_to_experience  \\\n",
       "0                            1270.71                      NaN   \n",
       "1                            5466.42                      NaN   \n",
       "\n",
       "   ratio_car_to_age  expected_total_loss_1  expected_total_loss_2  \\\n",
       "0               NaN           88957.124333           63804.966560   \n",
       "1               NaN                    NaN          237475.743779   \n",
       "\n",
       "   expected_total_loss_3  expected_monthly_loss_1  expected_monthly_loss_2  \\\n",
       "0          183213.275945              4447.856217              3190.248328   \n",
       "1          431008.094056                      NaN             12590.802122   \n",
       "\n",
       "   expected_monthly_loss_3  \n",
       "0              9160.663797  \n",
       "1             22851.755462  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_profile = get_input(\"client_profile.csv\")\n",
    "client_profile = create_client_profile_features(client_profile)\n",
    "client_profile.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(\n",
    "    client_profile, how=\"left\", on=\"application_number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cash</th>\n",
       "      <th>Credit Card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cash  Credit Card\n",
       "0     1            0\n",
       "1     1            0\n",
       "2     1            0\n",
       "3     1            0\n",
       "4     1            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"name_contract_type\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>XNA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F  M  XNA\n",
       "0  0  1    0\n",
       "1  0  0    0\n",
       "2  1  0    0\n",
       "3  0  1    0\n",
       "4  0  0    0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"gender\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Academic degree</th>\n",
       "      <th>Higher education</th>\n",
       "      <th>Incomplete higher</th>\n",
       "      <th>Lower secondary</th>\n",
       "      <th>Secondary / secondary special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Academic degree  Higher education  Incomplete higher  Lower secondary  \\\n",
       "0                0                 0                  0                0   \n",
       "1                0                 0                  0                0   \n",
       "2                0                 1                  0                0   \n",
       "3                0                 0                  0                0   \n",
       "4                0                 0                  0                0   \n",
       "\n",
       "   Secondary / secondary special  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              1  \n",
       "4                              0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"education_level\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Civil marriage</th>\n",
       "      <th>Married</th>\n",
       "      <th>Separated</th>\n",
       "      <th>Single / not married</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Civil marriage  Married  Separated  Single / not married  Unknown  Widow\n",
       "0               0        1          0                     0        0      0\n",
       "1               0        0          0                     0        0      0\n",
       "2               0        1          0                     0        0      0\n",
       "3               0        1          0                     0        0      0\n",
       "4               0        0          0                     0        0      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data[\"family_status\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education_level</th>\n",
       "      <th>education_level_freq_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.710221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 education_level  education_level_freq_enc\n",
       "0  Secondary / secondary special                  0.710221\n",
       "1                            NaN                       NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_encoder = data[\"education_level\"].value_counts(normalize=True)\n",
    "data[\"education_level_freq_enc\"] = data[\"education_level\"].map(freq_encoder)\n",
    "data[[\"education_level\", \"education_level_freq_enc\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data[\"target\"].isnull()\n",
    "features_to_drop = [\"application_number\", \"target\"]\n",
    "\n",
    "train, test = data.loc[~mask], data.loc[mask]\n",
    "\n",
    "target, test_id = train[\"target\"], test[\"application_number\"]\n",
    "train = train.drop(features_to_drop, axis=1)\n",
    "test = test.drop(features_to_drop, axis=1)\n",
    "\n",
    "categorial = train.dtypes[train.dtypes == \"object\"].index\n",
    "numerical = list(set(train.columns) - set(categorial))\n",
    "\n",
    "train = train.replace(np.inf, np.nan)\n",
    "train = train.replace(-np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 30 19:58:42 2020, Cross-Validation, 110093 rows, 49 cols\n",
      "[0]\tdtrain-auc:0.70634\tdvalid-auc:0.69114\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71490\tdvalid-auc:0.69528\n",
      "[20]\tdtrain-auc:0.72093\tdvalid-auc:0.69807\n",
      "[30]\tdtrain-auc:0.72577\tdvalid-auc:0.69773\n",
      "[40]\tdtrain-auc:0.72773\tdvalid-auc:0.69887\n",
      "[50]\tdtrain-auc:0.72966\tdvalid-auc:0.69930\n",
      "[60]\tdtrain-auc:0.73191\tdvalid-auc:0.69958\n",
      "[70]\tdtrain-auc:0.73364\tdvalid-auc:0.69956\n",
      "[80]\tdtrain-auc:0.73452\tdvalid-auc:0.69941\n",
      "Stopping. Best iteration:\n",
      "[62]\tdtrain-auc:0.73212\tdvalid-auc:0.69993\n",
      "\n",
      "Fold 1, Valid score = 0.69924\n",
      "[0]\tdtrain-auc:0.70376\tdvalid-auc:0.69479\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71684\tdvalid-auc:0.70196\n",
      "[20]\tdtrain-auc:0.72148\tdvalid-auc:0.70392\n",
      "[30]\tdtrain-auc:0.72440\tdvalid-auc:0.70571\n",
      "[40]\tdtrain-auc:0.72599\tdvalid-auc:0.70659\n",
      "[50]\tdtrain-auc:0.72731\tdvalid-auc:0.70684\n",
      "[60]\tdtrain-auc:0.72852\tdvalid-auc:0.70635\n",
      "Stopping. Best iteration:\n",
      "[43]\tdtrain-auc:0.72652\tdvalid-auc:0.70689\n",
      "\n",
      "Fold 2, Valid score = 0.70618\n",
      "[0]\tdtrain-auc:0.70522\tdvalid-auc:0.69583\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71662\tdvalid-auc:0.70356\n",
      "[20]\tdtrain-auc:0.71903\tdvalid-auc:0.70332\n",
      "[30]\tdtrain-auc:0.72182\tdvalid-auc:0.70446\n",
      "[40]\tdtrain-auc:0.72362\tdvalid-auc:0.70520\n",
      "[50]\tdtrain-auc:0.72564\tdvalid-auc:0.70603\n",
      "[60]\tdtrain-auc:0.72686\tdvalid-auc:0.70681\n",
      "[70]\tdtrain-auc:0.72849\tdvalid-auc:0.70695\n",
      "[80]\tdtrain-auc:0.73025\tdvalid-auc:0.70779\n",
      "[90]\tdtrain-auc:0.73167\tdvalid-auc:0.70775\n",
      "[100]\tdtrain-auc:0.73327\tdvalid-auc:0.70837\n",
      "[110]\tdtrain-auc:0.73465\tdvalid-auc:0.70895\n",
      "[120]\tdtrain-auc:0.73588\tdvalid-auc:0.70919\n",
      "[130]\tdtrain-auc:0.73712\tdvalid-auc:0.71034\n",
      "[140]\tdtrain-auc:0.73823\tdvalid-auc:0.71082\n",
      "[150]\tdtrain-auc:0.73935\tdvalid-auc:0.71069\n",
      "[160]\tdtrain-auc:0.74050\tdvalid-auc:0.71123\n",
      "[170]\tdtrain-auc:0.74216\tdvalid-auc:0.71246\n",
      "[180]\tdtrain-auc:0.74320\tdvalid-auc:0.71303\n",
      "[190]\tdtrain-auc:0.74394\tdvalid-auc:0.71370\n",
      "[200]\tdtrain-auc:0.74480\tdvalid-auc:0.71440\n",
      "[210]\tdtrain-auc:0.74592\tdvalid-auc:0.71437\n",
      "[220]\tdtrain-auc:0.74736\tdvalid-auc:0.71506\n",
      "[230]\tdtrain-auc:0.74839\tdvalid-auc:0.71574\n",
      "[240]\tdtrain-auc:0.74975\tdvalid-auc:0.71603\n",
      "[250]\tdtrain-auc:0.75092\tdvalid-auc:0.71709\n",
      "[260]\tdtrain-auc:0.75226\tdvalid-auc:0.71750\n",
      "[270]\tdtrain-auc:0.75372\tdvalid-auc:0.71856\n",
      "[280]\tdtrain-auc:0.75563\tdvalid-auc:0.71987\n",
      "[290]\tdtrain-auc:0.75710\tdvalid-auc:0.72070\n",
      "[300]\tdtrain-auc:0.75879\tdvalid-auc:0.72139\n",
      "[310]\tdtrain-auc:0.76028\tdvalid-auc:0.72181\n",
      "[320]\tdtrain-auc:0.76165\tdvalid-auc:0.72204\n",
      "[330]\tdtrain-auc:0.76314\tdvalid-auc:0.72246\n",
      "[340]\tdtrain-auc:0.76472\tdvalid-auc:0.72217\n",
      "[350]\tdtrain-auc:0.76598\tdvalid-auc:0.72247\n",
      "[360]\tdtrain-auc:0.76699\tdvalid-auc:0.72332\n",
      "[370]\tdtrain-auc:0.76821\tdvalid-auc:0.72419\n",
      "[380]\tdtrain-auc:0.76951\tdvalid-auc:0.72475\n",
      "[390]\tdtrain-auc:0.77071\tdvalid-auc:0.72492\n",
      "[400]\tdtrain-auc:0.77213\tdvalid-auc:0.72526\n",
      "[410]\tdtrain-auc:0.77338\tdvalid-auc:0.72617\n",
      "[420]\tdtrain-auc:0.77446\tdvalid-auc:0.72615\n",
      "[430]\tdtrain-auc:0.77558\tdvalid-auc:0.72619\n",
      "[440]\tdtrain-auc:0.77690\tdvalid-auc:0.72650\n",
      "[450]\tdtrain-auc:0.77841\tdvalid-auc:0.72694\n",
      "[460]\tdtrain-auc:0.77982\tdvalid-auc:0.72767\n",
      "[470]\tdtrain-auc:0.78094\tdvalid-auc:0.72843\n",
      "[480]\tdtrain-auc:0.78222\tdvalid-auc:0.72887\n",
      "[490]\tdtrain-auc:0.78351\tdvalid-auc:0.72879\n",
      "[500]\tdtrain-auc:0.78459\tdvalid-auc:0.72880\n",
      "[510]\tdtrain-auc:0.78562\tdvalid-auc:0.72864\n",
      "Stopping. Best iteration:\n",
      "[485]\tdtrain-auc:0.78281\tdvalid-auc:0.72894\n",
      "\n",
      "Fold 3, Valid score = 0.72864\n",
      "[0]\tdtrain-auc:0.70739\tdvalid-auc:0.68975\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71984\tdvalid-auc:0.69817\n",
      "[20]\tdtrain-auc:0.72233\tdvalid-auc:0.69946\n",
      "[30]\tdtrain-auc:0.72570\tdvalid-auc:0.70054\n",
      "[40]\tdtrain-auc:0.72774\tdvalid-auc:0.70095\n",
      "[50]\tdtrain-auc:0.72875\tdvalid-auc:0.70119\n",
      "[60]\tdtrain-auc:0.72975\tdvalid-auc:0.70179\n",
      "[70]\tdtrain-auc:0.73082\tdvalid-auc:0.70170\n",
      "[80]\tdtrain-auc:0.73195\tdvalid-auc:0.70215\n",
      "[90]\tdtrain-auc:0.73303\tdvalid-auc:0.70283\n",
      "[100]\tdtrain-auc:0.73411\tdvalid-auc:0.70314\n",
      "[110]\tdtrain-auc:0.73541\tdvalid-auc:0.70353\n",
      "[120]\tdtrain-auc:0.73712\tdvalid-auc:0.70407\n",
      "[130]\tdtrain-auc:0.73842\tdvalid-auc:0.70394\n",
      "[140]\tdtrain-auc:0.73956\tdvalid-auc:0.70444\n",
      "[150]\tdtrain-auc:0.74078\tdvalid-auc:0.70515\n",
      "[160]\tdtrain-auc:0.74247\tdvalid-auc:0.70607\n",
      "[170]\tdtrain-auc:0.74411\tdvalid-auc:0.70610\n",
      "[180]\tdtrain-auc:0.74527\tdvalid-auc:0.70611\n",
      "[190]\tdtrain-auc:0.74639\tdvalid-auc:0.70640\n",
      "[200]\tdtrain-auc:0.74760\tdvalid-auc:0.70687\n",
      "[210]\tdtrain-auc:0.74878\tdvalid-auc:0.70685\n",
      "[220]\tdtrain-auc:0.75028\tdvalid-auc:0.70720\n",
      "[230]\tdtrain-auc:0.75149\tdvalid-auc:0.70801\n",
      "[240]\tdtrain-auc:0.75269\tdvalid-auc:0.70773\n",
      "[250]\tdtrain-auc:0.75381\tdvalid-auc:0.70776\n",
      "Stopping. Best iteration:\n",
      "[228]\tdtrain-auc:0.75126\tdvalid-auc:0.70808\n",
      "\n",
      "Fold 4, Valid score = 0.70772\n",
      "[0]\tdtrain-auc:0.70822\tdvalid-auc:0.69364\n",
      "Multiple eval metrics have been passed: 'dvalid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until dvalid-auc hasn't improved in 25 rounds.\n",
      "[10]\tdtrain-auc:0.71766\tdvalid-auc:0.69676\n",
      "[20]\tdtrain-auc:0.72228\tdvalid-auc:0.69765\n",
      "[30]\tdtrain-auc:0.72449\tdvalid-auc:0.69762\n",
      "[40]\tdtrain-auc:0.72569\tdvalid-auc:0.69751\n",
      "[50]\tdtrain-auc:0.72720\tdvalid-auc:0.69797\n",
      "[60]\tdtrain-auc:0.72855\tdvalid-auc:0.69777\n",
      "[70]\tdtrain-auc:0.72989\tdvalid-auc:0.69766\n",
      "Stopping. Best iteration:\n",
      "[51]\tdtrain-auc:0.72745\tdvalid-auc:0.69812\n",
      "\n",
      "Fold 5, Valid score = 0.69768\n",
      "Score by each fold: [0.69924, 0.70618, 0.72864, 0.70772, 0.69768]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import BayesianOptimization\n",
    "xgb_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"nthread\": 6,\n",
    "    \"seed\": 27\n",
    "}\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1234123, shuffle=True)\n",
    "new_train = train[numerical]\n",
    "estimators, oof_preds_xgb = xgboost_cross_validation(\n",
    "    params=xgb_params, X=new_train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.62182\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_xgb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "#test[categorial] = test[categorial].astype(str)\n",
    "\n",
    "new_test = test[numerical]\n",
    "dtest = xgb.DMatrix(new_test)\n",
    "\n",
    "for estimator in estimators:\n",
    "    y_pred_xgb += estimator.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = y_pred_xgb / cv.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgboost_cross_validation(params, X, y, cv, categorical = None):\n",
    "#from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#N_FOLDS = 10\n",
    "#folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random\n",
    "    estimators = []\n",
    "    oof = np.zeros(len(X))\n",
    "    sub = np.zeros(len(test))\n",
    "    scores = [0 for _ in range(cv.n_splits)]\n",
    "    for fold_, (train_idx, val_idx) in enumerate(cv.split(X.values, y)):\n",
    "        X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "        X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val)\n",
    "        watchlist = [train_data, val_data]\n",
    "        clf = lgb.train(params, train_set = train_data, valid_sets=watchlist)\n",
    "        oof[val_idx] = clf.predict(X_val)\n",
    "        sub += clf.predict(new_test)/cv.n_splits\n",
    "        scores[fold_] = roc_auc_score(y[val_idx], oof[val_idx])\n",
    "        print(\"Fold {}: {}\".format(fold_+1, round(scores[fold_],5)))\n",
    "        estimators.append(clf)\n",
    "    \n",
    "    print(\"CV score(auc): {:<8.5f}, (std: {:<8.5f})\".format(roc_auc_score(y, oof), np.std(scores)))\n",
    "\n",
    "    print(\"=\"*65)\n",
    "    return estimators,oof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.705233\tvalid_1's auc: 0.696419\n",
      "[2]\ttraining's auc: 0.716252\tvalid_1's auc: 0.702777\n",
      "[3]\ttraining's auc: 0.721656\tvalid_1's auc: 0.707404\n",
      "[4]\ttraining's auc: 0.726994\tvalid_1's auc: 0.711742\n",
      "[5]\ttraining's auc: 0.731583\tvalid_1's auc: 0.714943\n",
      "[6]\ttraining's auc: 0.734744\tvalid_1's auc: 0.71639\n",
      "[7]\ttraining's auc: 0.737442\tvalid_1's auc: 0.717476\n",
      "[8]\ttraining's auc: 0.743179\tvalid_1's auc: 0.722673\n",
      "[9]\ttraining's auc: 0.745573\tvalid_1's auc: 0.723342\n",
      "[10]\ttraining's auc: 0.747584\tvalid_1's auc: 0.721867\n",
      "[11]\ttraining's auc: 0.750348\tvalid_1's auc: 0.723855\n",
      "[12]\ttraining's auc: 0.753263\tvalid_1's auc: 0.725308\n",
      "[13]\ttraining's auc: 0.7553\tvalid_1's auc: 0.725078\n",
      "[14]\ttraining's auc: 0.757943\tvalid_1's auc: 0.725768\n",
      "[15]\ttraining's auc: 0.760415\tvalid_1's auc: 0.728105\n",
      "[16]\ttraining's auc: 0.762784\tvalid_1's auc: 0.728191\n",
      "[17]\ttraining's auc: 0.765873\tvalid_1's auc: 0.728716\n",
      "[18]\ttraining's auc: 0.768086\tvalid_1's auc: 0.728383\n",
      "[19]\ttraining's auc: 0.771715\tvalid_1's auc: 0.72773\n",
      "[20]\ttraining's auc: 0.774693\tvalid_1's auc: 0.727819\n",
      "[21]\ttraining's auc: 0.776363\tvalid_1's auc: 0.72913\n",
      "[22]\ttraining's auc: 0.778849\tvalid_1's auc: 0.7288\n",
      "[23]\ttraining's auc: 0.780352\tvalid_1's auc: 0.727357\n",
      "[24]\ttraining's auc: 0.782565\tvalid_1's auc: 0.726031\n",
      "[25]\ttraining's auc: 0.78356\tvalid_1's auc: 0.726425\n",
      "[26]\ttraining's auc: 0.785466\tvalid_1's auc: 0.725628\n",
      "[27]\ttraining's auc: 0.787146\tvalid_1's auc: 0.724759\n",
      "[28]\ttraining's auc: 0.787752\tvalid_1's auc: 0.72483\n",
      "[29]\ttraining's auc: 0.789057\tvalid_1's auc: 0.725654\n",
      "[30]\ttraining's auc: 0.790631\tvalid_1's auc: 0.725654\n",
      "[31]\ttraining's auc: 0.792859\tvalid_1's auc: 0.726748\n",
      "[32]\ttraining's auc: 0.794695\tvalid_1's auc: 0.727253\n",
      "[33]\ttraining's auc: 0.796451\tvalid_1's auc: 0.72669\n",
      "[34]\ttraining's auc: 0.798673\tvalid_1's auc: 0.727265\n",
      "[35]\ttraining's auc: 0.800036\tvalid_1's auc: 0.726798\n",
      "[36]\ttraining's auc: 0.801601\tvalid_1's auc: 0.726929\n",
      "[37]\ttraining's auc: 0.803224\tvalid_1's auc: 0.727186\n",
      "[38]\ttraining's auc: 0.804302\tvalid_1's auc: 0.727171\n",
      "[39]\ttraining's auc: 0.805287\tvalid_1's auc: 0.727122\n",
      "[40]\ttraining's auc: 0.806637\tvalid_1's auc: 0.727361\n",
      "[41]\ttraining's auc: 0.80874\tvalid_1's auc: 0.727077\n",
      "[42]\ttraining's auc: 0.810505\tvalid_1's auc: 0.725836\n",
      "[43]\ttraining's auc: 0.812343\tvalid_1's auc: 0.725185\n",
      "[44]\ttraining's auc: 0.81375\tvalid_1's auc: 0.724232\n",
      "[45]\ttraining's auc: 0.814873\tvalid_1's auc: 0.724085\n",
      "[46]\ttraining's auc: 0.815783\tvalid_1's auc: 0.723846\n",
      "[47]\ttraining's auc: 0.81742\tvalid_1's auc: 0.724153\n",
      "[48]\ttraining's auc: 0.818878\tvalid_1's auc: 0.723942\n",
      "[49]\ttraining's auc: 0.819406\tvalid_1's auc: 0.723121\n",
      "[50]\ttraining's auc: 0.82161\tvalid_1's auc: 0.723341\n",
      "[51]\ttraining's auc: 0.823458\tvalid_1's auc: 0.723541\n",
      "[52]\ttraining's auc: 0.82483\tvalid_1's auc: 0.722605\n",
      "[53]\ttraining's auc: 0.825984\tvalid_1's auc: 0.721925\n",
      "[54]\ttraining's auc: 0.827731\tvalid_1's auc: 0.721685\n",
      "[55]\ttraining's auc: 0.828607\tvalid_1's auc: 0.722144\n",
      "[56]\ttraining's auc: 0.829507\tvalid_1's auc: 0.721437\n",
      "[57]\ttraining's auc: 0.829863\tvalid_1's auc: 0.720867\n",
      "[58]\ttraining's auc: 0.8308\tvalid_1's auc: 0.720748\n",
      "[59]\ttraining's auc: 0.833132\tvalid_1's auc: 0.720472\n",
      "[60]\ttraining's auc: 0.834519\tvalid_1's auc: 0.72103\n",
      "[61]\ttraining's auc: 0.836182\tvalid_1's auc: 0.720281\n",
      "[62]\ttraining's auc: 0.837573\tvalid_1's auc: 0.719873\n",
      "[63]\ttraining's auc: 0.838991\tvalid_1's auc: 0.720703\n",
      "[64]\ttraining's auc: 0.839743\tvalid_1's auc: 0.720426\n",
      "[65]\ttraining's auc: 0.840694\tvalid_1's auc: 0.721065\n",
      "[66]\ttraining's auc: 0.841519\tvalid_1's auc: 0.721048\n",
      "[67]\ttraining's auc: 0.842895\tvalid_1's auc: 0.720931\n",
      "[68]\ttraining's auc: 0.844191\tvalid_1's auc: 0.720536\n",
      "[69]\ttraining's auc: 0.845645\tvalid_1's auc: 0.720317\n",
      "[70]\ttraining's auc: 0.846795\tvalid_1's auc: 0.72006\n",
      "[71]\ttraining's auc: 0.847757\tvalid_1's auc: 0.720205\n",
      "[72]\ttraining's auc: 0.848124\tvalid_1's auc: 0.72017\n",
      "[73]\ttraining's auc: 0.848847\tvalid_1's auc: 0.72004\n",
      "[74]\ttraining's auc: 0.849932\tvalid_1's auc: 0.719575\n",
      "[75]\ttraining's auc: 0.850673\tvalid_1's auc: 0.719696\n",
      "[76]\ttraining's auc: 0.851406\tvalid_1's auc: 0.719169\n",
      "[77]\ttraining's auc: 0.852619\tvalid_1's auc: 0.718714\n",
      "[78]\ttraining's auc: 0.853789\tvalid_1's auc: 0.719127\n",
      "[79]\ttraining's auc: 0.855226\tvalid_1's auc: 0.718536\n",
      "[80]\ttraining's auc: 0.856105\tvalid_1's auc: 0.718254\n",
      "[81]\ttraining's auc: 0.856875\tvalid_1's auc: 0.718505\n",
      "[82]\ttraining's auc: 0.857698\tvalid_1's auc: 0.718147\n",
      "[83]\ttraining's auc: 0.859353\tvalid_1's auc: 0.718442\n",
      "[84]\ttraining's auc: 0.860455\tvalid_1's auc: 0.718242\n",
      "[85]\ttraining's auc: 0.861663\tvalid_1's auc: 0.717549\n",
      "[86]\ttraining's auc: 0.863064\tvalid_1's auc: 0.717038\n",
      "[87]\ttraining's auc: 0.864085\tvalid_1's auc: 0.71714\n",
      "[88]\ttraining's auc: 0.864983\tvalid_1's auc: 0.717477\n",
      "[89]\ttraining's auc: 0.865363\tvalid_1's auc: 0.717136\n",
      "[90]\ttraining's auc: 0.866704\tvalid_1's auc: 0.718325\n",
      "[91]\ttraining's auc: 0.867804\tvalid_1's auc: 0.718396\n",
      "[92]\ttraining's auc: 0.868999\tvalid_1's auc: 0.719439\n",
      "[93]\ttraining's auc: 0.869605\tvalid_1's auc: 0.719757\n",
      "[94]\ttraining's auc: 0.870935\tvalid_1's auc: 0.719222\n",
      "[95]\ttraining's auc: 0.871676\tvalid_1's auc: 0.719266\n",
      "[96]\ttraining's auc: 0.872253\tvalid_1's auc: 0.718806\n",
      "[97]\ttraining's auc: 0.873449\tvalid_1's auc: 0.718667\n",
      "[98]\ttraining's auc: 0.874845\tvalid_1's auc: 0.718523\n",
      "[99]\ttraining's auc: 0.875384\tvalid_1's auc: 0.718531\n",
      "[100]\ttraining's auc: 0.876259\tvalid_1's auc: 0.718476\n",
      "Fold 1: 0.71848\n",
      "[1]\ttraining's auc: 0.704432\tvalid_1's auc: 0.703001\n",
      "[2]\ttraining's auc: 0.713056\tvalid_1's auc: 0.706652\n",
      "[3]\ttraining's auc: 0.718603\tvalid_1's auc: 0.707585\n",
      "[4]\ttraining's auc: 0.725114\tvalid_1's auc: 0.714528\n",
      "[5]\ttraining's auc: 0.728909\tvalid_1's auc: 0.716262\n",
      "[6]\ttraining's auc: 0.731198\tvalid_1's auc: 0.717245\n",
      "[7]\ttraining's auc: 0.735188\tvalid_1's auc: 0.719297\n",
      "[8]\ttraining's auc: 0.739638\tvalid_1's auc: 0.718573\n",
      "[9]\ttraining's auc: 0.742896\tvalid_1's auc: 0.717191\n",
      "[10]\ttraining's auc: 0.746892\tvalid_1's auc: 0.716942\n",
      "[11]\ttraining's auc: 0.749342\tvalid_1's auc: 0.716229\n",
      "[12]\ttraining's auc: 0.754673\tvalid_1's auc: 0.720822\n",
      "[13]\ttraining's auc: 0.757161\tvalid_1's auc: 0.720873\n",
      "[14]\ttraining's auc: 0.759989\tvalid_1's auc: 0.719701\n",
      "[15]\ttraining's auc: 0.762534\tvalid_1's auc: 0.719541\n",
      "[16]\ttraining's auc: 0.76577\tvalid_1's auc: 0.717623\n",
      "[17]\ttraining's auc: 0.768695\tvalid_1's auc: 0.719616\n",
      "[18]\ttraining's auc: 0.771471\tvalid_1's auc: 0.719875\n",
      "[19]\ttraining's auc: 0.77384\tvalid_1's auc: 0.719296\n",
      "[20]\ttraining's auc: 0.775811\tvalid_1's auc: 0.719176\n",
      "[21]\ttraining's auc: 0.77774\tvalid_1's auc: 0.720262\n",
      "[22]\ttraining's auc: 0.779015\tvalid_1's auc: 0.720587\n",
      "[23]\ttraining's auc: 0.781559\tvalid_1's auc: 0.720189\n",
      "[24]\ttraining's auc: 0.783062\tvalid_1's auc: 0.719355\n",
      "[25]\ttraining's auc: 0.785084\tvalid_1's auc: 0.719087\n",
      "[26]\ttraining's auc: 0.787299\tvalid_1's auc: 0.718962\n",
      "[27]\ttraining's auc: 0.788851\tvalid_1's auc: 0.719639\n",
      "[28]\ttraining's auc: 0.790496\tvalid_1's auc: 0.719064\n",
      "[29]\ttraining's auc: 0.792323\tvalid_1's auc: 0.71805\n",
      "[30]\ttraining's auc: 0.795077\tvalid_1's auc: 0.717714\n",
      "[31]\ttraining's auc: 0.797158\tvalid_1's auc: 0.717307\n",
      "[32]\ttraining's auc: 0.798519\tvalid_1's auc: 0.717293\n",
      "[33]\ttraining's auc: 0.799933\tvalid_1's auc: 0.71713\n",
      "[34]\ttraining's auc: 0.801141\tvalid_1's auc: 0.717632\n",
      "[35]\ttraining's auc: 0.803256\tvalid_1's auc: 0.71998\n",
      "[36]\ttraining's auc: 0.805056\tvalid_1's auc: 0.718603\n",
      "[37]\ttraining's auc: 0.806862\tvalid_1's auc: 0.716857\n",
      "[38]\ttraining's auc: 0.808886\tvalid_1's auc: 0.716518\n",
      "[39]\ttraining's auc: 0.810547\tvalid_1's auc: 0.716288\n",
      "[40]\ttraining's auc: 0.810918\tvalid_1's auc: 0.716169\n",
      "[41]\ttraining's auc: 0.812085\tvalid_1's auc: 0.716431\n",
      "[42]\ttraining's auc: 0.813143\tvalid_1's auc: 0.716419\n",
      "[43]\ttraining's auc: 0.814966\tvalid_1's auc: 0.716727\n",
      "[44]\ttraining's auc: 0.816798\tvalid_1's auc: 0.716797\n",
      "[45]\ttraining's auc: 0.817924\tvalid_1's auc: 0.716738\n",
      "[46]\ttraining's auc: 0.819013\tvalid_1's auc: 0.716703\n",
      "[47]\ttraining's auc: 0.820299\tvalid_1's auc: 0.716909\n",
      "[48]\ttraining's auc: 0.821456\tvalid_1's auc: 0.717223\n",
      "[49]\ttraining's auc: 0.822894\tvalid_1's auc: 0.716888\n",
      "[50]\ttraining's auc: 0.823792\tvalid_1's auc: 0.716787\n",
      "[51]\ttraining's auc: 0.824664\tvalid_1's auc: 0.716932\n",
      "[52]\ttraining's auc: 0.826659\tvalid_1's auc: 0.717493\n",
      "[53]\ttraining's auc: 0.828098\tvalid_1's auc: 0.717036\n",
      "[54]\ttraining's auc: 0.82976\tvalid_1's auc: 0.716836\n",
      "[55]\ttraining's auc: 0.830476\tvalid_1's auc: 0.716615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56]\ttraining's auc: 0.830912\tvalid_1's auc: 0.716638\n",
      "[57]\ttraining's auc: 0.832164\tvalid_1's auc: 0.716334\n",
      "[58]\ttraining's auc: 0.833192\tvalid_1's auc: 0.715111\n",
      "[59]\ttraining's auc: 0.834671\tvalid_1's auc: 0.714506\n",
      "[60]\ttraining's auc: 0.835229\tvalid_1's auc: 0.714775\n",
      "[61]\ttraining's auc: 0.836416\tvalid_1's auc: 0.713065\n",
      "[62]\ttraining's auc: 0.837713\tvalid_1's auc: 0.713529\n",
      "[63]\ttraining's auc: 0.839108\tvalid_1's auc: 0.713185\n",
      "[64]\ttraining's auc: 0.840485\tvalid_1's auc: 0.712505\n",
      "[65]\ttraining's auc: 0.841392\tvalid_1's auc: 0.712047\n",
      "[66]\ttraining's auc: 0.843282\tvalid_1's auc: 0.71138\n",
      "[67]\ttraining's auc: 0.845006\tvalid_1's auc: 0.711013\n",
      "[68]\ttraining's auc: 0.846287\tvalid_1's auc: 0.711876\n",
      "[69]\ttraining's auc: 0.846754\tvalid_1's auc: 0.712335\n",
      "[70]\ttraining's auc: 0.847684\tvalid_1's auc: 0.712875\n",
      "[71]\ttraining's auc: 0.848709\tvalid_1's auc: 0.713645\n",
      "[72]\ttraining's auc: 0.849553\tvalid_1's auc: 0.712986\n",
      "[73]\ttraining's auc: 0.850458\tvalid_1's auc: 0.712818\n",
      "[74]\ttraining's auc: 0.851164\tvalid_1's auc: 0.712719\n",
      "[75]\ttraining's auc: 0.852455\tvalid_1's auc: 0.712459\n",
      "[76]\ttraining's auc: 0.853865\tvalid_1's auc: 0.712047\n",
      "[77]\ttraining's auc: 0.855272\tvalid_1's auc: 0.712637\n",
      "[78]\ttraining's auc: 0.855993\tvalid_1's auc: 0.713132\n",
      "[79]\ttraining's auc: 0.856806\tvalid_1's auc: 0.712518\n",
      "[80]\ttraining's auc: 0.857503\tvalid_1's auc: 0.712123\n",
      "[81]\ttraining's auc: 0.858017\tvalid_1's auc: 0.712485\n",
      "[82]\ttraining's auc: 0.858555\tvalid_1's auc: 0.711996\n",
      "[83]\ttraining's auc: 0.859278\tvalid_1's auc: 0.712229\n",
      "[84]\ttraining's auc: 0.86056\tvalid_1's auc: 0.711474\n",
      "[85]\ttraining's auc: 0.861647\tvalid_1's auc: 0.711826\n",
      "[86]\ttraining's auc: 0.862488\tvalid_1's auc: 0.711995\n",
      "[87]\ttraining's auc: 0.863359\tvalid_1's auc: 0.711846\n",
      "[88]\ttraining's auc: 0.864696\tvalid_1's auc: 0.710984\n",
      "[89]\ttraining's auc: 0.865084\tvalid_1's auc: 0.711235\n",
      "[90]\ttraining's auc: 0.866035\tvalid_1's auc: 0.711421\n",
      "[91]\ttraining's auc: 0.867054\tvalid_1's auc: 0.71126\n",
      "[92]\ttraining's auc: 0.867829\tvalid_1's auc: 0.710478\n",
      "[93]\ttraining's auc: 0.869052\tvalid_1's auc: 0.71073\n",
      "[94]\ttraining's auc: 0.869688\tvalid_1's auc: 0.709423\n",
      "[95]\ttraining's auc: 0.870395\tvalid_1's auc: 0.709269\n",
      "[96]\ttraining's auc: 0.870932\tvalid_1's auc: 0.709538\n",
      "[97]\ttraining's auc: 0.872174\tvalid_1's auc: 0.709802\n",
      "[98]\ttraining's auc: 0.872647\tvalid_1's auc: 0.70949\n",
      "[99]\ttraining's auc: 0.87314\tvalid_1's auc: 0.710003\n",
      "[100]\ttraining's auc: 0.873404\tvalid_1's auc: 0.710018\n",
      "Fold 2: 0.71002\n",
      "[1]\ttraining's auc: 0.703098\tvalid_1's auc: 0.695377\n",
      "[2]\ttraining's auc: 0.713951\tvalid_1's auc: 0.701751\n",
      "[3]\ttraining's auc: 0.719867\tvalid_1's auc: 0.709546\n",
      "[4]\ttraining's auc: 0.727127\tvalid_1's auc: 0.711734\n",
      "[5]\ttraining's auc: 0.731403\tvalid_1's auc: 0.711554\n",
      "[6]\ttraining's auc: 0.734846\tvalid_1's auc: 0.711715\n",
      "[7]\ttraining's auc: 0.73814\tvalid_1's auc: 0.709428\n",
      "[8]\ttraining's auc: 0.742883\tvalid_1's auc: 0.714192\n",
      "[9]\ttraining's auc: 0.746694\tvalid_1's auc: 0.713551\n",
      "[10]\ttraining's auc: 0.748951\tvalid_1's auc: 0.714504\n",
      "[11]\ttraining's auc: 0.751891\tvalid_1's auc: 0.71486\n",
      "[12]\ttraining's auc: 0.756891\tvalid_1's auc: 0.717068\n",
      "[13]\ttraining's auc: 0.759787\tvalid_1's auc: 0.717248\n",
      "[14]\ttraining's auc: 0.76214\tvalid_1's auc: 0.717405\n",
      "[15]\ttraining's auc: 0.764348\tvalid_1's auc: 0.716801\n",
      "[16]\ttraining's auc: 0.766637\tvalid_1's auc: 0.715547\n",
      "[17]\ttraining's auc: 0.768951\tvalid_1's auc: 0.716612\n",
      "[18]\ttraining's auc: 0.770886\tvalid_1's auc: 0.7163\n",
      "[19]\ttraining's auc: 0.773184\tvalid_1's auc: 0.715835\n",
      "[20]\ttraining's auc: 0.774952\tvalid_1's auc: 0.715899\n",
      "[21]\ttraining's auc: 0.776907\tvalid_1's auc: 0.71542\n",
      "[22]\ttraining's auc: 0.778233\tvalid_1's auc: 0.715186\n",
      "[23]\ttraining's auc: 0.779629\tvalid_1's auc: 0.714737\n",
      "[24]\ttraining's auc: 0.782383\tvalid_1's auc: 0.715896\n",
      "[25]\ttraining's auc: 0.785108\tvalid_1's auc: 0.715549\n",
      "[26]\ttraining's auc: 0.786653\tvalid_1's auc: 0.714792\n",
      "[27]\ttraining's auc: 0.788242\tvalid_1's auc: 0.714318\n",
      "[28]\ttraining's auc: 0.790528\tvalid_1's auc: 0.713436\n",
      "[29]\ttraining's auc: 0.792868\tvalid_1's auc: 0.713694\n",
      "[30]\ttraining's auc: 0.794925\tvalid_1's auc: 0.713942\n",
      "[31]\ttraining's auc: 0.795458\tvalid_1's auc: 0.714515\n",
      "[32]\ttraining's auc: 0.796728\tvalid_1's auc: 0.714485\n",
      "[33]\ttraining's auc: 0.798243\tvalid_1's auc: 0.715123\n",
      "[34]\ttraining's auc: 0.800047\tvalid_1's auc: 0.714482\n",
      "[35]\ttraining's auc: 0.801846\tvalid_1's auc: 0.714485\n",
      "[36]\ttraining's auc: 0.803574\tvalid_1's auc: 0.715947\n",
      "[37]\ttraining's auc: 0.805209\tvalid_1's auc: 0.714317\n",
      "[38]\ttraining's auc: 0.806365\tvalid_1's auc: 0.714107\n",
      "[39]\ttraining's auc: 0.807512\tvalid_1's auc: 0.714066\n",
      "[40]\ttraining's auc: 0.808873\tvalid_1's auc: 0.713586\n",
      "[41]\ttraining's auc: 0.810156\tvalid_1's auc: 0.712161\n",
      "[42]\ttraining's auc: 0.811083\tvalid_1's auc: 0.711431\n",
      "[43]\ttraining's auc: 0.812668\tvalid_1's auc: 0.711986\n",
      "[44]\ttraining's auc: 0.814311\tvalid_1's auc: 0.710774\n",
      "[45]\ttraining's auc: 0.814937\tvalid_1's auc: 0.710581\n",
      "[46]\ttraining's auc: 0.816311\tvalid_1's auc: 0.709919\n",
      "[47]\ttraining's auc: 0.818226\tvalid_1's auc: 0.709553\n",
      "[48]\ttraining's auc: 0.819421\tvalid_1's auc: 0.708994\n",
      "[49]\ttraining's auc: 0.821123\tvalid_1's auc: 0.709136\n",
      "[50]\ttraining's auc: 0.821923\tvalid_1's auc: 0.709078\n",
      "[51]\ttraining's auc: 0.822903\tvalid_1's auc: 0.709072\n",
      "[52]\ttraining's auc: 0.824201\tvalid_1's auc: 0.709087\n",
      "[53]\ttraining's auc: 0.82589\tvalid_1's auc: 0.709504\n",
      "[54]\ttraining's auc: 0.826732\tvalid_1's auc: 0.709594\n",
      "[55]\ttraining's auc: 0.828872\tvalid_1's auc: 0.709301\n",
      "[56]\ttraining's auc: 0.82992\tvalid_1's auc: 0.708952\n",
      "[57]\ttraining's auc: 0.831475\tvalid_1's auc: 0.708625\n",
      "[58]\ttraining's auc: 0.832706\tvalid_1's auc: 0.707948\n",
      "[59]\ttraining's auc: 0.83373\tvalid_1's auc: 0.708201\n",
      "[60]\ttraining's auc: 0.834399\tvalid_1's auc: 0.707845\n",
      "[61]\ttraining's auc: 0.835288\tvalid_1's auc: 0.707581\n",
      "[62]\ttraining's auc: 0.836143\tvalid_1's auc: 0.708142\n",
      "[63]\ttraining's auc: 0.837084\tvalid_1's auc: 0.707887\n",
      "[64]\ttraining's auc: 0.838642\tvalid_1's auc: 0.70765\n",
      "[65]\ttraining's auc: 0.839478\tvalid_1's auc: 0.706712\n",
      "[66]\ttraining's auc: 0.840554\tvalid_1's auc: 0.706385\n",
      "[67]\ttraining's auc: 0.841676\tvalid_1's auc: 0.706226\n",
      "[68]\ttraining's auc: 0.842737\tvalid_1's auc: 0.70583\n",
      "[69]\ttraining's auc: 0.843764\tvalid_1's auc: 0.705594\n",
      "[70]\ttraining's auc: 0.844704\tvalid_1's auc: 0.70451\n",
      "[71]\ttraining's auc: 0.845473\tvalid_1's auc: 0.704233\n",
      "[72]\ttraining's auc: 0.84659\tvalid_1's auc: 0.704489\n",
      "[73]\ttraining's auc: 0.847414\tvalid_1's auc: 0.705024\n",
      "[74]\ttraining's auc: 0.849127\tvalid_1's auc: 0.704941\n",
      "[75]\ttraining's auc: 0.850192\tvalid_1's auc: 0.704375\n",
      "[76]\ttraining's auc: 0.850817\tvalid_1's auc: 0.704587\n",
      "[77]\ttraining's auc: 0.852323\tvalid_1's auc: 0.703981\n",
      "[78]\ttraining's auc: 0.853593\tvalid_1's auc: 0.703498\n",
      "[79]\ttraining's auc: 0.854577\tvalid_1's auc: 0.702972\n",
      "[80]\ttraining's auc: 0.855954\tvalid_1's auc: 0.703419\n",
      "[81]\ttraining's auc: 0.856975\tvalid_1's auc: 0.703161\n",
      "[82]\ttraining's auc: 0.857671\tvalid_1's auc: 0.703578\n",
      "[83]\ttraining's auc: 0.858438\tvalid_1's auc: 0.703361\n",
      "[84]\ttraining's auc: 0.860116\tvalid_1's auc: 0.703505\n",
      "[85]\ttraining's auc: 0.861194\tvalid_1's auc: 0.703872\n",
      "[86]\ttraining's auc: 0.862093\tvalid_1's auc: 0.704519\n",
      "[87]\ttraining's auc: 0.862507\tvalid_1's auc: 0.703709\n",
      "[88]\ttraining's auc: 0.863303\tvalid_1's auc: 0.703265\n",
      "[89]\ttraining's auc: 0.863501\tvalid_1's auc: 0.70355\n",
      "[90]\ttraining's auc: 0.864477\tvalid_1's auc: 0.703728\n",
      "[91]\ttraining's auc: 0.865519\tvalid_1's auc: 0.703883\n",
      "[92]\ttraining's auc: 0.866695\tvalid_1's auc: 0.703237\n",
      "[93]\ttraining's auc: 0.867488\tvalid_1's auc: 0.703259\n",
      "[94]\ttraining's auc: 0.868817\tvalid_1's auc: 0.702847\n",
      "[95]\ttraining's auc: 0.869533\tvalid_1's auc: 0.702918\n",
      "[96]\ttraining's auc: 0.869952\tvalid_1's auc: 0.703158\n",
      "[97]\ttraining's auc: 0.870606\tvalid_1's auc: 0.702275\n",
      "[98]\ttraining's auc: 0.871352\tvalid_1's auc: 0.702191\n",
      "[99]\ttraining's auc: 0.87198\tvalid_1's auc: 0.702307\n",
      "[100]\ttraining's auc: 0.8724\tvalid_1's auc: 0.702376\n",
      "Fold 3: 0.70238\n",
      "[1]\ttraining's auc: 0.704495\tvalid_1's auc: 0.683557\n",
      "[2]\ttraining's auc: 0.716291\tvalid_1's auc: 0.690935\n",
      "[3]\ttraining's auc: 0.722243\tvalid_1's auc: 0.694325\n",
      "[4]\ttraining's auc: 0.725911\tvalid_1's auc: 0.693304\n",
      "[5]\ttraining's auc: 0.73138\tvalid_1's auc: 0.697936\n",
      "[6]\ttraining's auc: 0.733909\tvalid_1's auc: 0.700612\n",
      "[7]\ttraining's auc: 0.738905\tvalid_1's auc: 0.698867\n",
      "[8]\ttraining's auc: 0.742742\tvalid_1's auc: 0.702068\n",
      "[9]\ttraining's auc: 0.745887\tvalid_1's auc: 0.702613\n",
      "[10]\ttraining's auc: 0.748683\tvalid_1's auc: 0.70247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttraining's auc: 0.750421\tvalid_1's auc: 0.701829\n",
      "[12]\ttraining's auc: 0.755774\tvalid_1's auc: 0.709015\n",
      "[13]\ttraining's auc: 0.758031\tvalid_1's auc: 0.708815\n",
      "[14]\ttraining's auc: 0.760234\tvalid_1's auc: 0.708412\n",
      "[15]\ttraining's auc: 0.762984\tvalid_1's auc: 0.711639\n",
      "[16]\ttraining's auc: 0.765241\tvalid_1's auc: 0.713188\n",
      "[17]\ttraining's auc: 0.76731\tvalid_1's auc: 0.712297\n",
      "[18]\ttraining's auc: 0.769642\tvalid_1's auc: 0.712975\n",
      "[19]\ttraining's auc: 0.77139\tvalid_1's auc: 0.71261\n",
      "[20]\ttraining's auc: 0.773277\tvalid_1's auc: 0.712083\n",
      "[21]\ttraining's auc: 0.775786\tvalid_1's auc: 0.71313\n",
      "[22]\ttraining's auc: 0.776962\tvalid_1's auc: 0.712938\n",
      "[23]\ttraining's auc: 0.778792\tvalid_1's auc: 0.713065\n",
      "[24]\ttraining's auc: 0.78133\tvalid_1's auc: 0.712791\n",
      "[25]\ttraining's auc: 0.78354\tvalid_1's auc: 0.712985\n",
      "[26]\ttraining's auc: 0.785755\tvalid_1's auc: 0.712267\n",
      "[27]\ttraining's auc: 0.787723\tvalid_1's auc: 0.712284\n",
      "[28]\ttraining's auc: 0.789685\tvalid_1's auc: 0.712778\n",
      "[29]\ttraining's auc: 0.791599\tvalid_1's auc: 0.711492\n",
      "[30]\ttraining's auc: 0.792729\tvalid_1's auc: 0.710519\n",
      "[31]\ttraining's auc: 0.794177\tvalid_1's auc: 0.710389\n",
      "[32]\ttraining's auc: 0.795003\tvalid_1's auc: 0.709862\n",
      "[33]\ttraining's auc: 0.796502\tvalid_1's auc: 0.70976\n",
      "[34]\ttraining's auc: 0.797506\tvalid_1's auc: 0.709863\n",
      "[35]\ttraining's auc: 0.798782\tvalid_1's auc: 0.709191\n",
      "[36]\ttraining's auc: 0.800669\tvalid_1's auc: 0.707664\n",
      "[37]\ttraining's auc: 0.802309\tvalid_1's auc: 0.707891\n",
      "[38]\ttraining's auc: 0.803787\tvalid_1's auc: 0.708361\n",
      "[39]\ttraining's auc: 0.805244\tvalid_1's auc: 0.707778\n",
      "[40]\ttraining's auc: 0.806965\tvalid_1's auc: 0.706866\n",
      "[41]\ttraining's auc: 0.80897\tvalid_1's auc: 0.706074\n",
      "[42]\ttraining's auc: 0.810422\tvalid_1's auc: 0.706146\n",
      "[43]\ttraining's auc: 0.811146\tvalid_1's auc: 0.705983\n",
      "[44]\ttraining's auc: 0.812673\tvalid_1's auc: 0.705755\n",
      "[45]\ttraining's auc: 0.81368\tvalid_1's auc: 0.704955\n",
      "[46]\ttraining's auc: 0.815762\tvalid_1's auc: 0.704494\n",
      "[47]\ttraining's auc: 0.816871\tvalid_1's auc: 0.705223\n",
      "[48]\ttraining's auc: 0.818367\tvalid_1's auc: 0.705168\n",
      "[49]\ttraining's auc: 0.820499\tvalid_1's auc: 0.704388\n",
      "[50]\ttraining's auc: 0.82208\tvalid_1's auc: 0.703855\n",
      "[51]\ttraining's auc: 0.823406\tvalid_1's auc: 0.703869\n",
      "[52]\ttraining's auc: 0.824189\tvalid_1's auc: 0.703403\n",
      "[53]\ttraining's auc: 0.825411\tvalid_1's auc: 0.703601\n",
      "[54]\ttraining's auc: 0.826297\tvalid_1's auc: 0.703008\n",
      "[55]\ttraining's auc: 0.826842\tvalid_1's auc: 0.70325\n",
      "[56]\ttraining's auc: 0.828396\tvalid_1's auc: 0.703375\n",
      "[57]\ttraining's auc: 0.830095\tvalid_1's auc: 0.703462\n",
      "[58]\ttraining's auc: 0.83124\tvalid_1's auc: 0.702869\n",
      "[59]\ttraining's auc: 0.832708\tvalid_1's auc: 0.702795\n",
      "[60]\ttraining's auc: 0.833942\tvalid_1's auc: 0.703355\n",
      "[61]\ttraining's auc: 0.835529\tvalid_1's auc: 0.703539\n",
      "[62]\ttraining's auc: 0.836646\tvalid_1's auc: 0.703093\n",
      "[63]\ttraining's auc: 0.837983\tvalid_1's auc: 0.702731\n",
      "[64]\ttraining's auc: 0.839636\tvalid_1's auc: 0.702258\n",
      "[65]\ttraining's auc: 0.840538\tvalid_1's auc: 0.702137\n",
      "[66]\ttraining's auc: 0.841478\tvalid_1's auc: 0.702256\n",
      "[67]\ttraining's auc: 0.84245\tvalid_1's auc: 0.702513\n",
      "[68]\ttraining's auc: 0.843624\tvalid_1's auc: 0.701919\n",
      "[69]\ttraining's auc: 0.844627\tvalid_1's auc: 0.701663\n",
      "[70]\ttraining's auc: 0.845866\tvalid_1's auc: 0.701201\n",
      "[71]\ttraining's auc: 0.847103\tvalid_1's auc: 0.701405\n",
      "[72]\ttraining's auc: 0.84818\tvalid_1's auc: 0.702539\n",
      "[73]\ttraining's auc: 0.849558\tvalid_1's auc: 0.702392\n",
      "[74]\ttraining's auc: 0.850675\tvalid_1's auc: 0.702539\n",
      "[75]\ttraining's auc: 0.851866\tvalid_1's auc: 0.702671\n",
      "[76]\ttraining's auc: 0.852323\tvalid_1's auc: 0.702863\n",
      "[77]\ttraining's auc: 0.853259\tvalid_1's auc: 0.702137\n",
      "[78]\ttraining's auc: 0.854757\tvalid_1's auc: 0.702554\n",
      "[79]\ttraining's auc: 0.855728\tvalid_1's auc: 0.70249\n",
      "[80]\ttraining's auc: 0.857163\tvalid_1's auc: 0.702675\n",
      "[81]\ttraining's auc: 0.858517\tvalid_1's auc: 0.701739\n",
      "[82]\ttraining's auc: 0.859131\tvalid_1's auc: 0.70203\n",
      "[83]\ttraining's auc: 0.860671\tvalid_1's auc: 0.701733\n",
      "[84]\ttraining's auc: 0.861241\tvalid_1's auc: 0.701803\n",
      "[85]\ttraining's auc: 0.862809\tvalid_1's auc: 0.701735\n",
      "[86]\ttraining's auc: 0.863526\tvalid_1's auc: 0.70136\n",
      "[87]\ttraining's auc: 0.864027\tvalid_1's auc: 0.700935\n",
      "[88]\ttraining's auc: 0.864952\tvalid_1's auc: 0.700876\n",
      "[89]\ttraining's auc: 0.865653\tvalid_1's auc: 0.701726\n",
      "[90]\ttraining's auc: 0.866687\tvalid_1's auc: 0.701271\n",
      "[91]\ttraining's auc: 0.867153\tvalid_1's auc: 0.70029\n",
      "[92]\ttraining's auc: 0.86801\tvalid_1's auc: 0.699466\n",
      "[93]\ttraining's auc: 0.868859\tvalid_1's auc: 0.697799\n",
      "[94]\ttraining's auc: 0.869116\tvalid_1's auc: 0.697776\n",
      "[95]\ttraining's auc: 0.86972\tvalid_1's auc: 0.697833\n",
      "[96]\ttraining's auc: 0.87062\tvalid_1's auc: 0.698476\n",
      "[97]\ttraining's auc: 0.871488\tvalid_1's auc: 0.697828\n",
      "[98]\ttraining's auc: 0.872092\tvalid_1's auc: 0.698116\n",
      "[99]\ttraining's auc: 0.872993\tvalid_1's auc: 0.698113\n",
      "[100]\ttraining's auc: 0.873511\tvalid_1's auc: 0.698253\n",
      "Fold 4: 0.69825\n",
      "[1]\ttraining's auc: 0.70232\tvalid_1's auc: 0.705202\n",
      "[2]\ttraining's auc: 0.711697\tvalid_1's auc: 0.717341\n",
      "[3]\ttraining's auc: 0.716187\tvalid_1's auc: 0.721153\n",
      "[4]\ttraining's auc: 0.720819\tvalid_1's auc: 0.726104\n",
      "[5]\ttraining's auc: 0.725668\tvalid_1's auc: 0.72941\n",
      "[6]\ttraining's auc: 0.730069\tvalid_1's auc: 0.729621\n",
      "[7]\ttraining's auc: 0.733196\tvalid_1's auc: 0.728446\n",
      "[8]\ttraining's auc: 0.738697\tvalid_1's auc: 0.731417\n",
      "[9]\ttraining's auc: 0.74178\tvalid_1's auc: 0.732854\n",
      "[10]\ttraining's auc: 0.74466\tvalid_1's auc: 0.73297\n",
      "[11]\ttraining's auc: 0.746888\tvalid_1's auc: 0.732697\n",
      "[12]\ttraining's auc: 0.750823\tvalid_1's auc: 0.734339\n",
      "[13]\ttraining's auc: 0.753391\tvalid_1's auc: 0.735597\n",
      "[14]\ttraining's auc: 0.755116\tvalid_1's auc: 0.73639\n",
      "[15]\ttraining's auc: 0.758935\tvalid_1's auc: 0.739444\n",
      "[16]\ttraining's auc: 0.761198\tvalid_1's auc: 0.738195\n",
      "[17]\ttraining's auc: 0.762465\tvalid_1's auc: 0.738418\n",
      "[18]\ttraining's auc: 0.765025\tvalid_1's auc: 0.736783\n",
      "[19]\ttraining's auc: 0.767737\tvalid_1's auc: 0.73566\n",
      "[20]\ttraining's auc: 0.769602\tvalid_1's auc: 0.736136\n",
      "[21]\ttraining's auc: 0.770878\tvalid_1's auc: 0.73661\n",
      "[22]\ttraining's auc: 0.772834\tvalid_1's auc: 0.736192\n",
      "[23]\ttraining's auc: 0.775536\tvalid_1's auc: 0.73551\n",
      "[24]\ttraining's auc: 0.778269\tvalid_1's auc: 0.735173\n",
      "[25]\ttraining's auc: 0.78019\tvalid_1's auc: 0.735315\n",
      "[26]\ttraining's auc: 0.783072\tvalid_1's auc: 0.737318\n",
      "[27]\ttraining's auc: 0.785035\tvalid_1's auc: 0.736815\n",
      "[28]\ttraining's auc: 0.78706\tvalid_1's auc: 0.737399\n",
      "[29]\ttraining's auc: 0.788627\tvalid_1's auc: 0.736448\n",
      "[30]\ttraining's auc: 0.790352\tvalid_1's auc: 0.736234\n",
      "[31]\ttraining's auc: 0.791996\tvalid_1's auc: 0.735866\n",
      "[32]\ttraining's auc: 0.794375\tvalid_1's auc: 0.735804\n",
      "[33]\ttraining's auc: 0.795572\tvalid_1's auc: 0.736488\n",
      "[34]\ttraining's auc: 0.796878\tvalid_1's auc: 0.735983\n",
      "[35]\ttraining's auc: 0.798314\tvalid_1's auc: 0.735923\n",
      "[36]\ttraining's auc: 0.799473\tvalid_1's auc: 0.73679\n",
      "[37]\ttraining's auc: 0.800672\tvalid_1's auc: 0.736438\n",
      "[38]\ttraining's auc: 0.80187\tvalid_1's auc: 0.736534\n",
      "[39]\ttraining's auc: 0.802972\tvalid_1's auc: 0.736933\n",
      "[40]\ttraining's auc: 0.80471\tvalid_1's auc: 0.736612\n",
      "[41]\ttraining's auc: 0.805652\tvalid_1's auc: 0.73666\n",
      "[42]\ttraining's auc: 0.807029\tvalid_1's auc: 0.736105\n",
      "[43]\ttraining's auc: 0.808865\tvalid_1's auc: 0.736645\n",
      "[44]\ttraining's auc: 0.810201\tvalid_1's auc: 0.736575\n",
      "[45]\ttraining's auc: 0.811976\tvalid_1's auc: 0.736224\n",
      "[46]\ttraining's auc: 0.813492\tvalid_1's auc: 0.735837\n",
      "[47]\ttraining's auc: 0.81494\tvalid_1's auc: 0.735261\n",
      "[48]\ttraining's auc: 0.816044\tvalid_1's auc: 0.734375\n",
      "[49]\ttraining's auc: 0.816655\tvalid_1's auc: 0.73389\n",
      "[50]\ttraining's auc: 0.817074\tvalid_1's auc: 0.734102\n",
      "[51]\ttraining's auc: 0.818747\tvalid_1's auc: 0.734878\n",
      "[52]\ttraining's auc: 0.820869\tvalid_1's auc: 0.734536\n",
      "[53]\ttraining's auc: 0.821816\tvalid_1's auc: 0.734556\n",
      "[54]\ttraining's auc: 0.823005\tvalid_1's auc: 0.734432\n",
      "[55]\ttraining's auc: 0.824467\tvalid_1's auc: 0.734799\n",
      "[56]\ttraining's auc: 0.82561\tvalid_1's auc: 0.734477\n",
      "[57]\ttraining's auc: 0.826686\tvalid_1's auc: 0.734381\n",
      "[58]\ttraining's auc: 0.827655\tvalid_1's auc: 0.733687\n",
      "[59]\ttraining's auc: 0.828877\tvalid_1's auc: 0.733643\n",
      "[60]\ttraining's auc: 0.830013\tvalid_1's auc: 0.734189\n",
      "[61]\ttraining's auc: 0.832486\tvalid_1's auc: 0.733218\n",
      "[62]\ttraining's auc: 0.834188\tvalid_1's auc: 0.736143\n",
      "[63]\ttraining's auc: 0.835526\tvalid_1's auc: 0.736646\n",
      "[64]\ttraining's auc: 0.837447\tvalid_1's auc: 0.736374\n",
      "[65]\ttraining's auc: 0.83846\tvalid_1's auc: 0.736246\n",
      "[66]\ttraining's auc: 0.839849\tvalid_1's auc: 0.735922\n",
      "[67]\ttraining's auc: 0.84075\tvalid_1's auc: 0.736464\n",
      "[68]\ttraining's auc: 0.84139\tvalid_1's auc: 0.736801\n",
      "[69]\ttraining's auc: 0.842125\tvalid_1's auc: 0.737707\n",
      "[70]\ttraining's auc: 0.843358\tvalid_1's auc: 0.738244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\ttraining's auc: 0.844704\tvalid_1's auc: 0.737588\n",
      "[72]\ttraining's auc: 0.845473\tvalid_1's auc: 0.73727\n",
      "[73]\ttraining's auc: 0.846804\tvalid_1's auc: 0.737637\n",
      "[74]\ttraining's auc: 0.847968\tvalid_1's auc: 0.737276\n",
      "[75]\ttraining's auc: 0.848809\tvalid_1's auc: 0.736802\n",
      "[76]\ttraining's auc: 0.850151\tvalid_1's auc: 0.736708\n",
      "[77]\ttraining's auc: 0.850801\tvalid_1's auc: 0.737085\n",
      "[78]\ttraining's auc: 0.851808\tvalid_1's auc: 0.736493\n",
      "[79]\ttraining's auc: 0.853159\tvalid_1's auc: 0.737832\n",
      "[80]\ttraining's auc: 0.854203\tvalid_1's auc: 0.737499\n",
      "[81]\ttraining's auc: 0.855266\tvalid_1's auc: 0.738077\n",
      "[82]\ttraining's auc: 0.856328\tvalid_1's auc: 0.737948\n",
      "[83]\ttraining's auc: 0.856637\tvalid_1's auc: 0.738293\n",
      "[84]\ttraining's auc: 0.857817\tvalid_1's auc: 0.738421\n",
      "[85]\ttraining's auc: 0.858704\tvalid_1's auc: 0.738808\n",
      "[86]\ttraining's auc: 0.859485\tvalid_1's auc: 0.738682\n",
      "[87]\ttraining's auc: 0.860282\tvalid_1's auc: 0.739017\n",
      "[88]\ttraining's auc: 0.861258\tvalid_1's auc: 0.738801\n",
      "[89]\ttraining's auc: 0.862045\tvalid_1's auc: 0.737488\n",
      "[90]\ttraining's auc: 0.862371\tvalid_1's auc: 0.737221\n",
      "[91]\ttraining's auc: 0.863047\tvalid_1's auc: 0.737525\n",
      "[92]\ttraining's auc: 0.863756\tvalid_1's auc: 0.73762\n",
      "[93]\ttraining's auc: 0.864344\tvalid_1's auc: 0.737131\n",
      "[94]\ttraining's auc: 0.865358\tvalid_1's auc: 0.737276\n",
      "[95]\ttraining's auc: 0.865509\tvalid_1's auc: 0.737958\n",
      "[96]\ttraining's auc: 0.866049\tvalid_1's auc: 0.737832\n",
      "[97]\ttraining's auc: 0.866885\tvalid_1's auc: 0.737763\n",
      "[98]\ttraining's auc: 0.867217\tvalid_1's auc: 0.737733\n",
      "[99]\ttraining's auc: 0.868092\tvalid_1's auc: 0.737845\n",
      "[100]\ttraining's auc: 0.869079\tvalid_1's auc: 0.737696\n",
      "Fold 5: 0.7377\n",
      "[1]\ttraining's auc: 0.700996\tvalid_1's auc: 0.683109\n",
      "[2]\ttraining's auc: 0.713008\tvalid_1's auc: 0.690159\n",
      "[3]\ttraining's auc: 0.71888\tvalid_1's auc: 0.69203\n",
      "[4]\ttraining's auc: 0.725322\tvalid_1's auc: 0.696426\n",
      "[5]\ttraining's auc: 0.731045\tvalid_1's auc: 0.701097\n",
      "[6]\ttraining's auc: 0.73465\tvalid_1's auc: 0.700585\n",
      "[7]\ttraining's auc: 0.737314\tvalid_1's auc: 0.700978\n",
      "[8]\ttraining's auc: 0.740571\tvalid_1's auc: 0.701354\n",
      "[9]\ttraining's auc: 0.743229\tvalid_1's auc: 0.700077\n",
      "[10]\ttraining's auc: 0.746398\tvalid_1's auc: 0.699153\n",
      "[11]\ttraining's auc: 0.748577\tvalid_1's auc: 0.700182\n",
      "[12]\ttraining's auc: 0.752348\tvalid_1's auc: 0.702325\n",
      "[13]\ttraining's auc: 0.754426\tvalid_1's auc: 0.704267\n",
      "[14]\ttraining's auc: 0.75719\tvalid_1's auc: 0.704482\n",
      "[15]\ttraining's auc: 0.759318\tvalid_1's auc: 0.704571\n",
      "[16]\ttraining's auc: 0.761686\tvalid_1's auc: 0.704725\n",
      "[17]\ttraining's auc: 0.763118\tvalid_1's auc: 0.705007\n",
      "[18]\ttraining's auc: 0.765069\tvalid_1's auc: 0.705578\n",
      "[19]\ttraining's auc: 0.767218\tvalid_1's auc: 0.705278\n",
      "[20]\ttraining's auc: 0.77045\tvalid_1's auc: 0.707977\n",
      "[21]\ttraining's auc: 0.772339\tvalid_1's auc: 0.707459\n",
      "[22]\ttraining's auc: 0.775244\tvalid_1's auc: 0.708167\n",
      "[23]\ttraining's auc: 0.777222\tvalid_1's auc: 0.708056\n",
      "[24]\ttraining's auc: 0.779013\tvalid_1's auc: 0.707681\n",
      "[25]\ttraining's auc: 0.780834\tvalid_1's auc: 0.706411\n",
      "[26]\ttraining's auc: 0.78281\tvalid_1's auc: 0.706564\n",
      "[27]\ttraining's auc: 0.784269\tvalid_1's auc: 0.706839\n",
      "[28]\ttraining's auc: 0.78616\tvalid_1's auc: 0.706415\n",
      "[29]\ttraining's auc: 0.787828\tvalid_1's auc: 0.70699\n",
      "[30]\ttraining's auc: 0.789313\tvalid_1's auc: 0.707069\n",
      "[31]\ttraining's auc: 0.791031\tvalid_1's auc: 0.706578\n",
      "[32]\ttraining's auc: 0.792731\tvalid_1's auc: 0.707048\n",
      "[33]\ttraining's auc: 0.794173\tvalid_1's auc: 0.706289\n",
      "[34]\ttraining's auc: 0.795671\tvalid_1's auc: 0.705933\n",
      "[35]\ttraining's auc: 0.797149\tvalid_1's auc: 0.705863\n",
      "[36]\ttraining's auc: 0.798544\tvalid_1's auc: 0.705095\n",
      "[37]\ttraining's auc: 0.800173\tvalid_1's auc: 0.704736\n",
      "[38]\ttraining's auc: 0.80214\tvalid_1's auc: 0.704851\n",
      "[39]\ttraining's auc: 0.804491\tvalid_1's auc: 0.704867\n",
      "[40]\ttraining's auc: 0.806218\tvalid_1's auc: 0.704274\n",
      "[41]\ttraining's auc: 0.808578\tvalid_1's auc: 0.703966\n",
      "[42]\ttraining's auc: 0.810368\tvalid_1's auc: 0.70374\n",
      "[43]\ttraining's auc: 0.813004\tvalid_1's auc: 0.703912\n",
      "[44]\ttraining's auc: 0.814187\tvalid_1's auc: 0.702659\n",
      "[45]\ttraining's auc: 0.81527\tvalid_1's auc: 0.702475\n",
      "[46]\ttraining's auc: 0.815897\tvalid_1's auc: 0.702247\n",
      "[47]\ttraining's auc: 0.817703\tvalid_1's auc: 0.701969\n",
      "[48]\ttraining's auc: 0.818667\tvalid_1's auc: 0.701308\n",
      "[49]\ttraining's auc: 0.820063\tvalid_1's auc: 0.700946\n",
      "[50]\ttraining's auc: 0.821081\tvalid_1's auc: 0.700462\n",
      "[51]\ttraining's auc: 0.822047\tvalid_1's auc: 0.699668\n",
      "[52]\ttraining's auc: 0.822993\tvalid_1's auc: 0.69945\n",
      "[53]\ttraining's auc: 0.824305\tvalid_1's auc: 0.700317\n",
      "[54]\ttraining's auc: 0.825434\tvalid_1's auc: 0.699471\n",
      "[55]\ttraining's auc: 0.826303\tvalid_1's auc: 0.699527\n",
      "[56]\ttraining's auc: 0.82809\tvalid_1's auc: 0.699487\n",
      "[57]\ttraining's auc: 0.829362\tvalid_1's auc: 0.699362\n",
      "[58]\ttraining's auc: 0.830604\tvalid_1's auc: 0.699408\n",
      "[59]\ttraining's auc: 0.831708\tvalid_1's auc: 0.699054\n",
      "[60]\ttraining's auc: 0.83271\tvalid_1's auc: 0.699202\n",
      "[61]\ttraining's auc: 0.834361\tvalid_1's auc: 0.698912\n",
      "[62]\ttraining's auc: 0.835434\tvalid_1's auc: 0.698643\n",
      "[63]\ttraining's auc: 0.836973\tvalid_1's auc: 0.69868\n",
      "[64]\ttraining's auc: 0.839217\tvalid_1's auc: 0.697846\n",
      "[65]\ttraining's auc: 0.840318\tvalid_1's auc: 0.698565\n",
      "[66]\ttraining's auc: 0.841451\tvalid_1's auc: 0.698127\n",
      "[67]\ttraining's auc: 0.841942\tvalid_1's auc: 0.698272\n",
      "[68]\ttraining's auc: 0.843463\tvalid_1's auc: 0.697816\n",
      "[69]\ttraining's auc: 0.844518\tvalid_1's auc: 0.697873\n",
      "[70]\ttraining's auc: 0.845605\tvalid_1's auc: 0.696916\n",
      "[71]\ttraining's auc: 0.846776\tvalid_1's auc: 0.69765\n",
      "[72]\ttraining's auc: 0.84759\tvalid_1's auc: 0.697851\n",
      "[73]\ttraining's auc: 0.847968\tvalid_1's auc: 0.697025\n",
      "[74]\ttraining's auc: 0.848748\tvalid_1's auc: 0.696393\n",
      "[75]\ttraining's auc: 0.849214\tvalid_1's auc: 0.696078\n",
      "[76]\ttraining's auc: 0.850613\tvalid_1's auc: 0.695939\n",
      "[77]\ttraining's auc: 0.851224\tvalid_1's auc: 0.696899\n",
      "[78]\ttraining's auc: 0.852174\tvalid_1's auc: 0.697242\n",
      "[79]\ttraining's auc: 0.853356\tvalid_1's auc: 0.698751\n",
      "[80]\ttraining's auc: 0.853739\tvalid_1's auc: 0.698965\n",
      "[81]\ttraining's auc: 0.854396\tvalid_1's auc: 0.699072\n",
      "[82]\ttraining's auc: 0.855312\tvalid_1's auc: 0.698741\n",
      "[83]\ttraining's auc: 0.856138\tvalid_1's auc: 0.698354\n",
      "[84]\ttraining's auc: 0.856909\tvalid_1's auc: 0.698037\n",
      "[85]\ttraining's auc: 0.857684\tvalid_1's auc: 0.698258\n",
      "[86]\ttraining's auc: 0.858302\tvalid_1's auc: 0.6982\n",
      "[87]\ttraining's auc: 0.859161\tvalid_1's auc: 0.697809\n",
      "[88]\ttraining's auc: 0.860163\tvalid_1's auc: 0.697642\n",
      "[89]\ttraining's auc: 0.860871\tvalid_1's auc: 0.697489\n",
      "[90]\ttraining's auc: 0.862073\tvalid_1's auc: 0.696271\n",
      "[91]\ttraining's auc: 0.862903\tvalid_1's auc: 0.695168\n",
      "[92]\ttraining's auc: 0.863756\tvalid_1's auc: 0.695733\n",
      "[93]\ttraining's auc: 0.86556\tvalid_1's auc: 0.695647\n",
      "[94]\ttraining's auc: 0.866794\tvalid_1's auc: 0.69448\n",
      "[95]\ttraining's auc: 0.868771\tvalid_1's auc: 0.694213\n",
      "[96]\ttraining's auc: 0.8695\tvalid_1's auc: 0.694027\n",
      "[97]\ttraining's auc: 0.870741\tvalid_1's auc: 0.695133\n",
      "[98]\ttraining's auc: 0.871253\tvalid_1's auc: 0.695058\n",
      "[99]\ttraining's auc: 0.872078\tvalid_1's auc: 0.695284\n",
      "[100]\ttraining's auc: 0.872958\tvalid_1's auc: 0.694779\n",
      "Fold 6: 0.69478\n",
      "[1]\ttraining's auc: 0.700126\tvalid_1's auc: 0.706269\n",
      "[2]\ttraining's auc: 0.71132\tvalid_1's auc: 0.711817\n",
      "[3]\ttraining's auc: 0.718051\tvalid_1's auc: 0.712368\n",
      "[4]\ttraining's auc: 0.725602\tvalid_1's auc: 0.71565\n",
      "[5]\ttraining's auc: 0.729765\tvalid_1's auc: 0.717614\n",
      "[6]\ttraining's auc: 0.732647\tvalid_1's auc: 0.719988\n",
      "[7]\ttraining's auc: 0.735718\tvalid_1's auc: 0.719451\n",
      "[8]\ttraining's auc: 0.740026\tvalid_1's auc: 0.723123\n",
      "[9]\ttraining's auc: 0.742299\tvalid_1's auc: 0.722377\n",
      "[10]\ttraining's auc: 0.744324\tvalid_1's auc: 0.721364\n",
      "[11]\ttraining's auc: 0.747204\tvalid_1's auc: 0.720731\n",
      "[12]\ttraining's auc: 0.752252\tvalid_1's auc: 0.725706\n",
      "[13]\ttraining's auc: 0.755863\tvalid_1's auc: 0.725798\n",
      "[14]\ttraining's auc: 0.758385\tvalid_1's auc: 0.725193\n",
      "[15]\ttraining's auc: 0.761553\tvalid_1's auc: 0.727013\n",
      "[16]\ttraining's auc: 0.764074\tvalid_1's auc: 0.726323\n",
      "[17]\ttraining's auc: 0.766859\tvalid_1's auc: 0.725209\n",
      "[18]\ttraining's auc: 0.769289\tvalid_1's auc: 0.724079\n",
      "[19]\ttraining's auc: 0.771232\tvalid_1's auc: 0.723349\n",
      "[20]\ttraining's auc: 0.774218\tvalid_1's auc: 0.72521\n",
      "[21]\ttraining's auc: 0.775755\tvalid_1's auc: 0.725592\n",
      "[22]\ttraining's auc: 0.777977\tvalid_1's auc: 0.726216\n",
      "[23]\ttraining's auc: 0.779716\tvalid_1's auc: 0.725438\n",
      "[24]\ttraining's auc: 0.781689\tvalid_1's auc: 0.726065\n",
      "[25]\ttraining's auc: 0.783556\tvalid_1's auc: 0.727247\n",
      "[26]\ttraining's auc: 0.78524\tvalid_1's auc: 0.72727\n",
      "[27]\ttraining's auc: 0.786929\tvalid_1's auc: 0.726596\n",
      "[28]\ttraining's auc: 0.788921\tvalid_1's auc: 0.725434\n",
      "[29]\ttraining's auc: 0.791341\tvalid_1's auc: 0.724904\n",
      "[30]\ttraining's auc: 0.792707\tvalid_1's auc: 0.723872\n",
      "[31]\ttraining's auc: 0.794005\tvalid_1's auc: 0.724195\n",
      "[32]\ttraining's auc: 0.797113\tvalid_1's auc: 0.723587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttraining's auc: 0.798511\tvalid_1's auc: 0.723126\n",
      "[34]\ttraining's auc: 0.800909\tvalid_1's auc: 0.722544\n",
      "[35]\ttraining's auc: 0.802481\tvalid_1's auc: 0.722214\n",
      "[36]\ttraining's auc: 0.804269\tvalid_1's auc: 0.721205\n",
      "[37]\ttraining's auc: 0.805925\tvalid_1's auc: 0.72018\n",
      "[38]\ttraining's auc: 0.807213\tvalid_1's auc: 0.720333\n",
      "[39]\ttraining's auc: 0.808298\tvalid_1's auc: 0.720471\n",
      "[40]\ttraining's auc: 0.810307\tvalid_1's auc: 0.720351\n",
      "[41]\ttraining's auc: 0.811718\tvalid_1's auc: 0.719739\n",
      "[42]\ttraining's auc: 0.81315\tvalid_1's auc: 0.719438\n",
      "[43]\ttraining's auc: 0.81357\tvalid_1's auc: 0.719014\n",
      "[44]\ttraining's auc: 0.814976\tvalid_1's auc: 0.718856\n",
      "[45]\ttraining's auc: 0.81588\tvalid_1's auc: 0.718116\n",
      "[46]\ttraining's auc: 0.817535\tvalid_1's auc: 0.718309\n",
      "[47]\ttraining's auc: 0.818775\tvalid_1's auc: 0.718233\n",
      "[48]\ttraining's auc: 0.819817\tvalid_1's auc: 0.717664\n",
      "[49]\ttraining's auc: 0.820763\tvalid_1's auc: 0.717883\n",
      "[50]\ttraining's auc: 0.822726\tvalid_1's auc: 0.718191\n",
      "[51]\ttraining's auc: 0.824078\tvalid_1's auc: 0.719183\n",
      "[52]\ttraining's auc: 0.82474\tvalid_1's auc: 0.719156\n",
      "[53]\ttraining's auc: 0.826215\tvalid_1's auc: 0.71859\n",
      "[54]\ttraining's auc: 0.827383\tvalid_1's auc: 0.71838\n",
      "[55]\ttraining's auc: 0.828498\tvalid_1's auc: 0.718101\n",
      "[56]\ttraining's auc: 0.82954\tvalid_1's auc: 0.718006\n",
      "[57]\ttraining's auc: 0.831134\tvalid_1's auc: 0.718865\n",
      "[58]\ttraining's auc: 0.832566\tvalid_1's auc: 0.717074\n",
      "[59]\ttraining's auc: 0.833862\tvalid_1's auc: 0.717231\n",
      "[60]\ttraining's auc: 0.834639\tvalid_1's auc: 0.717397\n",
      "[61]\ttraining's auc: 0.835748\tvalid_1's auc: 0.716897\n",
      "[62]\ttraining's auc: 0.836699\tvalid_1's auc: 0.71642\n",
      "[63]\ttraining's auc: 0.838202\tvalid_1's auc: 0.716337\n",
      "[64]\ttraining's auc: 0.840092\tvalid_1's auc: 0.715907\n",
      "[65]\ttraining's auc: 0.840919\tvalid_1's auc: 0.715285\n",
      "[66]\ttraining's auc: 0.842199\tvalid_1's auc: 0.715099\n",
      "[67]\ttraining's auc: 0.843496\tvalid_1's auc: 0.714618\n",
      "[68]\ttraining's auc: 0.84512\tvalid_1's auc: 0.714284\n",
      "[69]\ttraining's auc: 0.846272\tvalid_1's auc: 0.713407\n",
      "[70]\ttraining's auc: 0.847292\tvalid_1's auc: 0.71365\n",
      "[71]\ttraining's auc: 0.848211\tvalid_1's auc: 0.712883\n",
      "[72]\ttraining's auc: 0.849004\tvalid_1's auc: 0.712815\n",
      "[73]\ttraining's auc: 0.850472\tvalid_1's auc: 0.711824\n",
      "[74]\ttraining's auc: 0.851295\tvalid_1's auc: 0.711881\n",
      "[75]\ttraining's auc: 0.852192\tvalid_1's auc: 0.711896\n",
      "[76]\ttraining's auc: 0.853092\tvalid_1's auc: 0.712041\n",
      "[77]\ttraining's auc: 0.85419\tvalid_1's auc: 0.711411\n",
      "[78]\ttraining's auc: 0.854754\tvalid_1's auc: 0.71128\n",
      "[79]\ttraining's auc: 0.85591\tvalid_1's auc: 0.711032\n",
      "[80]\ttraining's auc: 0.856808\tvalid_1's auc: 0.711397\n",
      "[81]\ttraining's auc: 0.857983\tvalid_1's auc: 0.710866\n",
      "[82]\ttraining's auc: 0.858953\tvalid_1's auc: 0.711449\n",
      "[83]\ttraining's auc: 0.859884\tvalid_1's auc: 0.71107\n",
      "[84]\ttraining's auc: 0.861058\tvalid_1's auc: 0.710988\n",
      "[85]\ttraining's auc: 0.862684\tvalid_1's auc: 0.710804\n",
      "[86]\ttraining's auc: 0.863427\tvalid_1's auc: 0.710277\n",
      "[87]\ttraining's auc: 0.864324\tvalid_1's auc: 0.709862\n",
      "[88]\ttraining's auc: 0.865411\tvalid_1's auc: 0.710173\n",
      "[89]\ttraining's auc: 0.866418\tvalid_1's auc: 0.709404\n",
      "[90]\ttraining's auc: 0.867481\tvalid_1's auc: 0.708933\n",
      "[91]\ttraining's auc: 0.868461\tvalid_1's auc: 0.708002\n",
      "[92]\ttraining's auc: 0.869313\tvalid_1's auc: 0.707691\n",
      "[93]\ttraining's auc: 0.870171\tvalid_1's auc: 0.707411\n",
      "[94]\ttraining's auc: 0.871033\tvalid_1's auc: 0.707201\n",
      "[95]\ttraining's auc: 0.871642\tvalid_1's auc: 0.707507\n",
      "[96]\ttraining's auc: 0.872515\tvalid_1's auc: 0.707184\n",
      "[97]\ttraining's auc: 0.873333\tvalid_1's auc: 0.707485\n",
      "[98]\ttraining's auc: 0.874205\tvalid_1's auc: 0.70716\n",
      "[99]\ttraining's auc: 0.87489\tvalid_1's auc: 0.707312\n",
      "[100]\ttraining's auc: 0.87575\tvalid_1's auc: 0.708446\n",
      "Fold 7: 0.70845\n",
      "[1]\ttraining's auc: 0.704157\tvalid_1's auc: 0.687959\n",
      "[2]\ttraining's auc: 0.713788\tvalid_1's auc: 0.698095\n",
      "[3]\ttraining's auc: 0.718681\tvalid_1's auc: 0.699308\n",
      "[4]\ttraining's auc: 0.726751\tvalid_1's auc: 0.70383\n",
      "[5]\ttraining's auc: 0.732687\tvalid_1's auc: 0.708692\n",
      "[6]\ttraining's auc: 0.73466\tvalid_1's auc: 0.709271\n",
      "[7]\ttraining's auc: 0.73774\tvalid_1's auc: 0.708781\n",
      "[8]\ttraining's auc: 0.741897\tvalid_1's auc: 0.710986\n",
      "[9]\ttraining's auc: 0.745663\tvalid_1's auc: 0.713069\n",
      "[10]\ttraining's auc: 0.747978\tvalid_1's auc: 0.712317\n",
      "[11]\ttraining's auc: 0.750735\tvalid_1's auc: 0.713606\n",
      "[12]\ttraining's auc: 0.754685\tvalid_1's auc: 0.716137\n",
      "[13]\ttraining's auc: 0.758031\tvalid_1's auc: 0.716365\n",
      "[14]\ttraining's auc: 0.75989\tvalid_1's auc: 0.716\n",
      "[15]\ttraining's auc: 0.762865\tvalid_1's auc: 0.718489\n",
      "[16]\ttraining's auc: 0.76499\tvalid_1's auc: 0.718176\n",
      "[17]\ttraining's auc: 0.767215\tvalid_1's auc: 0.717998\n",
      "[18]\ttraining's auc: 0.770558\tvalid_1's auc: 0.71747\n",
      "[19]\ttraining's auc: 0.772298\tvalid_1's auc: 0.718103\n",
      "[20]\ttraining's auc: 0.773819\tvalid_1's auc: 0.717209\n",
      "[21]\ttraining's auc: 0.775631\tvalid_1's auc: 0.717876\n",
      "[22]\ttraining's auc: 0.777855\tvalid_1's auc: 0.717135\n",
      "[23]\ttraining's auc: 0.779742\tvalid_1's auc: 0.716264\n",
      "[24]\ttraining's auc: 0.781542\tvalid_1's auc: 0.716851\n",
      "[25]\ttraining's auc: 0.782609\tvalid_1's auc: 0.715949\n",
      "[26]\ttraining's auc: 0.784429\tvalid_1's auc: 0.715968\n",
      "[27]\ttraining's auc: 0.785942\tvalid_1's auc: 0.715197\n",
      "[28]\ttraining's auc: 0.787747\tvalid_1's auc: 0.714312\n",
      "[29]\ttraining's auc: 0.789545\tvalid_1's auc: 0.71409\n",
      "[30]\ttraining's auc: 0.791007\tvalid_1's auc: 0.713922\n",
      "[31]\ttraining's auc: 0.792659\tvalid_1's auc: 0.713695\n",
      "[32]\ttraining's auc: 0.794972\tvalid_1's auc: 0.713322\n",
      "[33]\ttraining's auc: 0.796769\tvalid_1's auc: 0.713025\n",
      "[34]\ttraining's auc: 0.79837\tvalid_1's auc: 0.712965\n",
      "[35]\ttraining's auc: 0.799476\tvalid_1's auc: 0.713175\n",
      "[36]\ttraining's auc: 0.800836\tvalid_1's auc: 0.712675\n",
      "[37]\ttraining's auc: 0.802161\tvalid_1's auc: 0.712885\n",
      "[38]\ttraining's auc: 0.803284\tvalid_1's auc: 0.713222\n",
      "[39]\ttraining's auc: 0.804096\tvalid_1's auc: 0.712855\n",
      "[40]\ttraining's auc: 0.805421\tvalid_1's auc: 0.712782\n",
      "[41]\ttraining's auc: 0.806332\tvalid_1's auc: 0.712783\n",
      "[42]\ttraining's auc: 0.807561\tvalid_1's auc: 0.712706\n",
      "[43]\ttraining's auc: 0.809511\tvalid_1's auc: 0.712008\n",
      "[44]\ttraining's auc: 0.81035\tvalid_1's auc: 0.711576\n",
      "[45]\ttraining's auc: 0.811523\tvalid_1's auc: 0.710322\n",
      "[46]\ttraining's auc: 0.812276\tvalid_1's auc: 0.710488\n",
      "[47]\ttraining's auc: 0.813534\tvalid_1's auc: 0.709406\n",
      "[48]\ttraining's auc: 0.814761\tvalid_1's auc: 0.709117\n",
      "[49]\ttraining's auc: 0.816058\tvalid_1's auc: 0.710159\n",
      "[50]\ttraining's auc: 0.817449\tvalid_1's auc: 0.710294\n",
      "[51]\ttraining's auc: 0.818647\tvalid_1's auc: 0.709211\n",
      "[52]\ttraining's auc: 0.820453\tvalid_1's auc: 0.708273\n",
      "[53]\ttraining's auc: 0.821765\tvalid_1's auc: 0.708287\n",
      "[54]\ttraining's auc: 0.823439\tvalid_1's auc: 0.707614\n",
      "[55]\ttraining's auc: 0.82463\tvalid_1's auc: 0.70779\n",
      "[56]\ttraining's auc: 0.825861\tvalid_1's auc: 0.707101\n",
      "[57]\ttraining's auc: 0.827102\tvalid_1's auc: 0.706318\n",
      "[58]\ttraining's auc: 0.828273\tvalid_1's auc: 0.706502\n",
      "[59]\ttraining's auc: 0.829847\tvalid_1's auc: 0.706342\n",
      "[60]\ttraining's auc: 0.831224\tvalid_1's auc: 0.706093\n",
      "[61]\ttraining's auc: 0.832108\tvalid_1's auc: 0.706158\n",
      "[62]\ttraining's auc: 0.833408\tvalid_1's auc: 0.706182\n",
      "[63]\ttraining's auc: 0.835012\tvalid_1's auc: 0.705972\n",
      "[64]\ttraining's auc: 0.836293\tvalid_1's auc: 0.705197\n",
      "[65]\ttraining's auc: 0.837551\tvalid_1's auc: 0.704485\n",
      "[66]\ttraining's auc: 0.838874\tvalid_1's auc: 0.704241\n",
      "[67]\ttraining's auc: 0.840067\tvalid_1's auc: 0.703728\n",
      "[68]\ttraining's auc: 0.841237\tvalid_1's auc: 0.702519\n",
      "[69]\ttraining's auc: 0.843301\tvalid_1's auc: 0.701615\n",
      "[70]\ttraining's auc: 0.844626\tvalid_1's auc: 0.702872\n",
      "[71]\ttraining's auc: 0.845246\tvalid_1's auc: 0.702671\n",
      "[72]\ttraining's auc: 0.846777\tvalid_1's auc: 0.702498\n",
      "[73]\ttraining's auc: 0.848639\tvalid_1's auc: 0.70215\n",
      "[74]\ttraining's auc: 0.849622\tvalid_1's auc: 0.703005\n",
      "[75]\ttraining's auc: 0.850853\tvalid_1's auc: 0.702796\n",
      "[76]\ttraining's auc: 0.852054\tvalid_1's auc: 0.704057\n",
      "[77]\ttraining's auc: 0.85289\tvalid_1's auc: 0.703458\n",
      "[78]\ttraining's auc: 0.854211\tvalid_1's auc: 0.703744\n",
      "[79]\ttraining's auc: 0.854746\tvalid_1's auc: 0.703093\n",
      "[80]\ttraining's auc: 0.855993\tvalid_1's auc: 0.70264\n",
      "[81]\ttraining's auc: 0.856894\tvalid_1's auc: 0.702254\n",
      "[82]\ttraining's auc: 0.858053\tvalid_1's auc: 0.703881\n",
      "[83]\ttraining's auc: 0.85949\tvalid_1's auc: 0.703284\n",
      "[84]\ttraining's auc: 0.860045\tvalid_1's auc: 0.703497\n",
      "[85]\ttraining's auc: 0.860283\tvalid_1's auc: 0.703667\n",
      "[86]\ttraining's auc: 0.861037\tvalid_1's auc: 0.703352\n",
      "[87]\ttraining's auc: 0.862376\tvalid_1's auc: 0.703636\n",
      "[88]\ttraining's auc: 0.862765\tvalid_1's auc: 0.703947\n",
      "[89]\ttraining's auc: 0.863362\tvalid_1's auc: 0.703974\n",
      "[90]\ttraining's auc: 0.864313\tvalid_1's auc: 0.704355\n",
      "[91]\ttraining's auc: 0.865074\tvalid_1's auc: 0.703814\n",
      "[92]\ttraining's auc: 0.865838\tvalid_1's auc: 0.703176\n",
      "[93]\ttraining's auc: 0.866674\tvalid_1's auc: 0.702152\n",
      "[94]\ttraining's auc: 0.867548\tvalid_1's auc: 0.701462\n",
      "[95]\ttraining's auc: 0.86851\tvalid_1's auc: 0.700916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\ttraining's auc: 0.869412\tvalid_1's auc: 0.700885\n",
      "[97]\ttraining's auc: 0.870054\tvalid_1's auc: 0.70098\n",
      "[98]\ttraining's auc: 0.870844\tvalid_1's auc: 0.700746\n",
      "[99]\ttraining's auc: 0.87194\tvalid_1's auc: 0.70023\n",
      "[100]\ttraining's auc: 0.872934\tvalid_1's auc: 0.700281\n",
      "Fold 8: 0.70028\n",
      "[1]\ttraining's auc: 0.702789\tvalid_1's auc: 0.69033\n",
      "[2]\ttraining's auc: 0.713226\tvalid_1's auc: 0.696706\n",
      "[3]\ttraining's auc: 0.719802\tvalid_1's auc: 0.70013\n",
      "[4]\ttraining's auc: 0.726405\tvalid_1's auc: 0.704773\n",
      "[5]\ttraining's auc: 0.729625\tvalid_1's auc: 0.70429\n",
      "[6]\ttraining's auc: 0.733092\tvalid_1's auc: 0.704187\n",
      "[7]\ttraining's auc: 0.735907\tvalid_1's auc: 0.704886\n",
      "[8]\ttraining's auc: 0.739047\tvalid_1's auc: 0.706513\n",
      "[9]\ttraining's auc: 0.742479\tvalid_1's auc: 0.707367\n",
      "[10]\ttraining's auc: 0.745029\tvalid_1's auc: 0.70599\n",
      "[11]\ttraining's auc: 0.747687\tvalid_1's auc: 0.70543\n",
      "[12]\ttraining's auc: 0.752886\tvalid_1's auc: 0.71059\n",
      "[13]\ttraining's auc: 0.756741\tvalid_1's auc: 0.710571\n",
      "[14]\ttraining's auc: 0.758838\tvalid_1's auc: 0.710002\n",
      "[15]\ttraining's auc: 0.761151\tvalid_1's auc: 0.710599\n",
      "[16]\ttraining's auc: 0.763258\tvalid_1's auc: 0.710459\n",
      "[17]\ttraining's auc: 0.76601\tvalid_1's auc: 0.709867\n",
      "[18]\ttraining's auc: 0.767773\tvalid_1's auc: 0.709045\n",
      "[19]\ttraining's auc: 0.770001\tvalid_1's auc: 0.708368\n",
      "[20]\ttraining's auc: 0.772869\tvalid_1's auc: 0.710344\n",
      "[21]\ttraining's auc: 0.775079\tvalid_1's auc: 0.711184\n",
      "[22]\ttraining's auc: 0.776946\tvalid_1's auc: 0.711257\n",
      "[23]\ttraining's auc: 0.778649\tvalid_1's auc: 0.711053\n",
      "[24]\ttraining's auc: 0.780953\tvalid_1's auc: 0.711434\n",
      "[25]\ttraining's auc: 0.782807\tvalid_1's auc: 0.710508\n",
      "[26]\ttraining's auc: 0.784716\tvalid_1's auc: 0.710832\n",
      "[27]\ttraining's auc: 0.786673\tvalid_1's auc: 0.710886\n",
      "[28]\ttraining's auc: 0.788965\tvalid_1's auc: 0.710484\n",
      "[29]\ttraining's auc: 0.790778\tvalid_1's auc: 0.710338\n",
      "[30]\ttraining's auc: 0.792305\tvalid_1's auc: 0.709752\n",
      "[31]\ttraining's auc: 0.794258\tvalid_1's auc: 0.709477\n",
      "[32]\ttraining's auc: 0.795465\tvalid_1's auc: 0.709271\n",
      "[33]\ttraining's auc: 0.796467\tvalid_1's auc: 0.708869\n",
      "[34]\ttraining's auc: 0.798664\tvalid_1's auc: 0.709284\n",
      "[35]\ttraining's auc: 0.800574\tvalid_1's auc: 0.708911\n",
      "[36]\ttraining's auc: 0.802318\tvalid_1's auc: 0.70839\n",
      "[37]\ttraining's auc: 0.803827\tvalid_1's auc: 0.708891\n",
      "[38]\ttraining's auc: 0.806093\tvalid_1's auc: 0.709199\n",
      "[39]\ttraining's auc: 0.807701\tvalid_1's auc: 0.709452\n",
      "[40]\ttraining's auc: 0.809736\tvalid_1's auc: 0.708373\n",
      "[41]\ttraining's auc: 0.811335\tvalid_1's auc: 0.708258\n",
      "[42]\ttraining's auc: 0.813232\tvalid_1's auc: 0.708296\n",
      "[43]\ttraining's auc: 0.814807\tvalid_1's auc: 0.70931\n",
      "[44]\ttraining's auc: 0.816324\tvalid_1's auc: 0.708018\n",
      "[45]\ttraining's auc: 0.818006\tvalid_1's auc: 0.708942\n",
      "[46]\ttraining's auc: 0.819249\tvalid_1's auc: 0.70949\n",
      "[47]\ttraining's auc: 0.820972\tvalid_1's auc: 0.70863\n",
      "[48]\ttraining's auc: 0.822124\tvalid_1's auc: 0.708334\n",
      "[49]\ttraining's auc: 0.823518\tvalid_1's auc: 0.708963\n",
      "[50]\ttraining's auc: 0.824538\tvalid_1's auc: 0.709192\n",
      "[51]\ttraining's auc: 0.825541\tvalid_1's auc: 0.709022\n",
      "[52]\ttraining's auc: 0.82722\tvalid_1's auc: 0.708395\n",
      "[53]\ttraining's auc: 0.828593\tvalid_1's auc: 0.709291\n",
      "[54]\ttraining's auc: 0.830347\tvalid_1's auc: 0.710376\n",
      "[55]\ttraining's auc: 0.831273\tvalid_1's auc: 0.709145\n",
      "[56]\ttraining's auc: 0.832044\tvalid_1's auc: 0.708679\n",
      "[57]\ttraining's auc: 0.83431\tvalid_1's auc: 0.709277\n",
      "[58]\ttraining's auc: 0.835179\tvalid_1's auc: 0.71018\n",
      "[59]\ttraining's auc: 0.836595\tvalid_1's auc: 0.710464\n",
      "[60]\ttraining's auc: 0.837752\tvalid_1's auc: 0.710465\n",
      "[61]\ttraining's auc: 0.839232\tvalid_1's auc: 0.709323\n",
      "[62]\ttraining's auc: 0.840261\tvalid_1's auc: 0.709604\n",
      "[63]\ttraining's auc: 0.840753\tvalid_1's auc: 0.709526\n",
      "[64]\ttraining's auc: 0.842088\tvalid_1's auc: 0.709138\n",
      "[65]\ttraining's auc: 0.843095\tvalid_1's auc: 0.708427\n",
      "[66]\ttraining's auc: 0.844244\tvalid_1's auc: 0.707665\n",
      "[67]\ttraining's auc: 0.84514\tvalid_1's auc: 0.707708\n",
      "[68]\ttraining's auc: 0.846455\tvalid_1's auc: 0.708122\n",
      "[69]\ttraining's auc: 0.847609\tvalid_1's auc: 0.708188\n",
      "[70]\ttraining's auc: 0.848715\tvalid_1's auc: 0.708333\n",
      "[71]\ttraining's auc: 0.84933\tvalid_1's auc: 0.708261\n",
      "[72]\ttraining's auc: 0.850347\tvalid_1's auc: 0.707931\n",
      "[73]\ttraining's auc: 0.851275\tvalid_1's auc: 0.706714\n",
      "[74]\ttraining's auc: 0.852462\tvalid_1's auc: 0.707044\n",
      "[75]\ttraining's auc: 0.853695\tvalid_1's auc: 0.707233\n",
      "[76]\ttraining's auc: 0.854915\tvalid_1's auc: 0.707993\n",
      "[77]\ttraining's auc: 0.855913\tvalid_1's auc: 0.70778\n",
      "[78]\ttraining's auc: 0.857209\tvalid_1's auc: 0.707656\n",
      "[79]\ttraining's auc: 0.857964\tvalid_1's auc: 0.706745\n",
      "[80]\ttraining's auc: 0.858889\tvalid_1's auc: 0.706762\n",
      "[81]\ttraining's auc: 0.86009\tvalid_1's auc: 0.706334\n",
      "[82]\ttraining's auc: 0.86082\tvalid_1's auc: 0.706385\n",
      "[83]\ttraining's auc: 0.86158\tvalid_1's auc: 0.706797\n",
      "[84]\ttraining's auc: 0.862584\tvalid_1's auc: 0.707585\n",
      "[85]\ttraining's auc: 0.863291\tvalid_1's auc: 0.70729\n",
      "[86]\ttraining's auc: 0.863853\tvalid_1's auc: 0.707314\n",
      "[87]\ttraining's auc: 0.865096\tvalid_1's auc: 0.707382\n",
      "[88]\ttraining's auc: 0.86624\tvalid_1's auc: 0.707798\n",
      "[89]\ttraining's auc: 0.867523\tvalid_1's auc: 0.706598\n",
      "[90]\ttraining's auc: 0.867887\tvalid_1's auc: 0.706239\n",
      "[91]\ttraining's auc: 0.868356\tvalid_1's auc: 0.706393\n",
      "[92]\ttraining's auc: 0.869011\tvalid_1's auc: 0.70637\n",
      "[93]\ttraining's auc: 0.869585\tvalid_1's auc: 0.706897\n",
      "[94]\ttraining's auc: 0.870188\tvalid_1's auc: 0.706114\n",
      "[95]\ttraining's auc: 0.871177\tvalid_1's auc: 0.705837\n",
      "[96]\ttraining's auc: 0.872219\tvalid_1's auc: 0.705324\n",
      "[97]\ttraining's auc: 0.872809\tvalid_1's auc: 0.705544\n",
      "[98]\ttraining's auc: 0.873581\tvalid_1's auc: 0.705496\n",
      "[99]\ttraining's auc: 0.874359\tvalid_1's auc: 0.705146\n",
      "[100]\ttraining's auc: 0.875168\tvalid_1's auc: 0.704507\n",
      "Fold 9: 0.70451\n",
      "[1]\ttraining's auc: 0.707687\tvalid_1's auc: 0.678013\n",
      "[2]\ttraining's auc: 0.716843\tvalid_1's auc: 0.69093\n",
      "[3]\ttraining's auc: 0.722254\tvalid_1's auc: 0.69778\n",
      "[4]\ttraining's auc: 0.726075\tvalid_1's auc: 0.699055\n",
      "[5]\ttraining's auc: 0.731194\tvalid_1's auc: 0.698758\n",
      "[6]\ttraining's auc: 0.734858\tvalid_1's auc: 0.698522\n",
      "[7]\ttraining's auc: 0.737619\tvalid_1's auc: 0.699373\n",
      "[8]\ttraining's auc: 0.741859\tvalid_1's auc: 0.704229\n",
      "[9]\ttraining's auc: 0.744906\tvalid_1's auc: 0.705665\n",
      "[10]\ttraining's auc: 0.748205\tvalid_1's auc: 0.70449\n",
      "[11]\ttraining's auc: 0.750446\tvalid_1's auc: 0.704986\n",
      "[12]\ttraining's auc: 0.753107\tvalid_1's auc: 0.705988\n",
      "[13]\ttraining's auc: 0.754897\tvalid_1's auc: 0.705488\n",
      "[14]\ttraining's auc: 0.756837\tvalid_1's auc: 0.705655\n",
      "[15]\ttraining's auc: 0.759353\tvalid_1's auc: 0.706255\n",
      "[16]\ttraining's auc: 0.761599\tvalid_1's auc: 0.706947\n",
      "[17]\ttraining's auc: 0.765095\tvalid_1's auc: 0.710687\n",
      "[18]\ttraining's auc: 0.766958\tvalid_1's auc: 0.709885\n",
      "[19]\ttraining's auc: 0.768974\tvalid_1's auc: 0.709962\n",
      "[20]\ttraining's auc: 0.770924\tvalid_1's auc: 0.710487\n",
      "[21]\ttraining's auc: 0.772516\tvalid_1's auc: 0.711227\n",
      "[22]\ttraining's auc: 0.774419\tvalid_1's auc: 0.711165\n",
      "[23]\ttraining's auc: 0.775942\tvalid_1's auc: 0.711187\n",
      "[24]\ttraining's auc: 0.77749\tvalid_1's auc: 0.711698\n",
      "[25]\ttraining's auc: 0.779156\tvalid_1's auc: 0.71116\n",
      "[26]\ttraining's auc: 0.781697\tvalid_1's auc: 0.710975\n",
      "[27]\ttraining's auc: 0.782851\tvalid_1's auc: 0.709796\n",
      "[28]\ttraining's auc: 0.78547\tvalid_1's auc: 0.710374\n",
      "[29]\ttraining's auc: 0.787299\tvalid_1's auc: 0.709776\n",
      "[30]\ttraining's auc: 0.788987\tvalid_1's auc: 0.708646\n",
      "[31]\ttraining's auc: 0.791184\tvalid_1's auc: 0.708386\n",
      "[32]\ttraining's auc: 0.792902\tvalid_1's auc: 0.709917\n",
      "[33]\ttraining's auc: 0.794137\tvalid_1's auc: 0.710223\n",
      "[34]\ttraining's auc: 0.79568\tvalid_1's auc: 0.70913\n",
      "[35]\ttraining's auc: 0.797762\tvalid_1's auc: 0.709313\n",
      "[36]\ttraining's auc: 0.799482\tvalid_1's auc: 0.709037\n",
      "[37]\ttraining's auc: 0.800631\tvalid_1's auc: 0.709151\n",
      "[38]\ttraining's auc: 0.802923\tvalid_1's auc: 0.709384\n",
      "[39]\ttraining's auc: 0.804558\tvalid_1's auc: 0.708514\n",
      "[40]\ttraining's auc: 0.80564\tvalid_1's auc: 0.708555\n",
      "[41]\ttraining's auc: 0.807168\tvalid_1's auc: 0.708185\n",
      "[42]\ttraining's auc: 0.808205\tvalid_1's auc: 0.708038\n",
      "[43]\ttraining's auc: 0.809069\tvalid_1's auc: 0.708947\n",
      "[44]\ttraining's auc: 0.809844\tvalid_1's auc: 0.708331\n",
      "[45]\ttraining's auc: 0.811701\tvalid_1's auc: 0.708102\n",
      "[46]\ttraining's auc: 0.812333\tvalid_1's auc: 0.708388\n",
      "[47]\ttraining's auc: 0.814225\tvalid_1's auc: 0.708743\n",
      "[48]\ttraining's auc: 0.81549\tvalid_1's auc: 0.709816\n",
      "[49]\ttraining's auc: 0.816399\tvalid_1's auc: 0.709459\n",
      "[50]\ttraining's auc: 0.817659\tvalid_1's auc: 0.709753\n",
      "[51]\ttraining's auc: 0.819329\tvalid_1's auc: 0.709564\n",
      "[52]\ttraining's auc: 0.820455\tvalid_1's auc: 0.709252\n",
      "[53]\ttraining's auc: 0.821853\tvalid_1's auc: 0.708903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54]\ttraining's auc: 0.8228\tvalid_1's auc: 0.709393\n",
      "[55]\ttraining's auc: 0.824926\tvalid_1's auc: 0.710267\n",
      "[56]\ttraining's auc: 0.826154\tvalid_1's auc: 0.710076\n",
      "[57]\ttraining's auc: 0.827378\tvalid_1's auc: 0.709309\n",
      "[58]\ttraining's auc: 0.828714\tvalid_1's auc: 0.708891\n",
      "[59]\ttraining's auc: 0.829862\tvalid_1's auc: 0.709016\n",
      "[60]\ttraining's auc: 0.830579\tvalid_1's auc: 0.70919\n",
      "[61]\ttraining's auc: 0.83164\tvalid_1's auc: 0.708211\n",
      "[62]\ttraining's auc: 0.83259\tvalid_1's auc: 0.707571\n",
      "[63]\ttraining's auc: 0.833955\tvalid_1's auc: 0.70727\n",
      "[64]\ttraining's auc: 0.835292\tvalid_1's auc: 0.707218\n",
      "[65]\ttraining's auc: 0.836604\tvalid_1's auc: 0.706771\n",
      "[66]\ttraining's auc: 0.837036\tvalid_1's auc: 0.706842\n",
      "[67]\ttraining's auc: 0.838543\tvalid_1's auc: 0.706028\n",
      "[68]\ttraining's auc: 0.839711\tvalid_1's auc: 0.705231\n",
      "[69]\ttraining's auc: 0.84087\tvalid_1's auc: 0.704969\n",
      "[70]\ttraining's auc: 0.841932\tvalid_1's auc: 0.705094\n",
      "[71]\ttraining's auc: 0.842638\tvalid_1's auc: 0.704831\n",
      "[72]\ttraining's auc: 0.843538\tvalid_1's auc: 0.704579\n",
      "[73]\ttraining's auc: 0.844778\tvalid_1's auc: 0.703705\n",
      "[74]\ttraining's auc: 0.845759\tvalid_1's auc: 0.704209\n",
      "[75]\ttraining's auc: 0.846543\tvalid_1's auc: 0.704971\n",
      "[76]\ttraining's auc: 0.847299\tvalid_1's auc: 0.704086\n",
      "[77]\ttraining's auc: 0.848347\tvalid_1's auc: 0.703947\n",
      "[78]\ttraining's auc: 0.848895\tvalid_1's auc: 0.703385\n",
      "[79]\ttraining's auc: 0.849349\tvalid_1's auc: 0.703084\n",
      "[80]\ttraining's auc: 0.850729\tvalid_1's auc: 0.703351\n",
      "[81]\ttraining's auc: 0.851771\tvalid_1's auc: 0.703201\n",
      "[82]\ttraining's auc: 0.852763\tvalid_1's auc: 0.703687\n",
      "[83]\ttraining's auc: 0.853578\tvalid_1's auc: 0.70294\n",
      "[84]\ttraining's auc: 0.854083\tvalid_1's auc: 0.703235\n",
      "[85]\ttraining's auc: 0.854793\tvalid_1's auc: 0.703055\n",
      "[86]\ttraining's auc: 0.856055\tvalid_1's auc: 0.703674\n",
      "[87]\ttraining's auc: 0.857248\tvalid_1's auc: 0.704216\n",
      "[88]\ttraining's auc: 0.858392\tvalid_1's auc: 0.703373\n",
      "[89]\ttraining's auc: 0.859542\tvalid_1's auc: 0.704202\n",
      "[90]\ttraining's auc: 0.860381\tvalid_1's auc: 0.703668\n",
      "[91]\ttraining's auc: 0.861306\tvalid_1's auc: 0.703767\n",
      "[92]\ttraining's auc: 0.862309\tvalid_1's auc: 0.703881\n",
      "[93]\ttraining's auc: 0.863612\tvalid_1's auc: 0.702918\n",
      "[94]\ttraining's auc: 0.864705\tvalid_1's auc: 0.70166\n",
      "[95]\ttraining's auc: 0.865352\tvalid_1's auc: 0.70071\n",
      "[96]\ttraining's auc: 0.86631\tvalid_1's auc: 0.700237\n",
      "[97]\ttraining's auc: 0.8678\tvalid_1's auc: 0.700053\n",
      "[98]\ttraining's auc: 0.86896\tvalid_1's auc: 0.700106\n",
      "[99]\ttraining's auc: 0.869673\tvalid_1's auc: 0.700056\n",
      "[100]\ttraining's auc: 0.869967\tvalid_1's auc: 0.699917\n",
      "Fold 10: 0.69992\n",
      "CV score(auc): 0.70652 , (std: 0.01197 )\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "lgb_params = {'learning_rate': 0.3,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 31,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,\n",
    "              'lambda_l1': 1,\n",
    "              'lambda_l2': 1}\n",
    "\n",
    "N_FOLDS = 10\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "new_train = train[numerical]\n",
    "new_test = test[numerical]\n",
    "estimators, oof_preds_lgb = lgboost_cross_validation(\n",
    "    params=lgb_params, X=new_train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.70652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_lgb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оценить корреляцию прогнозов на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36165103],\n",
       "       [0.36165103, 1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(\n",
    "    x = oof_preds_lgb,\n",
    "    y = oof_preds_xgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.02180408, 0.11500328, 0.24272412, ..., 0.27453855, 0.23320237,\n",
       "        0.30034339]),\n",
       " array([0.01071466, 0.08306752, 0.06918635, ..., 0.08362073, 0.01843834,\n",
       "        0.0997197 ])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = []\n",
    "oof_train.append(oof_preds_xgb)\n",
    "oof_train.append(oof_preds_lgb)\n",
    "#oof_train = np.array(oof_train)\n",
    "oof_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применить модели на тестовую выборку и оценить корреляцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "#test[categorial] = test[categorial].astype(str)\n",
    "new_test = test[numerical]\n",
    "for estimator in estimators:\n",
    "    y_pred_lgb += estimator.predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb = y_pred_lgb / cv.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04265717, 0.28020678, 0.13450095, ..., 0.08217762, 0.01037823,\n",
       "       0.02629846])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.90685133],\n",
       "       [0.90685133, 1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(\n",
    "    x = y_pred_lgb,\n",
    "    y = y_pred_xgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19475852, 0.28085497, 0.28609303, ..., 0.20393237, 0.16206918,\n",
       "        0.1767074 ],\n",
       "       [0.04265717, 0.28020678, 0.13450095, ..., 0.08217762, 0.01037823,\n",
       "        0.02629846]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test = []\n",
    "oof_test.append(y_pred_xgb)\n",
    "oof_test.append(y_pred_lgb)\n",
    "oof_test = np.array(oof_test)\n",
    "oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>110078</th>\n",
       "      <th>110079</th>\n",
       "      <th>110080</th>\n",
       "      <th>110081</th>\n",
       "      <th>110082</th>\n",
       "      <th>110083</th>\n",
       "      <th>110084</th>\n",
       "      <th>110085</th>\n",
       "      <th>110086</th>\n",
       "      <th>110087</th>\n",
       "      <th>110088</th>\n",
       "      <th>110089</th>\n",
       "      <th>110090</th>\n",
       "      <th>110091</th>\n",
       "      <th>110092</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021804</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.242724</td>\n",
       "      <td>0.327103</td>\n",
       "      <td>0.253870</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.274493</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.123239</td>\n",
       "      <td>0.257960</td>\n",
       "      <td>0.274539</td>\n",
       "      <td>0.268973</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>0.125615</td>\n",
       "      <td>0.320062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095010</td>\n",
       "      <td>0.057954</td>\n",
       "      <td>0.288158</td>\n",
       "      <td>0.098362</td>\n",
       "      <td>0.258538</td>\n",
       "      <td>0.084297</td>\n",
       "      <td>0.253870</td>\n",
       "      <td>0.115003</td>\n",
       "      <td>0.274539</td>\n",
       "      <td>0.084545</td>\n",
       "      <td>0.291705</td>\n",
       "      <td>0.260985</td>\n",
       "      <td>0.274539</td>\n",
       "      <td>0.233202</td>\n",
       "      <td>0.300343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.083068</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.113912</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.560826</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.108530</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.082242</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056113</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.107808</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.038181</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.018438</td>\n",
       "      <td>0.099720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 110093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.021804  0.115003  0.242724  0.327103  0.253870  0.309703  0.274493   \n",
       "1  0.010715  0.083068  0.069186  0.113912  0.083621  0.560826  0.025938   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.168009  0.123239  0.257960  0.274539  0.268973  0.025762  0.125615   \n",
       "1  0.032510  0.108530  0.038389  0.082242  0.061880  0.007936  0.129061   \n",
       "\n",
       "     14      ...    110078    110079    110080    110081    110082    110083  \\\n",
       "0  0.320062  ...  0.095010  0.057954  0.288158  0.098362  0.258538  0.084297   \n",
       "1  0.237281  ...  0.056113  0.222659  0.025226  0.107808  0.012001  0.052649   \n",
       "\n",
       "     110084    110085    110086    110087    110088    110089    110090  \\\n",
       "0  0.253870  0.115003  0.274539  0.084545  0.291705  0.260985  0.274539   \n",
       "1  0.081648  0.082990  0.081648  0.081648  0.083621  0.038181  0.083621   \n",
       "\n",
       "     110091    110092  \n",
       "0  0.233202  0.300343  \n",
       "1  0.018438  0.099720  \n",
       "\n",
       "[2 rows x 110093 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_train)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12429579497430172"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5034274902407732"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>165126</th>\n",
       "      <th>165127</th>\n",
       "      <th>165128</th>\n",
       "      <th>165129</th>\n",
       "      <th>165130</th>\n",
       "      <th>165131</th>\n",
       "      <th>165132</th>\n",
       "      <th>165133</th>\n",
       "      <th>165134</th>\n",
       "      <th>165135</th>\n",
       "      <th>165136</th>\n",
       "      <th>165137</th>\n",
       "      <th>165138</th>\n",
       "      <th>165139</th>\n",
       "      <th>165140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194759</td>\n",
       "      <td>0.280855</td>\n",
       "      <td>0.286093</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.167907</td>\n",
       "      <td>0.172871</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.256291</td>\n",
       "      <td>0.157321</td>\n",
       "      <td>0.166737</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.177878</td>\n",
       "      <td>0.173460</td>\n",
       "      <td>0.206655</td>\n",
       "      <td>0.169337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165647</td>\n",
       "      <td>0.213648</td>\n",
       "      <td>0.161938</td>\n",
       "      <td>0.160148</td>\n",
       "      <td>0.155443</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.157340</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.169106</td>\n",
       "      <td>0.203932</td>\n",
       "      <td>0.162069</td>\n",
       "      <td>0.176707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042657</td>\n",
       "      <td>0.280207</td>\n",
       "      <td>0.134501</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.042439</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>0.083732</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.040369</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.026298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.194759  0.280855  0.286093  0.203932  0.167907  0.172871  0.203932   \n",
       "1  0.042657  0.280207  0.134501  0.082178  0.018202  0.026691  0.082178   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.256291  0.157321  0.166737  0.203932  0.177878  0.173460  0.206655   \n",
       "1  0.101307  0.002751  0.020221  0.082178  0.042439  0.029281  0.083732   \n",
       "\n",
       "     14      ...    165126    165127    165128    165129    165130    165131  \\\n",
       "0  0.169337  ...  0.165647  0.213648  0.161938  0.160148  0.155443  0.203932   \n",
       "1  0.020947  ...  0.022487  0.062768  0.013450  0.009253  0.003990  0.082178   \n",
       "\n",
       "     165132    165133    165134    165135    165136    165137    165138  \\\n",
       "0  0.203932  0.203932  0.157340  0.203932  0.203932  0.169106  0.203932   \n",
       "1  0.082178  0.082178  0.006549  0.082178  0.082178  0.040369  0.082178   \n",
       "\n",
       "     165139    165140  \n",
       "0  0.162069  0.176707  \n",
       "1  0.010378  0.026298  \n",
       "\n",
       "[2 rows x 165141 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_test)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12411951150425493"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_test[0] - oof_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_arifm = (oof_preds_xgb + oof_preds_lgb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_geom = (oof_preds_xgb * oof_preds_lgb) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.66966\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_arifm\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.70013\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_geom\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 30 20:09:28 2020, Cross-Validation, 110093 rows, 53 cols\n",
      "0:\ttest: 0.6734332\ttest1: 0.6641824\tbest: 0.6641824 (0)\ttotal: 378ms\tremaining: 12m 35s\n",
      "10:\ttest: 0.7007889\ttest1: 0.6938119\tbest: 0.6938119 (10)\ttotal: 1.63s\tremaining: 4m 55s\n",
      "20:\ttest: 0.7029293\ttest1: 0.6963111\tbest: 0.6970105 (18)\ttotal: 2.88s\tremaining: 4m 31s\n",
      "30:\ttest: 0.7058306\ttest1: 0.6981630\tbest: 0.6985139 (29)\ttotal: 4.08s\tremaining: 4m 19s\n",
      "40:\ttest: 0.7068103\ttest1: 0.6994951\tbest: 0.6994951 (40)\ttotal: 5.32s\tremaining: 4m 14s\n",
      "50:\ttest: 0.7073623\ttest1: 0.7009414\tbest: 0.7010275 (46)\ttotal: 6.5s\tremaining: 4m 8s\n",
      "60:\ttest: 0.7083320\ttest1: 0.7028293\tbest: 0.7028614 (59)\ttotal: 7.72s\tremaining: 4m 5s\n",
      "70:\ttest: 0.7087590\ttest1: 0.7025761\tbest: 0.7029574 (64)\ttotal: 8.91s\tremaining: 4m 2s\n",
      "80:\ttest: 0.7094492\ttest1: 0.7035250\tbest: 0.7035250 (80)\ttotal: 10.1s\tremaining: 4m\n",
      "90:\ttest: 0.7100618\ttest1: 0.7038065\tbest: 0.7038065 (90)\ttotal: 11.4s\tremaining: 3m 58s\n",
      "100:\ttest: 0.7107377\ttest1: 0.7049387\tbest: 0.7049387 (100)\ttotal: 12.6s\tremaining: 3m 56s\n",
      "110:\ttest: 0.7111525\ttest1: 0.7049380\tbest: 0.7051281 (107)\ttotal: 13.8s\tremaining: 3m 55s\n",
      "120:\ttest: 0.7119920\ttest1: 0.7055332\tbest: 0.7055332 (120)\ttotal: 15s\tremaining: 3m 53s\n",
      "130:\ttest: 0.7122432\ttest1: 0.7054498\tbest: 0.7056216 (121)\ttotal: 16.2s\tremaining: 3m 50s\n",
      "140:\ttest: 0.7127023\ttest1: 0.7062489\tbest: 0.7064070 (135)\ttotal: 17.4s\tremaining: 3m 49s\n",
      "150:\ttest: 0.7133704\ttest1: 0.7069288\tbest: 0.7070098 (149)\ttotal: 18.6s\tremaining: 3m 47s\n",
      "160:\ttest: 0.7141563\ttest1: 0.7077022\tbest: 0.7077022 (160)\ttotal: 19.7s\tremaining: 3m 45s\n",
      "170:\ttest: 0.7148194\ttest1: 0.7080918\tbest: 0.7080918 (170)\ttotal: 20.9s\tremaining: 3m 44s\n",
      "180:\ttest: 0.7154515\ttest1: 0.7087161\tbest: 0.7089049 (178)\ttotal: 22.2s\tremaining: 3m 42s\n",
      "190:\ttest: 0.7160740\ttest1: 0.7092477\tbest: 0.7092477 (190)\ttotal: 23.4s\tremaining: 3m 41s\n",
      "200:\ttest: 0.7166322\ttest1: 0.7095682\tbest: 0.7095682 (200)\ttotal: 24.5s\tremaining: 3m 39s\n",
      "210:\ttest: 0.7172854\ttest1: 0.7101848\tbest: 0.7101848 (210)\ttotal: 25.7s\tremaining: 3m 37s\n",
      "220:\ttest: 0.7177808\ttest1: 0.7105783\tbest: 0.7105783 (220)\ttotal: 26.9s\tremaining: 3m 36s\n",
      "230:\ttest: 0.7184580\ttest1: 0.7110290\tbest: 0.7110290 (230)\ttotal: 28.1s\tremaining: 3m 35s\n",
      "240:\ttest: 0.7191693\ttest1: 0.7114830\tbest: 0.7114890 (239)\ttotal: 29.3s\tremaining: 3m 33s\n",
      "250:\ttest: 0.7195681\ttest1: 0.7116629\tbest: 0.7118355 (246)\ttotal: 30.4s\tremaining: 3m 31s\n",
      "260:\ttest: 0.7202435\ttest1: 0.7121051\tbest: 0.7121839 (259)\ttotal: 31.6s\tremaining: 3m 30s\n",
      "270:\ttest: 0.7207897\ttest1: 0.7125034\tbest: 0.7125034 (270)\ttotal: 32.7s\tremaining: 3m 28s\n",
      "280:\ttest: 0.7212173\ttest1: 0.7126202\tbest: 0.7127238 (278)\ttotal: 33.9s\tremaining: 3m 27s\n",
      "290:\ttest: 0.7219228\ttest1: 0.7130589\tbest: 0.7131766 (287)\ttotal: 35.1s\tremaining: 3m 25s\n",
      "300:\ttest: 0.7223899\ttest1: 0.7134356\tbest: 0.7134409 (298)\ttotal: 36.3s\tremaining: 3m 24s\n",
      "310:\ttest: 0.7228333\ttest1: 0.7137387\tbest: 0.7137387 (310)\ttotal: 37.4s\tremaining: 3m 23s\n",
      "320:\ttest: 0.7235418\ttest1: 0.7142380\tbest: 0.7143501 (317)\ttotal: 38.5s\tremaining: 3m 21s\n",
      "330:\ttest: 0.7242397\ttest1: 0.7144845\tbest: 0.7145854 (327)\ttotal: 39.7s\tremaining: 3m 20s\n",
      "340:\ttest: 0.7249435\ttest1: 0.7148921\tbest: 0.7148921 (340)\ttotal: 40.8s\tremaining: 3m 18s\n",
      "350:\ttest: 0.7255887\ttest1: 0.7149194\tbest: 0.7149684 (344)\ttotal: 42.1s\tremaining: 3m 17s\n",
      "360:\ttest: 0.7259327\ttest1: 0.7147954\tbest: 0.7149684 (344)\ttotal: 43.2s\tremaining: 3m 16s\n",
      "370:\ttest: 0.7264867\ttest1: 0.7153671\tbest: 0.7153671 (370)\ttotal: 44.4s\tremaining: 3m 15s\n",
      "380:\ttest: 0.7269707\ttest1: 0.7156422\tbest: 0.7156422 (380)\ttotal: 45.6s\tremaining: 3m 13s\n",
      "390:\ttest: 0.7274827\ttest1: 0.7160319\tbest: 0.7160319 (390)\ttotal: 46.8s\tremaining: 3m 12s\n",
      "400:\ttest: 0.7280692\ttest1: 0.7166016\tbest: 0.7166016 (400)\ttotal: 47.9s\tremaining: 3m 11s\n",
      "410:\ttest: 0.7283622\ttest1: 0.7165406\tbest: 0.7167026 (403)\ttotal: 49s\tremaining: 3m 9s\n",
      "420:\ttest: 0.7288832\ttest1: 0.7172522\tbest: 0.7172541 (419)\ttotal: 50.1s\tremaining: 3m 8s\n",
      "430:\ttest: 0.7292555\ttest1: 0.7175706\tbest: 0.7175706 (430)\ttotal: 51.3s\tremaining: 3m 6s\n",
      "440:\ttest: 0.7296645\ttest1: 0.7180394\tbest: 0.7180394 (440)\ttotal: 52.4s\tremaining: 3m 5s\n",
      "450:\ttest: 0.7301549\ttest1: 0.7181225\tbest: 0.7181225 (450)\ttotal: 53.6s\tremaining: 3m 4s\n",
      "460:\ttest: 0.7306147\ttest1: 0.7182364\tbest: 0.7183004 (453)\ttotal: 54.7s\tremaining: 3m 2s\n",
      "470:\ttest: 0.7310461\ttest1: 0.7181965\tbest: 0.7183114 (464)\ttotal: 55.9s\tremaining: 3m 1s\n",
      "480:\ttest: 0.7315438\ttest1: 0.7184128\tbest: 0.7184128 (480)\ttotal: 57.1s\tremaining: 3m\n",
      "490:\ttest: 0.7319522\ttest1: 0.7185707\tbest: 0.7186113 (489)\ttotal: 58.1s\tremaining: 2m 58s\n",
      "500:\ttest: 0.7324091\ttest1: 0.7187848\tbest: 0.7187848 (500)\ttotal: 59.3s\tremaining: 2m 57s\n",
      "510:\ttest: 0.7327392\ttest1: 0.7188383\tbest: 0.7188661 (508)\ttotal: 1m\tremaining: 2m 56s\n",
      "520:\ttest: 0.7329758\ttest1: 0.7189537\tbest: 0.7189642 (517)\ttotal: 1m 1s\tremaining: 2m 54s\n",
      "530:\ttest: 0.7333106\ttest1: 0.7188299\tbest: 0.7189642 (517)\ttotal: 1m 2s\tremaining: 2m 53s\n",
      "540:\ttest: 0.7337116\ttest1: 0.7189690\tbest: 0.7190201 (535)\ttotal: 1m 3s\tremaining: 2m 52s\n",
      "550:\ttest: 0.7340900\ttest1: 0.7191441\tbest: 0.7191888 (547)\ttotal: 1m 5s\tremaining: 2m 50s\n",
      "560:\ttest: 0.7344330\ttest1: 0.7191197\tbest: 0.7193506 (555)\ttotal: 1m 6s\tremaining: 2m 49s\n",
      "570:\ttest: 0.7346253\ttest1: 0.7192139\tbest: 0.7193519 (562)\ttotal: 1m 7s\tremaining: 2m 48s\n",
      "580:\ttest: 0.7349916\ttest1: 0.7193011\tbest: 0.7193519 (562)\ttotal: 1m 8s\tremaining: 2m 46s\n",
      "590:\ttest: 0.7352593\ttest1: 0.7194442\tbest: 0.7194627 (585)\ttotal: 1m 9s\tremaining: 2m 45s\n",
      "600:\ttest: 0.7356128\ttest1: 0.7195533\tbest: 0.7195605 (599)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "610:\ttest: 0.7360013\ttest1: 0.7198231\tbest: 0.7198231 (610)\ttotal: 1m 11s\tremaining: 2m 43s\n",
      "620:\ttest: 0.7363279\ttest1: 0.7198800\tbest: 0.7198906 (619)\ttotal: 1m 12s\tremaining: 2m 41s\n",
      "630:\ttest: 0.7367278\ttest1: 0.7199964\tbest: 0.7200481 (626)\ttotal: 1m 13s\tremaining: 2m 40s\n",
      "640:\ttest: 0.7370343\ttest1: 0.7200308\tbest: 0.7200976 (636)\ttotal: 1m 15s\tremaining: 2m 39s\n",
      "650:\ttest: 0.7373095\ttest1: 0.7199707\tbest: 0.7201306 (644)\ttotal: 1m 16s\tremaining: 2m 37s\n",
      "660:\ttest: 0.7377603\ttest1: 0.7201663\tbest: 0.7201663 (660)\ttotal: 1m 17s\tremaining: 2m 36s\n",
      "670:\ttest: 0.7379735\ttest1: 0.7199764\tbest: 0.7202037 (664)\ttotal: 1m 18s\tremaining: 2m 35s\n",
      "680:\ttest: 0.7382876\ttest1: 0.7200766\tbest: 0.7202037 (664)\ttotal: 1m 19s\tremaining: 2m 34s\n",
      "690:\ttest: 0.7386843\ttest1: 0.7203249\tbest: 0.7203821 (686)\ttotal: 1m 20s\tremaining: 2m 33s\n",
      "700:\ttest: 0.7388685\ttest1: 0.7203259\tbest: 0.7204211 (698)\ttotal: 1m 21s\tremaining: 2m 31s\n",
      "710:\ttest: 0.7392707\ttest1: 0.7205308\tbest: 0.7205535 (704)\ttotal: 1m 22s\tremaining: 2m 30s\n",
      "720:\ttest: 0.7394811\ttest1: 0.7203465\tbest: 0.7206844 (715)\ttotal: 1m 24s\tremaining: 2m 29s\n",
      "730:\ttest: 0.7397236\ttest1: 0.7203796\tbest: 0.7206844 (715)\ttotal: 1m 25s\tremaining: 2m 28s\n",
      "740:\ttest: 0.7398278\ttest1: 0.7204062\tbest: 0.7206844 (715)\ttotal: 1m 26s\tremaining: 2m 26s\n",
      "750:\ttest: 0.7400912\ttest1: 0.7203814\tbest: 0.7206844 (715)\ttotal: 1m 27s\tremaining: 2m 25s\n",
      "760:\ttest: 0.7404009\ttest1: 0.7203798\tbest: 0.7206844 (715)\ttotal: 1m 28s\tremaining: 2m 24s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7206844311\n",
      "bestIteration = 715\n",
      "\n",
      "Shrink model to first 716 iterations.\n",
      "Fold 1, Valid score = 0.72068\n",
      "0:\ttest: 0.6729537\ttest1: 0.6735935\tbest: 0.6735935 (0)\ttotal: 131ms\tremaining: 4m 21s\n",
      "10:\ttest: 0.6989716\ttest1: 0.7006435\tbest: 0.7006435 (10)\ttotal: 1.36s\tremaining: 4m 5s\n",
      "20:\ttest: 0.7013279\ttest1: 0.7033123\tbest: 0.7035578 (18)\ttotal: 2.53s\tremaining: 3m 58s\n",
      "30:\ttest: 0.7040805\ttest1: 0.7062677\tbest: 0.7062677 (30)\ttotal: 3.68s\tremaining: 3m 53s\n",
      "40:\ttest: 0.7057435\ttest1: 0.7060585\tbest: 0.7066366 (31)\ttotal: 4.86s\tremaining: 3m 52s\n",
      "50:\ttest: 0.7064967\ttest1: 0.7072601\tbest: 0.7072601 (50)\ttotal: 6.09s\tremaining: 3m 52s\n",
      "60:\ttest: 0.7074875\ttest1: 0.7081247\tbest: 0.7086986 (58)\ttotal: 7.28s\tremaining: 3m 51s\n",
      "70:\ttest: 0.7076100\ttest1: 0.7085970\tbest: 0.7088267 (63)\ttotal: 8.48s\tremaining: 3m 50s\n",
      "80:\ttest: 0.7089362\ttest1: 0.7094219\tbest: 0.7094219 (80)\ttotal: 9.69s\tremaining: 3m 49s\n",
      "90:\ttest: 0.7090073\ttest1: 0.7092548\tbest: 0.7094219 (80)\ttotal: 10.9s\tremaining: 3m 47s\n",
      "100:\ttest: 0.7096141\ttest1: 0.7086761\tbest: 0.7094219 (80)\ttotal: 12s\tremaining: 3m 45s\n",
      "110:\ttest: 0.7096761\ttest1: 0.7089010\tbest: 0.7094219 (80)\ttotal: 13.2s\tremaining: 3m 45s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120:\ttest: 0.7102942\ttest1: 0.7094887\tbest: 0.7094887 (120)\ttotal: 14.4s\tremaining: 3m 44s\n",
      "130:\ttest: 0.7109416\ttest1: 0.7096544\tbest: 0.7097525 (125)\ttotal: 15.6s\tremaining: 3m 43s\n",
      "140:\ttest: 0.7114409\ttest1: 0.7100903\tbest: 0.7101572 (138)\ttotal: 16.8s\tremaining: 3m 41s\n",
      "150:\ttest: 0.7124348\ttest1: 0.7114451\tbest: 0.7114451 (150)\ttotal: 18s\tremaining: 3m 40s\n",
      "160:\ttest: 0.7130634\ttest1: 0.7116085\tbest: 0.7116093 (156)\ttotal: 19.2s\tremaining: 3m 38s\n",
      "170:\ttest: 0.7134697\ttest1: 0.7120329\tbest: 0.7122668 (166)\ttotal: 20.4s\tremaining: 3m 38s\n",
      "180:\ttest: 0.7138800\ttest1: 0.7124840\tbest: 0.7125025 (179)\ttotal: 21.6s\tremaining: 3m 37s\n",
      "190:\ttest: 0.7145701\ttest1: 0.7128818\tbest: 0.7128818 (190)\ttotal: 22.8s\tremaining: 3m 35s\n",
      "200:\ttest: 0.7150727\ttest1: 0.7131927\tbest: 0.7131927 (200)\ttotal: 23.9s\tremaining: 3m 33s\n",
      "210:\ttest: 0.7157641\ttest1: 0.7139536\tbest: 0.7139536 (210)\ttotal: 25s\tremaining: 3m 32s\n",
      "220:\ttest: 0.7165304\ttest1: 0.7144560\tbest: 0.7144675 (218)\ttotal: 26.2s\tremaining: 3m 30s\n",
      "230:\ttest: 0.7171534\ttest1: 0.7147089\tbest: 0.7148432 (229)\ttotal: 27.4s\tremaining: 3m 29s\n",
      "240:\ttest: 0.7177943\ttest1: 0.7154301\tbest: 0.7154301 (240)\ttotal: 28.6s\tremaining: 3m 28s\n",
      "250:\ttest: 0.7182470\ttest1: 0.7157308\tbest: 0.7157308 (250)\ttotal: 29.8s\tremaining: 3m 27s\n",
      "260:\ttest: 0.7190987\ttest1: 0.7162283\tbest: 0.7162754 (259)\ttotal: 30.9s\tremaining: 3m 26s\n",
      "270:\ttest: 0.7198572\ttest1: 0.7167724\tbest: 0.7167724 (270)\ttotal: 32.1s\tremaining: 3m 24s\n",
      "280:\ttest: 0.7207496\ttest1: 0.7171668\tbest: 0.7172521 (278)\ttotal: 33.3s\tremaining: 3m 23s\n",
      "290:\ttest: 0.7210790\ttest1: 0.7172724\tbest: 0.7172935 (281)\ttotal: 34.4s\tremaining: 3m 22s\n",
      "300:\ttest: 0.7215705\ttest1: 0.7174181\tbest: 0.7174181 (300)\ttotal: 35.7s\tremaining: 3m 21s\n",
      "310:\ttest: 0.7221183\ttest1: 0.7177691\tbest: 0.7177691 (310)\ttotal: 36.8s\tremaining: 3m 19s\n",
      "320:\ttest: 0.7227888\ttest1: 0.7178319\tbest: 0.7179135 (318)\ttotal: 38s\tremaining: 3m 18s\n",
      "330:\ttest: 0.7234525\ttest1: 0.7187307\tbest: 0.7187433 (329)\ttotal: 39.2s\tremaining: 3m 17s\n",
      "340:\ttest: 0.7238978\ttest1: 0.7193944\tbest: 0.7193944 (340)\ttotal: 40.3s\tremaining: 3m 16s\n",
      "350:\ttest: 0.7241585\ttest1: 0.7194943\tbest: 0.7195213 (348)\ttotal: 41.5s\tremaining: 3m 15s\n",
      "360:\ttest: 0.7247585\ttest1: 0.7199276\tbest: 0.7199394 (359)\ttotal: 42.7s\tremaining: 3m 13s\n",
      "370:\ttest: 0.7252420\ttest1: 0.7199964\tbest: 0.7200768 (367)\ttotal: 43.9s\tremaining: 3m 12s\n",
      "380:\ttest: 0.7258998\ttest1: 0.7203251\tbest: 0.7203329 (379)\ttotal: 45.1s\tremaining: 3m 11s\n",
      "390:\ttest: 0.7264302\ttest1: 0.7203454\tbest: 0.7203832 (383)\ttotal: 46.2s\tremaining: 3m 10s\n",
      "400:\ttest: 0.7270677\ttest1: 0.7202680\tbest: 0.7203832 (383)\ttotal: 47.4s\tremaining: 3m 8s\n",
      "410:\ttest: 0.7274660\ttest1: 0.7205593\tbest: 0.7205716 (409)\ttotal: 48.5s\tremaining: 3m 7s\n",
      "420:\ttest: 0.7280182\ttest1: 0.7210087\tbest: 0.7210087 (420)\ttotal: 49.7s\tremaining: 3m 6s\n",
      "430:\ttest: 0.7284578\ttest1: 0.7211857\tbest: 0.7211857 (430)\ttotal: 50.9s\tremaining: 3m 5s\n",
      "440:\ttest: 0.7287109\ttest1: 0.7216433\tbest: 0.7216433 (440)\ttotal: 52.1s\tremaining: 3m 4s\n",
      "450:\ttest: 0.7291227\ttest1: 0.7218723\tbest: 0.7219674 (447)\ttotal: 53.2s\tremaining: 3m 2s\n",
      "460:\ttest: 0.7293782\ttest1: 0.7220309\tbest: 0.7220481 (456)\ttotal: 54.3s\tremaining: 3m 1s\n",
      "470:\ttest: 0.7299461\ttest1: 0.7222769\tbest: 0.7223351 (467)\ttotal: 55.5s\tremaining: 3m\n",
      "480:\ttest: 0.7304093\ttest1: 0.7222747\tbest: 0.7223351 (467)\ttotal: 56.6s\tremaining: 2m 58s\n",
      "490:\ttest: 0.7308276\ttest1: 0.7226942\tbest: 0.7226942 (490)\ttotal: 57.8s\tremaining: 2m 57s\n",
      "500:\ttest: 0.7312631\ttest1: 0.7230880\tbest: 0.7230880 (500)\ttotal: 59s\tremaining: 2m 56s\n",
      "510:\ttest: 0.7316653\ttest1: 0.7229223\tbest: 0.7231571 (506)\ttotal: 1m\tremaining: 2m 55s\n",
      "520:\ttest: 0.7319172\ttest1: 0.7231412\tbest: 0.7231571 (506)\ttotal: 1m 1s\tremaining: 2m 53s\n",
      "530:\ttest: 0.7323090\ttest1: 0.7231557\tbest: 0.7234089 (527)\ttotal: 1m 2s\tremaining: 2m 52s\n",
      "540:\ttest: 0.7326211\ttest1: 0.7234743\tbest: 0.7234797 (539)\ttotal: 1m 3s\tremaining: 2m 51s\n",
      "550:\ttest: 0.7329078\ttest1: 0.7232189\tbest: 0.7235016 (541)\ttotal: 1m 4s\tremaining: 2m 50s\n",
      "560:\ttest: 0.7331075\ttest1: 0.7234510\tbest: 0.7236134 (558)\ttotal: 1m 6s\tremaining: 2m 49s\n",
      "570:\ttest: 0.7334413\ttest1: 0.7233922\tbest: 0.7236134 (558)\ttotal: 1m 7s\tremaining: 2m 48s\n",
      "580:\ttest: 0.7337765\ttest1: 0.7235420\tbest: 0.7236134 (558)\ttotal: 1m 8s\tremaining: 2m 46s\n",
      "590:\ttest: 0.7340567\ttest1: 0.7236596\tbest: 0.7236726 (589)\ttotal: 1m 9s\tremaining: 2m 45s\n",
      "600:\ttest: 0.7343325\ttest1: 0.7240886\tbest: 0.7240886 (600)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "610:\ttest: 0.7345614\ttest1: 0.7242589\tbest: 0.7242589 (610)\ttotal: 1m 11s\tremaining: 2m 43s\n",
      "620:\ttest: 0.7348334\ttest1: 0.7243915\tbest: 0.7243967 (619)\ttotal: 1m 12s\tremaining: 2m 41s\n",
      "630:\ttest: 0.7350954\ttest1: 0.7245939\tbest: 0.7245939 (630)\ttotal: 1m 14s\tremaining: 2m 40s\n",
      "640:\ttest: 0.7353334\ttest1: 0.7246288\tbest: 0.7246288 (640)\ttotal: 1m 15s\tremaining: 2m 39s\n",
      "650:\ttest: 0.7357057\ttest1: 0.7249991\tbest: 0.7250207 (648)\ttotal: 1m 16s\tremaining: 2m 38s\n",
      "660:\ttest: 0.7360495\ttest1: 0.7250664\tbest: 0.7251563 (652)\ttotal: 1m 17s\tremaining: 2m 37s\n",
      "670:\ttest: 0.7362493\ttest1: 0.7251620\tbest: 0.7253236 (669)\ttotal: 1m 18s\tremaining: 2m 35s\n",
      "680:\ttest: 0.7364059\ttest1: 0.7252468\tbest: 0.7253337 (678)\ttotal: 1m 19s\tremaining: 2m 34s\n",
      "690:\ttest: 0.7367133\ttest1: 0.7252218\tbest: 0.7253621 (682)\ttotal: 1m 20s\tremaining: 2m 33s\n",
      "700:\ttest: 0.7369946\ttest1: 0.7254962\tbest: 0.7254962 (700)\ttotal: 1m 22s\tremaining: 2m 32s\n",
      "710:\ttest: 0.7372294\ttest1: 0.7255468\tbest: 0.7255468 (710)\ttotal: 1m 23s\tremaining: 2m 31s\n",
      "720:\ttest: 0.7375412\ttest1: 0.7257414\tbest: 0.7257414 (720)\ttotal: 1m 24s\tremaining: 2m 30s\n",
      "730:\ttest: 0.7378568\ttest1: 0.7260274\tbest: 0.7260274 (730)\ttotal: 1m 25s\tremaining: 2m 28s\n",
      "740:\ttest: 0.7381249\ttest1: 0.7260241\tbest: 0.7260913 (736)\ttotal: 1m 26s\tremaining: 2m 27s\n",
      "750:\ttest: 0.7384743\ttest1: 0.7263468\tbest: 0.7263468 (750)\ttotal: 1m 28s\tremaining: 2m 26s\n",
      "760:\ttest: 0.7387317\ttest1: 0.7262128\tbest: 0.7263832 (751)\ttotal: 1m 29s\tremaining: 2m 25s\n",
      "770:\ttest: 0.7389075\ttest1: 0.7260742\tbest: 0.7263832 (751)\ttotal: 1m 30s\tremaining: 2m 24s\n",
      "780:\ttest: 0.7392286\ttest1: 0.7261983\tbest: 0.7263832 (751)\ttotal: 1m 31s\tremaining: 2m 22s\n",
      "790:\ttest: 0.7394173\ttest1: 0.7263192\tbest: 0.7263832 (751)\ttotal: 1m 32s\tremaining: 2m 21s\n",
      "800:\ttest: 0.7395949\ttest1: 0.7263050\tbest: 0.7263832 (751)\ttotal: 1m 33s\tremaining: 2m 20s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7263831921\n",
      "bestIteration = 751\n",
      "\n",
      "Shrink model to first 752 iterations.\n",
      "Fold 2, Valid score = 0.72638\n",
      "0:\ttest: 0.6726414\ttest1: 0.6762924\tbest: 0.6762924 (0)\ttotal: 140ms\tremaining: 4m 39s\n",
      "10:\ttest: 0.6997830\ttest1: 0.7009374\tbest: 0.7009374 (10)\ttotal: 1.41s\tremaining: 4m 15s\n",
      "20:\ttest: 0.7021615\ttest1: 0.7040370\tbest: 0.7044587 (19)\ttotal: 2.63s\tremaining: 4m 7s\n",
      "30:\ttest: 0.7049362\ttest1: 0.7053683\tbest: 0.7057209 (29)\ttotal: 3.84s\tremaining: 4m 3s\n",
      "40:\ttest: 0.7056281\ttest1: 0.7064705\tbest: 0.7064705 (40)\ttotal: 5.03s\tremaining: 4m\n",
      "50:\ttest: 0.7063439\ttest1: 0.7073457\tbest: 0.7075734 (49)\ttotal: 6.23s\tremaining: 3m 58s\n",
      "60:\ttest: 0.7073357\ttest1: 0.7072643\tbest: 0.7079201 (55)\ttotal: 7.46s\tremaining: 3m 57s\n",
      "70:\ttest: 0.7079443\ttest1: 0.7083653\tbest: 0.7084416 (67)\ttotal: 8.64s\tremaining: 3m 54s\n",
      "80:\ttest: 0.7080791\ttest1: 0.7086654\tbest: 0.7086654 (80)\ttotal: 9.89s\tremaining: 3m 54s\n",
      "90:\ttest: 0.7084104\ttest1: 0.7083440\tbest: 0.7087246 (85)\ttotal: 11.1s\tremaining: 3m 52s\n",
      "100:\ttest: 0.7088160\ttest1: 0.7087412\tbest: 0.7089566 (99)\ttotal: 12.3s\tremaining: 3m 51s\n",
      "110:\ttest: 0.7090396\ttest1: 0.7088011\tbest: 0.7089978 (101)\ttotal: 13.5s\tremaining: 3m 49s\n",
      "120:\ttest: 0.7099367\ttest1: 0.7096591\tbest: 0.7096591 (120)\ttotal: 14.6s\tremaining: 3m 46s\n",
      "130:\ttest: 0.7102321\ttest1: 0.7098475\tbest: 0.7098475 (130)\ttotal: 15.7s\tremaining: 3m 43s\n",
      "140:\ttest: 0.7109256\ttest1: 0.7104185\tbest: 0.7105045 (135)\ttotal: 16.8s\tremaining: 3m 41s\n",
      "150:\ttest: 0.7116690\ttest1: 0.7111999\tbest: 0.7111999 (150)\ttotal: 17.9s\tremaining: 3m 39s\n",
      "160:\ttest: 0.7124006\ttest1: 0.7122916\tbest: 0.7122916 (160)\ttotal: 19s\tremaining: 3m 36s\n",
      "170:\ttest: 0.7131494\ttest1: 0.7131576\tbest: 0.7131576 (170)\ttotal: 20.1s\tremaining: 3m 35s\n",
      "180:\ttest: 0.7135253\ttest1: 0.7132151\tbest: 0.7135057 (179)\ttotal: 21.6s\tremaining: 3m 37s\n",
      "190:\ttest: 0.7143193\ttest1: 0.7141821\tbest: 0.7141821 (190)\ttotal: 22.9s\tremaining: 3m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200:\ttest: 0.7148753\ttest1: 0.7147597\tbest: 0.7150023 (198)\ttotal: 24.1s\tremaining: 3m 36s\n",
      "210:\ttest: 0.7155343\ttest1: 0.7160551\tbest: 0.7160551 (210)\ttotal: 25.4s\tremaining: 3m 35s\n",
      "220:\ttest: 0.7162537\ttest1: 0.7163370\tbest: 0.7163370 (220)\ttotal: 26.7s\tremaining: 3m 34s\n",
      "230:\ttest: 0.7170317\ttest1: 0.7167893\tbest: 0.7168715 (229)\ttotal: 28s\tremaining: 3m 34s\n",
      "240:\ttest: 0.7176536\ttest1: 0.7172015\tbest: 0.7172213 (239)\ttotal: 29.3s\tremaining: 3m 33s\n",
      "250:\ttest: 0.7183309\ttest1: 0.7181379\tbest: 0.7181379 (250)\ttotal: 30.5s\tremaining: 3m 32s\n",
      "260:\ttest: 0.7188662\ttest1: 0.7184569\tbest: 0.7184569 (260)\ttotal: 31.8s\tremaining: 3m 31s\n",
      "270:\ttest: 0.7195983\ttest1: 0.7190029\tbest: 0.7190029 (270)\ttotal: 33s\tremaining: 3m 30s\n",
      "280:\ttest: 0.7200566\ttest1: 0.7191380\tbest: 0.7191650 (279)\ttotal: 34s\tremaining: 3m 27s\n",
      "290:\ttest: 0.7205093\ttest1: 0.7196423\tbest: 0.7198270 (289)\ttotal: 35.2s\tremaining: 3m 26s\n",
      "300:\ttest: 0.7211720\ttest1: 0.7199142\tbest: 0.7200460 (299)\ttotal: 36.4s\tremaining: 3m 25s\n",
      "310:\ttest: 0.7216494\ttest1: 0.7206488\tbest: 0.7206488 (310)\ttotal: 37.6s\tremaining: 3m 24s\n",
      "320:\ttest: 0.7222380\ttest1: 0.7209790\tbest: 0.7209790 (320)\ttotal: 38.8s\tremaining: 3m 23s\n",
      "330:\ttest: 0.7224354\ttest1: 0.7213458\tbest: 0.7213458 (330)\ttotal: 40.1s\tremaining: 3m 22s\n",
      "340:\ttest: 0.7229978\ttest1: 0.7219649\tbest: 0.7219649 (340)\ttotal: 41.3s\tremaining: 3m 21s\n",
      "350:\ttest: 0.7236650\ttest1: 0.7225761\tbest: 0.7225761 (350)\ttotal: 42.5s\tremaining: 3m 19s\n",
      "360:\ttest: 0.7240249\ttest1: 0.7228962\tbest: 0.7229222 (358)\ttotal: 43.9s\tremaining: 3m 19s\n",
      "370:\ttest: 0.7245342\ttest1: 0.7234455\tbest: 0.7234634 (369)\ttotal: 45.1s\tremaining: 3m 18s\n",
      "380:\ttest: 0.7251510\ttest1: 0.7238145\tbest: 0.7238145 (380)\ttotal: 46.4s\tremaining: 3m 17s\n",
      "390:\ttest: 0.7257247\ttest1: 0.7241841\tbest: 0.7241841 (390)\ttotal: 47.6s\tremaining: 3m 16s\n",
      "400:\ttest: 0.7261637\ttest1: 0.7241854\tbest: 0.7242970 (391)\ttotal: 48.9s\tremaining: 3m 15s\n",
      "410:\ttest: 0.7266689\ttest1: 0.7244539\tbest: 0.7244727 (409)\ttotal: 50s\tremaining: 3m 13s\n",
      "420:\ttest: 0.7271217\ttest1: 0.7246872\tbest: 0.7247806 (419)\ttotal: 51.1s\tremaining: 3m 11s\n",
      "430:\ttest: 0.7276873\ttest1: 0.7250593\tbest: 0.7250593 (430)\ttotal: 52.2s\tremaining: 3m 9s\n",
      "440:\ttest: 0.7280662\ttest1: 0.7249555\tbest: 0.7250593 (430)\ttotal: 53.3s\tremaining: 3m 8s\n",
      "450:\ttest: 0.7286214\ttest1: 0.7252649\tbest: 0.7252649 (450)\ttotal: 54.4s\tremaining: 3m 6s\n",
      "460:\ttest: 0.7288523\ttest1: 0.7255501\tbest: 0.7255501 (460)\ttotal: 55.5s\tremaining: 3m 5s\n",
      "470:\ttest: 0.7293380\ttest1: 0.7258358\tbest: 0.7258358 (470)\ttotal: 56.6s\tremaining: 3m 3s\n",
      "480:\ttest: 0.7297731\ttest1: 0.7261665\tbest: 0.7261665 (480)\ttotal: 57.6s\tremaining: 3m 2s\n",
      "490:\ttest: 0.7300418\ttest1: 0.7263156\tbest: 0.7263156 (490)\ttotal: 58.7s\tremaining: 3m\n",
      "500:\ttest: 0.7302964\ttest1: 0.7265782\tbest: 0.7266344 (495)\ttotal: 59.9s\tremaining: 2m 59s\n",
      "510:\ttest: 0.7306580\ttest1: 0.7266064\tbest: 0.7266344 (495)\ttotal: 1m\tremaining: 2m 57s\n",
      "520:\ttest: 0.7310627\ttest1: 0.7269031\tbest: 0.7269031 (520)\ttotal: 1m 2s\tremaining: 2m 56s\n",
      "530:\ttest: 0.7313125\ttest1: 0.7269993\tbest: 0.7270122 (525)\ttotal: 1m 3s\tremaining: 2m 54s\n",
      "540:\ttest: 0.7315649\ttest1: 0.7271999\tbest: 0.7272416 (538)\ttotal: 1m 4s\tremaining: 2m 53s\n",
      "550:\ttest: 0.7318961\ttest1: 0.7272454\tbest: 0.7272598 (549)\ttotal: 1m 5s\tremaining: 2m 51s\n",
      "560:\ttest: 0.7321542\ttest1: 0.7274054\tbest: 0.7274054 (560)\ttotal: 1m 6s\tremaining: 2m 50s\n",
      "570:\ttest: 0.7325461\ttest1: 0.7276021\tbest: 0.7276085 (569)\ttotal: 1m 7s\tremaining: 2m 48s\n",
      "580:\ttest: 0.7328047\ttest1: 0.7275495\tbest: 0.7276085 (569)\ttotal: 1m 8s\tremaining: 2m 47s\n",
      "590:\ttest: 0.7332104\ttest1: 0.7276977\tbest: 0.7276977 (590)\ttotal: 1m 9s\tremaining: 2m 45s\n",
      "600:\ttest: 0.7335526\ttest1: 0.7278027\tbest: 0.7278027 (600)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "610:\ttest: 0.7337685\ttest1: 0.7279825\tbest: 0.7280338 (607)\ttotal: 1m 11s\tremaining: 2m 43s\n",
      "620:\ttest: 0.7338536\ttest1: 0.7280266\tbest: 0.7281141 (619)\ttotal: 1m 12s\tremaining: 2m 41s\n",
      "630:\ttest: 0.7342534\ttest1: 0.7280537\tbest: 0.7281584 (629)\ttotal: 1m 13s\tremaining: 2m 40s\n",
      "640:\ttest: 0.7345236\ttest1: 0.7284848\tbest: 0.7284848 (640)\ttotal: 1m 14s\tremaining: 2m 38s\n",
      "650:\ttest: 0.7347829\ttest1: 0.7284567\tbest: 0.7285822 (645)\ttotal: 1m 15s\tremaining: 2m 37s\n",
      "660:\ttest: 0.7350669\ttest1: 0.7287850\tbest: 0.7288780 (657)\ttotal: 1m 17s\tremaining: 2m 36s\n",
      "670:\ttest: 0.7353504\ttest1: 0.7288115\tbest: 0.7288780 (657)\ttotal: 1m 18s\tremaining: 2m 34s\n",
      "680:\ttest: 0.7354992\ttest1: 0.7286148\tbest: 0.7288780 (657)\ttotal: 1m 19s\tremaining: 2m 33s\n",
      "690:\ttest: 0.7358093\ttest1: 0.7288478\tbest: 0.7288780 (657)\ttotal: 1m 20s\tremaining: 2m 31s\n",
      "700:\ttest: 0.7359138\ttest1: 0.7287637\tbest: 0.7289210 (692)\ttotal: 1m 21s\tremaining: 2m 30s\n",
      "710:\ttest: 0.7362092\ttest1: 0.7291145\tbest: 0.7291167 (709)\ttotal: 1m 22s\tremaining: 2m 29s\n",
      "720:\ttest: 0.7364073\ttest1: 0.7291081\tbest: 0.7291301 (713)\ttotal: 1m 23s\tremaining: 2m 27s\n",
      "730:\ttest: 0.7366021\ttest1: 0.7294286\tbest: 0.7294286 (730)\ttotal: 1m 24s\tremaining: 2m 26s\n",
      "740:\ttest: 0.7368685\ttest1: 0.7295583\tbest: 0.7296629 (738)\ttotal: 1m 25s\tremaining: 2m 25s\n",
      "750:\ttest: 0.7370825\ttest1: 0.7296724\tbest: 0.7297100 (745)\ttotal: 1m 26s\tremaining: 2m 23s\n",
      "760:\ttest: 0.7372901\ttest1: 0.7297059\tbest: 0.7297941 (758)\ttotal: 1m 27s\tremaining: 2m 22s\n",
      "770:\ttest: 0.7374281\ttest1: 0.7298017\tbest: 0.7299082 (768)\ttotal: 1m 28s\tremaining: 2m 21s\n",
      "780:\ttest: 0.7377077\ttest1: 0.7298979\tbest: 0.7299082 (768)\ttotal: 1m 29s\tremaining: 2m 19s\n",
      "790:\ttest: 0.7380512\ttest1: 0.7297357\tbest: 0.7299825 (785)\ttotal: 1m 30s\tremaining: 2m 18s\n",
      "800:\ttest: 0.7383285\ttest1: 0.7297170\tbest: 0.7299825 (785)\ttotal: 1m 31s\tremaining: 2m 17s\n",
      "810:\ttest: 0.7385071\ttest1: 0.7297445\tbest: 0.7299825 (785)\ttotal: 1m 32s\tremaining: 2m 16s\n",
      "820:\ttest: 0.7387739\ttest1: 0.7298995\tbest: 0.7299825 (785)\ttotal: 1m 33s\tremaining: 2m 14s\n",
      "830:\ttest: 0.7389965\ttest1: 0.7298716\tbest: 0.7299825 (785)\ttotal: 1m 35s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7299825118\n",
      "bestIteration = 785\n",
      "\n",
      "Shrink model to first 786 iterations.\n",
      "Fold 3, Valid score = 0.72999\n",
      "0:\ttest: 0.6573217\ttest1: 0.6580999\tbest: 0.6580999 (0)\ttotal: 115ms\tremaining: 3m 50s\n",
      "10:\ttest: 0.7023566\ttest1: 0.7005952\tbest: 0.7005952 (10)\ttotal: 1.25s\tremaining: 3m 47s\n",
      "20:\ttest: 0.7063989\ttest1: 0.7033976\tbest: 0.7033976 (20)\ttotal: 2.4s\tremaining: 3m 46s\n",
      "30:\ttest: 0.7077686\ttest1: 0.7045898\tbest: 0.7048647 (25)\ttotal: 3.59s\tremaining: 3m 47s\n",
      "40:\ttest: 0.7089650\ttest1: 0.7049052\tbest: 0.7050581 (33)\ttotal: 4.71s\tremaining: 3m 45s\n",
      "50:\ttest: 0.7093678\ttest1: 0.7052295\tbest: 0.7052295 (50)\ttotal: 5.9s\tremaining: 3m 45s\n",
      "60:\ttest: 0.7091589\ttest1: 0.7044208\tbest: 0.7052295 (50)\ttotal: 7.03s\tremaining: 3m 43s\n",
      "70:\ttest: 0.7099171\ttest1: 0.7052124\tbest: 0.7052295 (50)\ttotal: 8.26s\tremaining: 3m 44s\n",
      "80:\ttest: 0.7105284\ttest1: 0.7053662\tbest: 0.7055553 (75)\ttotal: 9.42s\tremaining: 3m 43s\n",
      "90:\ttest: 0.7111164\ttest1: 0.7057485\tbest: 0.7060127 (88)\ttotal: 10.6s\tremaining: 3m 41s\n",
      "100:\ttest: 0.7113888\ttest1: 0.7057735\tbest: 0.7060127 (88)\ttotal: 11.7s\tremaining: 3m 39s\n",
      "110:\ttest: 0.7123408\ttest1: 0.7055978\tbest: 0.7060127 (88)\ttotal: 12.9s\tremaining: 3m 38s\n",
      "120:\ttest: 0.7128014\ttest1: 0.7061260\tbest: 0.7061260 (120)\ttotal: 14s\tremaining: 3m 37s\n",
      "130:\ttest: 0.7132835\ttest1: 0.7056935\tbest: 0.7061260 (120)\ttotal: 15.1s\tremaining: 3m 35s\n",
      "140:\ttest: 0.7137711\ttest1: 0.7059854\tbest: 0.7063963 (137)\ttotal: 16.3s\tremaining: 3m 34s\n",
      "150:\ttest: 0.7137883\ttest1: 0.7058228\tbest: 0.7063963 (137)\ttotal: 17.4s\tremaining: 3m 33s\n",
      "160:\ttest: 0.7145233\ttest1: 0.7062594\tbest: 0.7065452 (159)\ttotal: 18.5s\tremaining: 3m 31s\n",
      "170:\ttest: 0.7154737\ttest1: 0.7064568\tbest: 0.7069169 (169)\ttotal: 19.7s\tremaining: 3m 30s\n",
      "180:\ttest: 0.7161208\ttest1: 0.7074509\tbest: 0.7075414 (177)\ttotal: 20.8s\tremaining: 3m 28s\n",
      "190:\ttest: 0.7169542\ttest1: 0.7082626\tbest: 0.7082626 (190)\ttotal: 22s\tremaining: 3m 28s\n",
      "200:\ttest: 0.7176999\ttest1: 0.7085971\tbest: 0.7086065 (198)\ttotal: 23.1s\tremaining: 3m 26s\n",
      "210:\ttest: 0.7184388\ttest1: 0.7085024\tbest: 0.7086065 (198)\ttotal: 24.3s\tremaining: 3m 25s\n",
      "220:\ttest: 0.7188438\ttest1: 0.7085304\tbest: 0.7086065 (198)\ttotal: 25.4s\tremaining: 3m 24s\n",
      "230:\ttest: 0.7194945\ttest1: 0.7090919\tbest: 0.7091109 (227)\ttotal: 26.6s\tremaining: 3m 23s\n",
      "240:\ttest: 0.7200520\ttest1: 0.7092569\tbest: 0.7093088 (238)\ttotal: 27.6s\tremaining: 3m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250:\ttest: 0.7205258\ttest1: 0.7090452\tbest: 0.7093088 (238)\ttotal: 28.8s\tremaining: 3m 20s\n",
      "260:\ttest: 0.7211952\ttest1: 0.7094150\tbest: 0.7094454 (258)\ttotal: 29.9s\tremaining: 3m 19s\n",
      "270:\ttest: 0.7217562\ttest1: 0.7098355\tbest: 0.7098355 (270)\ttotal: 31s\tremaining: 3m 17s\n",
      "280:\ttest: 0.7224329\ttest1: 0.7102272\tbest: 0.7102272 (280)\ttotal: 32.1s\tremaining: 3m 16s\n",
      "290:\ttest: 0.7230225\ttest1: 0.7106736\tbest: 0.7107217 (289)\ttotal: 33.2s\tremaining: 3m 14s\n",
      "300:\ttest: 0.7236039\ttest1: 0.7109276\tbest: 0.7110676 (292)\ttotal: 34.2s\tremaining: 3m 13s\n",
      "310:\ttest: 0.7241218\ttest1: 0.7112946\tbest: 0.7114504 (309)\ttotal: 35.4s\tremaining: 3m 12s\n",
      "320:\ttest: 0.7245276\ttest1: 0.7117339\tbest: 0.7117339 (320)\ttotal: 36.5s\tremaining: 3m 11s\n",
      "330:\ttest: 0.7249405\ttest1: 0.7118951\tbest: 0.7118951 (330)\ttotal: 37.7s\tremaining: 3m 10s\n",
      "340:\ttest: 0.7255719\ttest1: 0.7123632\tbest: 0.7123632 (340)\ttotal: 38.9s\tremaining: 3m 9s\n",
      "350:\ttest: 0.7260102\ttest1: 0.7125803\tbest: 0.7127009 (347)\ttotal: 40.1s\tremaining: 3m 8s\n",
      "360:\ttest: 0.7265095\ttest1: 0.7128512\tbest: 0.7128512 (360)\ttotal: 41.2s\tremaining: 3m 7s\n",
      "370:\ttest: 0.7271592\ttest1: 0.7128640\tbest: 0.7129598 (367)\ttotal: 42.3s\tremaining: 3m 5s\n",
      "380:\ttest: 0.7275709\ttest1: 0.7131303\tbest: 0.7132514 (379)\ttotal: 43.5s\tremaining: 3m 4s\n",
      "390:\ttest: 0.7282129\ttest1: 0.7132440\tbest: 0.7133435 (387)\ttotal: 44.6s\tremaining: 3m 3s\n",
      "400:\ttest: 0.7288168\ttest1: 0.7136196\tbest: 0.7136196 (400)\ttotal: 45.7s\tremaining: 3m 2s\n",
      "410:\ttest: 0.7292111\ttest1: 0.7138783\tbest: 0.7139004 (408)\ttotal: 46.8s\tremaining: 3m\n",
      "420:\ttest: 0.7296840\ttest1: 0.7142707\tbest: 0.7142731 (419)\ttotal: 47.9s\tremaining: 2m 59s\n",
      "430:\ttest: 0.7300291\ttest1: 0.7143098\tbest: 0.7143773 (428)\ttotal: 49s\tremaining: 2m 58s\n",
      "440:\ttest: 0.7302431\ttest1: 0.7145689\tbest: 0.7145761 (438)\ttotal: 50.2s\tremaining: 2m 57s\n",
      "450:\ttest: 0.7304778\ttest1: 0.7147586\tbest: 0.7147586 (450)\ttotal: 51.3s\tremaining: 2m 56s\n",
      "460:\ttest: 0.7309633\ttest1: 0.7149487\tbest: 0.7149487 (460)\ttotal: 52.4s\tremaining: 2m 54s\n",
      "470:\ttest: 0.7314212\ttest1: 0.7150973\tbest: 0.7151766 (469)\ttotal: 53.5s\tremaining: 2m 53s\n",
      "480:\ttest: 0.7318350\ttest1: 0.7152567\tbest: 0.7154430 (477)\ttotal: 54.7s\tremaining: 2m 52s\n",
      "490:\ttest: 0.7320549\ttest1: 0.7157591\tbest: 0.7157591 (490)\ttotal: 55.8s\tremaining: 2m 51s\n",
      "500:\ttest: 0.7324143\ttest1: 0.7158293\tbest: 0.7160056 (498)\ttotal: 56.9s\tremaining: 2m 50s\n",
      "510:\ttest: 0.7328522\ttest1: 0.7158224\tbest: 0.7160605 (505)\ttotal: 58s\tremaining: 2m 48s\n",
      "520:\ttest: 0.7330508\ttest1: 0.7159549\tbest: 0.7160701 (516)\ttotal: 59.1s\tremaining: 2m 47s\n",
      "530:\ttest: 0.7333461\ttest1: 0.7160879\tbest: 0.7161744 (527)\ttotal: 1m\tremaining: 2m 46s\n",
      "540:\ttest: 0.7337099\ttest1: 0.7161708\tbest: 0.7163584 (538)\ttotal: 1m 1s\tremaining: 2m 44s\n",
      "550:\ttest: 0.7340209\ttest1: 0.7164498\tbest: 0.7165191 (546)\ttotal: 1m 2s\tremaining: 2m 43s\n",
      "560:\ttest: 0.7344352\ttest1: 0.7167794\tbest: 0.7167794 (560)\ttotal: 1m 3s\tremaining: 2m 42s\n",
      "570:\ttest: 0.7346916\ttest1: 0.7170151\tbest: 0.7170306 (569)\ttotal: 1m 4s\tremaining: 2m 41s\n",
      "580:\ttest: 0.7350340\ttest1: 0.7170724\tbest: 0.7172800 (576)\ttotal: 1m 5s\tremaining: 2m 39s\n",
      "590:\ttest: 0.7352320\ttest1: 0.7171787\tbest: 0.7172800 (576)\ttotal: 1m 6s\tremaining: 2m 38s\n",
      "600:\ttest: 0.7355126\ttest1: 0.7174615\tbest: 0.7174638 (599)\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "610:\ttest: 0.7359226\ttest1: 0.7176298\tbest: 0.7176298 (610)\ttotal: 1m 8s\tremaining: 2m 36s\n",
      "620:\ttest: 0.7360795\ttest1: 0.7176281\tbest: 0.7177066 (614)\ttotal: 1m 9s\tremaining: 2m 34s\n",
      "630:\ttest: 0.7363092\ttest1: 0.7176779\tbest: 0.7177066 (614)\ttotal: 1m 10s\tremaining: 2m 33s\n",
      "640:\ttest: 0.7366108\ttest1: 0.7178586\tbest: 0.7179756 (636)\ttotal: 1m 11s\tremaining: 2m 32s\n",
      "650:\ttest: 0.7368732\ttest1: 0.7180732\tbest: 0.7180732 (650)\ttotal: 1m 13s\tremaining: 2m 31s\n",
      "660:\ttest: 0.7369743\ttest1: 0.7180869\tbest: 0.7183094 (658)\ttotal: 1m 14s\tremaining: 2m 30s\n",
      "670:\ttest: 0.7372236\ttest1: 0.7184888\tbest: 0.7185410 (669)\ttotal: 1m 15s\tremaining: 2m 29s\n",
      "680:\ttest: 0.7375955\ttest1: 0.7188943\tbest: 0.7189860 (679)\ttotal: 1m 16s\tremaining: 2m 27s\n",
      "690:\ttest: 0.7378618\ttest1: 0.7189090\tbest: 0.7190986 (689)\ttotal: 1m 17s\tremaining: 2m 26s\n",
      "700:\ttest: 0.7381364\ttest1: 0.7189914\tbest: 0.7191103 (699)\ttotal: 1m 18s\tremaining: 2m 25s\n",
      "710:\ttest: 0.7385371\ttest1: 0.7191121\tbest: 0.7192201 (709)\ttotal: 1m 19s\tremaining: 2m 24s\n",
      "720:\ttest: 0.7387763\ttest1: 0.7190963\tbest: 0.7194055 (716)\ttotal: 1m 20s\tremaining: 2m 23s\n",
      "730:\ttest: 0.7390345\ttest1: 0.7192508\tbest: 0.7194055 (716)\ttotal: 1m 21s\tremaining: 2m 22s\n",
      "740:\ttest: 0.7392857\ttest1: 0.7192702\tbest: 0.7194055 (716)\ttotal: 1m 22s\tremaining: 2m 20s\n",
      "750:\ttest: 0.7394839\ttest1: 0.7194544\tbest: 0.7195024 (748)\ttotal: 1m 24s\tremaining: 2m 19s\n",
      "760:\ttest: 0.7397890\ttest1: 0.7196983\tbest: 0.7197294 (757)\ttotal: 1m 25s\tremaining: 2m 18s\n",
      "770:\ttest: 0.7399422\ttest1: 0.7198487\tbest: 0.7198487 (770)\ttotal: 1m 26s\tremaining: 2m 17s\n",
      "780:\ttest: 0.7402014\ttest1: 0.7197652\tbest: 0.7198487 (770)\ttotal: 1m 27s\tremaining: 2m 16s\n",
      "790:\ttest: 0.7404250\ttest1: 0.7198285\tbest: 0.7198487 (770)\ttotal: 1m 28s\tremaining: 2m 15s\n",
      "800:\ttest: 0.7405385\ttest1: 0.7198020\tbest: 0.7199265 (791)\ttotal: 1m 29s\tremaining: 2m 14s\n",
      "810:\ttest: 0.7408445\ttest1: 0.7199397\tbest: 0.7199397 (810)\ttotal: 1m 30s\tremaining: 2m 12s\n",
      "820:\ttest: 0.7411585\ttest1: 0.7199706\tbest: 0.7199799 (819)\ttotal: 1m 31s\tremaining: 2m 11s\n",
      "830:\ttest: 0.7413639\ttest1: 0.7201025\tbest: 0.7201025 (830)\ttotal: 1m 32s\tremaining: 2m 10s\n",
      "840:\ttest: 0.7415693\ttest1: 0.7201815\tbest: 0.7201943 (839)\ttotal: 1m 33s\tremaining: 2m 9s\n",
      "850:\ttest: 0.7417378\ttest1: 0.7201442\tbest: 0.7202027 (844)\ttotal: 1m 34s\tremaining: 2m 8s\n",
      "860:\ttest: 0.7419210\ttest1: 0.7202736\tbest: 0.7202920 (859)\ttotal: 1m 36s\tremaining: 2m 7s\n",
      "870:\ttest: 0.7421562\ttest1: 0.7202119\tbest: 0.7203187 (862)\ttotal: 1m 37s\tremaining: 2m 5s\n",
      "880:\ttest: 0.7423899\ttest1: 0.7202133\tbest: 0.7203187 (862)\ttotal: 1m 38s\tremaining: 2m 4s\n",
      "890:\ttest: 0.7425022\ttest1: 0.7204477\tbest: 0.7204477 (890)\ttotal: 1m 39s\tremaining: 2m 3s\n",
      "900:\ttest: 0.7426749\ttest1: 0.7203346\tbest: 0.7204771 (895)\ttotal: 1m 40s\tremaining: 2m 2s\n",
      "910:\ttest: 0.7429121\ttest1: 0.7204965\tbest: 0.7204965 (910)\ttotal: 1m 41s\tremaining: 2m 1s\n",
      "920:\ttest: 0.7430804\ttest1: 0.7204201\tbest: 0.7204965 (910)\ttotal: 1m 42s\tremaining: 2m\n",
      "930:\ttest: 0.7432739\ttest1: 0.7204466\tbest: 0.7204965 (910)\ttotal: 1m 43s\tremaining: 1m 59s\n",
      "940:\ttest: 0.7434460\ttest1: 0.7204374\tbest: 0.7204965 (910)\ttotal: 1m 44s\tremaining: 1m 57s\n",
      "950:\ttest: 0.7436445\ttest1: 0.7204735\tbest: 0.7204965 (910)\ttotal: 1m 45s\tremaining: 1m 56s\n",
      "960:\ttest: 0.7438336\ttest1: 0.7204716\tbest: 0.7205722 (955)\ttotal: 1m 46s\tremaining: 1m 55s\n",
      "970:\ttest: 0.7441681\ttest1: 0.7206588\tbest: 0.7206588 (970)\ttotal: 1m 47s\tremaining: 1m 54s\n",
      "980:\ttest: 0.7442300\ttest1: 0.7207202\tbest: 0.7207358 (977)\ttotal: 1m 48s\tremaining: 1m 52s\n",
      "990:\ttest: 0.7444173\ttest1: 0.7208026\tbest: 0.7208026 (990)\ttotal: 1m 49s\tremaining: 1m 51s\n",
      "1000:\ttest: 0.7446543\ttest1: 0.7207631\tbest: 0.7208026 (990)\ttotal: 1m 50s\tremaining: 1m 50s\n",
      "1010:\ttest: 0.7448270\ttest1: 0.7208216\tbest: 0.7208216 (1010)\ttotal: 1m 51s\tremaining: 1m 49s\n",
      "1020:\ttest: 0.7449413\ttest1: 0.7208322\tbest: 0.7208354 (1014)\ttotal: 1m 52s\tremaining: 1m 48s\n",
      "1030:\ttest: 0.7450517\ttest1: 0.7207719\tbest: 0.7208659 (1025)\ttotal: 1m 53s\tremaining: 1m 46s\n",
      "1040:\ttest: 0.7453217\ttest1: 0.7207388\tbest: 0.7208659 (1025)\ttotal: 1m 54s\tremaining: 1m 45s\n",
      "1050:\ttest: 0.7455176\ttest1: 0.7207693\tbest: 0.7208659 (1025)\ttotal: 1m 55s\tremaining: 1m 44s\n",
      "1060:\ttest: 0.7455843\ttest1: 0.7208013\tbest: 0.7208659 (1025)\ttotal: 1m 56s\tremaining: 1m 43s\n",
      "1070:\ttest: 0.7458564\ttest1: 0.7209119\tbest: 0.7209711 (1065)\ttotal: 1m 57s\tremaining: 1m 41s\n",
      "1080:\ttest: 0.7460461\ttest1: 0.7209831\tbest: 0.7209831 (1080)\ttotal: 1m 58s\tremaining: 1m 40s\n",
      "1090:\ttest: 0.7463325\ttest1: 0.7209573\tbest: 0.7210023 (1087)\ttotal: 1m 59s\tremaining: 1m 39s\n",
      "1100:\ttest: 0.7464948\ttest1: 0.7210011\tbest: 0.7210023 (1087)\ttotal: 2m\tremaining: 1m 38s\n",
      "1110:\ttest: 0.7466883\ttest1: 0.7210921\tbest: 0.7210921 (1110)\ttotal: 2m 1s\tremaining: 1m 37s\n",
      "1120:\ttest: 0.7468466\ttest1: 0.7211327\tbest: 0.7211475 (1118)\ttotal: 2m 2s\tremaining: 1m 36s\n",
      "1130:\ttest: 0.7472120\ttest1: 0.7212430\tbest: 0.7212544 (1129)\ttotal: 2m 3s\tremaining: 1m 35s\n",
      "1140:\ttest: 0.7474644\ttest1: 0.7211953\tbest: 0.7213218 (1136)\ttotal: 2m 4s\tremaining: 1m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150:\ttest: 0.7476175\ttest1: 0.7213730\tbest: 0.7213793 (1149)\ttotal: 2m 5s\tremaining: 1m 32s\n",
      "1160:\ttest: 0.7478340\ttest1: 0.7212903\tbest: 0.7213793 (1149)\ttotal: 2m 6s\tremaining: 1m 31s\n",
      "1170:\ttest: 0.7479798\ttest1: 0.7213998\tbest: 0.7214150 (1168)\ttotal: 2m 7s\tremaining: 1m 30s\n",
      "1180:\ttest: 0.7480866\ttest1: 0.7214179\tbest: 0.7214179 (1180)\ttotal: 2m 8s\tremaining: 1m 29s\n",
      "1190:\ttest: 0.7482241\ttest1: 0.7213467\tbest: 0.7215495 (1184)\ttotal: 2m 9s\tremaining: 1m 28s\n",
      "1200:\ttest: 0.7485157\ttest1: 0.7213675\tbest: 0.7215495 (1184)\ttotal: 2m 10s\tremaining: 1m 26s\n",
      "1210:\ttest: 0.7486463\ttest1: 0.7213554\tbest: 0.7215495 (1184)\ttotal: 2m 11s\tremaining: 1m 25s\n",
      "1220:\ttest: 0.7488918\ttest1: 0.7213513\tbest: 0.7215495 (1184)\ttotal: 2m 12s\tremaining: 1m 24s\n",
      "1230:\ttest: 0.7490701\ttest1: 0.7214572\tbest: 0.7215495 (1184)\ttotal: 2m 13s\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7215494853\n",
      "bestIteration = 1184\n",
      "\n",
      "Shrink model to first 1185 iterations.\n",
      "Fold 4, Valid score = 0.72155\n",
      "0:\ttest: 0.6586125\ttest1: 0.6529867\tbest: 0.6529867 (0)\ttotal: 108ms\tremaining: 3m 35s\n",
      "10:\ttest: 0.7027386\ttest1: 0.7012382\tbest: 0.7012382 (10)\ttotal: 1.17s\tremaining: 3m 31s\n",
      "20:\ttest: 0.7064282\ttest1: 0.7053068\tbest: 0.7054341 (19)\ttotal: 2.23s\tremaining: 3m 30s\n",
      "30:\ttest: 0.7079968\ttest1: 0.7054703\tbest: 0.7057276 (21)\ttotal: 3.31s\tremaining: 3m 30s\n",
      "40:\ttest: 0.7080088\ttest1: 0.7058867\tbest: 0.7058867 (40)\ttotal: 4.34s\tremaining: 3m 27s\n",
      "50:\ttest: 0.7081481\ttest1: 0.7049770\tbest: 0.7058867 (40)\ttotal: 5.37s\tremaining: 3m 25s\n",
      "60:\ttest: 0.7084777\ttest1: 0.7055965\tbest: 0.7058867 (40)\ttotal: 6.46s\tremaining: 3m 25s\n",
      "70:\ttest: 0.7091508\ttest1: 0.7062349\tbest: 0.7064577 (64)\ttotal: 7.51s\tremaining: 3m 23s\n",
      "80:\ttest: 0.7092932\ttest1: 0.7068407\tbest: 0.7068504 (78)\ttotal: 8.56s\tremaining: 3m 22s\n",
      "90:\ttest: 0.7101593\ttest1: 0.7070081\tbest: 0.7073790 (85)\ttotal: 9.62s\tremaining: 3m 21s\n",
      "100:\ttest: 0.7103357\ttest1: 0.7067539\tbest: 0.7073790 (85)\ttotal: 10.7s\tremaining: 3m 20s\n",
      "110:\ttest: 0.7106039\ttest1: 0.7068742\tbest: 0.7073790 (85)\ttotal: 11.7s\tremaining: 3m 19s\n",
      "120:\ttest: 0.7111959\ttest1: 0.7073775\tbest: 0.7074239 (117)\ttotal: 12.8s\tremaining: 3m 18s\n",
      "130:\ttest: 0.7116965\ttest1: 0.7078743\tbest: 0.7078743 (130)\ttotal: 13.8s\tremaining: 3m 17s\n",
      "140:\ttest: 0.7120956\ttest1: 0.7082923\tbest: 0.7082923 (140)\ttotal: 14.9s\tremaining: 3m 16s\n",
      "150:\ttest: 0.7130043\ttest1: 0.7086099\tbest: 0.7086513 (149)\ttotal: 16s\tremaining: 3m 16s\n",
      "160:\ttest: 0.7136241\ttest1: 0.7089472\tbest: 0.7089472 (160)\ttotal: 17.2s\tremaining: 3m 15s\n",
      "170:\ttest: 0.7142857\ttest1: 0.7097210\tbest: 0.7097834 (169)\ttotal: 18.2s\tremaining: 3m 15s\n",
      "180:\ttest: 0.7145830\ttest1: 0.7097748\tbest: 0.7097834 (169)\ttotal: 19.3s\tremaining: 3m 14s\n",
      "190:\ttest: 0.7155444\ttest1: 0.7102284\tbest: 0.7102284 (190)\ttotal: 20.4s\tremaining: 3m 13s\n",
      "200:\ttest: 0.7159736\ttest1: 0.7101383\tbest: 0.7102284 (190)\ttotal: 21.5s\tremaining: 3m 12s\n",
      "210:\ttest: 0.7165866\ttest1: 0.7107116\tbest: 0.7107729 (209)\ttotal: 22.5s\tremaining: 3m 10s\n",
      "220:\ttest: 0.7170589\ttest1: 0.7111545\tbest: 0.7111545 (219)\ttotal: 23.5s\tremaining: 3m 8s\n",
      "230:\ttest: 0.7177040\ttest1: 0.7119791\tbest: 0.7119791 (230)\ttotal: 24.5s\tremaining: 3m 7s\n",
      "240:\ttest: 0.7183580\ttest1: 0.7126206\tbest: 0.7126206 (240)\ttotal: 25.6s\tremaining: 3m 7s\n",
      "250:\ttest: 0.7187798\ttest1: 0.7129755\tbest: 0.7129755 (250)\ttotal: 26.7s\tremaining: 3m 6s\n",
      "260:\ttest: 0.7194550\ttest1: 0.7136682\tbest: 0.7136682 (260)\ttotal: 27.8s\tremaining: 3m 5s\n",
      "270:\ttest: 0.7201450\ttest1: 0.7142377\tbest: 0.7143312 (268)\ttotal: 28.8s\tremaining: 3m 3s\n",
      "280:\ttest: 0.7206338\ttest1: 0.7144841\tbest: 0.7144841 (280)\ttotal: 29.9s\tremaining: 3m 2s\n",
      "290:\ttest: 0.7212907\ttest1: 0.7151145\tbest: 0.7151145 (290)\ttotal: 30.9s\tremaining: 3m 1s\n",
      "300:\ttest: 0.7219761\ttest1: 0.7152641\tbest: 0.7153163 (297)\ttotal: 32s\tremaining: 3m\n",
      "310:\ttest: 0.7222182\ttest1: 0.7155316\tbest: 0.7155316 (310)\ttotal: 32.9s\tremaining: 2m 58s\n",
      "320:\ttest: 0.7228345\ttest1: 0.7162248\tbest: 0.7163479 (319)\ttotal: 34s\tremaining: 2m 57s\n",
      "330:\ttest: 0.7232027\ttest1: 0.7165813\tbest: 0.7165813 (330)\ttotal: 35s\tremaining: 2m 56s\n",
      "340:\ttest: 0.7238114\ttest1: 0.7170770\tbest: 0.7170770 (340)\ttotal: 36.1s\tremaining: 2m 55s\n",
      "350:\ttest: 0.7241123\ttest1: 0.7174981\tbest: 0.7174981 (350)\ttotal: 37.1s\tremaining: 2m 54s\n",
      "360:\ttest: 0.7245825\ttest1: 0.7177581\tbest: 0.7177874 (359)\ttotal: 38.2s\tremaining: 2m 53s\n",
      "370:\ttest: 0.7252198\ttest1: 0.7182279\tbest: 0.7182279 (370)\ttotal: 39.3s\tremaining: 2m 52s\n",
      "380:\ttest: 0.7256558\ttest1: 0.7182969\tbest: 0.7182969 (380)\ttotal: 40.3s\tremaining: 2m 51s\n",
      "390:\ttest: 0.7262384\ttest1: 0.7186552\tbest: 0.7186552 (390)\ttotal: 41.3s\tremaining: 2m 49s\n",
      "400:\ttest: 0.7266878\ttest1: 0.7191505\tbest: 0.7191505 (400)\ttotal: 42.3s\tremaining: 2m 48s\n",
      "410:\ttest: 0.7272268\ttest1: 0.7193283\tbest: 0.7193283 (410)\ttotal: 43.3s\tremaining: 2m 47s\n",
      "420:\ttest: 0.7278787\ttest1: 0.7194945\tbest: 0.7194945 (420)\ttotal: 44.3s\tremaining: 2m 46s\n",
      "430:\ttest: 0.7283131\ttest1: 0.7196742\tbest: 0.7196742 (430)\ttotal: 45.3s\tremaining: 2m 45s\n",
      "440:\ttest: 0.7288764\ttest1: 0.7199345\tbest: 0.7199345 (440)\ttotal: 46.4s\tremaining: 2m 43s\n",
      "450:\ttest: 0.7293090\ttest1: 0.7203680\tbest: 0.7203883 (449)\ttotal: 47.4s\tremaining: 2m 42s\n",
      "460:\ttest: 0.7296419\ttest1: 0.7205766\tbest: 0.7205868 (459)\ttotal: 48.4s\tremaining: 2m 41s\n",
      "470:\ttest: 0.7299984\ttest1: 0.7206430\tbest: 0.7206723 (469)\ttotal: 49.5s\tremaining: 2m 40s\n",
      "480:\ttest: 0.7303642\ttest1: 0.7209294\tbest: 0.7209294 (480)\ttotal: 50.5s\tremaining: 2m 39s\n",
      "490:\ttest: 0.7307467\ttest1: 0.7211072\tbest: 0.7211072 (490)\ttotal: 51.6s\tremaining: 2m 38s\n",
      "500:\ttest: 0.7310360\ttest1: 0.7212260\tbest: 0.7212260 (500)\ttotal: 52.5s\tremaining: 2m 37s\n",
      "510:\ttest: 0.7314952\ttest1: 0.7213905\tbest: 0.7213975 (509)\ttotal: 53.6s\tremaining: 2m 36s\n",
      "520:\ttest: 0.7317011\ttest1: 0.7213869\tbest: 0.7214085 (518)\ttotal: 54.6s\tremaining: 2m 35s\n",
      "530:\ttest: 0.7319705\ttest1: 0.7214804\tbest: 0.7214944 (527)\ttotal: 55.6s\tremaining: 2m 33s\n",
      "540:\ttest: 0.7323522\ttest1: 0.7215934\tbest: 0.7216683 (539)\ttotal: 56.7s\tremaining: 2m 32s\n",
      "550:\ttest: 0.7327117\ttest1: 0.7216864\tbest: 0.7216874 (548)\ttotal: 57.7s\tremaining: 2m 31s\n",
      "560:\ttest: 0.7331275\ttest1: 0.7217753\tbest: 0.7217904 (559)\ttotal: 58.6s\tremaining: 2m 30s\n",
      "570:\ttest: 0.7333668\ttest1: 0.7218103\tbest: 0.7218439 (563)\ttotal: 59.6s\tremaining: 2m 29s\n",
      "580:\ttest: 0.7335103\ttest1: 0.7217274\tbest: 0.7218439 (563)\ttotal: 1m\tremaining: 2m 28s\n",
      "590:\ttest: 0.7338644\ttest1: 0.7218720\tbest: 0.7219292 (585)\ttotal: 1m 1s\tremaining: 2m 27s\n",
      "600:\ttest: 0.7341157\ttest1: 0.7220214\tbest: 0.7220214 (600)\ttotal: 1m 2s\tremaining: 2m 26s\n",
      "610:\ttest: 0.7343540\ttest1: 0.7221283\tbest: 0.7222220 (609)\ttotal: 1m 3s\tremaining: 2m 24s\n",
      "620:\ttest: 0.7347805\ttest1: 0.7224172\tbest: 0.7224172 (620)\ttotal: 1m 4s\tremaining: 2m 23s\n",
      "630:\ttest: 0.7351175\ttest1: 0.7223595\tbest: 0.7224172 (620)\ttotal: 1m 5s\tremaining: 2m 22s\n",
      "640:\ttest: 0.7352893\ttest1: 0.7225386\tbest: 0.7225386 (640)\ttotal: 1m 6s\tremaining: 2m 21s\n",
      "650:\ttest: 0.7358001\ttest1: 0.7227210\tbest: 0.7227795 (644)\ttotal: 1m 7s\tremaining: 2m 20s\n",
      "660:\ttest: 0.7360701\ttest1: 0.7227309\tbest: 0.7228317 (656)\ttotal: 1m 8s\tremaining: 2m 19s\n",
      "670:\ttest: 0.7362331\ttest1: 0.7226827\tbest: 0.7229283 (665)\ttotal: 1m 9s\tremaining: 2m 18s\n",
      "680:\ttest: 0.7364120\ttest1: 0.7228401\tbest: 0.7229283 (665)\ttotal: 1m 10s\tremaining: 2m 17s\n",
      "690:\ttest: 0.7366460\ttest1: 0.7230162\tbest: 0.7230972 (683)\ttotal: 1m 11s\tremaining: 2m 16s\n",
      "700:\ttest: 0.7369845\ttest1: 0.7231900\tbest: 0.7231900 (700)\ttotal: 1m 12s\tremaining: 2m 15s\n",
      "710:\ttest: 0.7371297\ttest1: 0.7232468\tbest: 0.7232468 (710)\ttotal: 1m 13s\tremaining: 2m 14s\n",
      "720:\ttest: 0.7374031\ttest1: 0.7232478\tbest: 0.7232661 (711)\ttotal: 1m 14s\tremaining: 2m 12s\n",
      "730:\ttest: 0.7377033\ttest1: 0.7233457\tbest: 0.7233578 (729)\ttotal: 1m 15s\tremaining: 2m 11s\n",
      "740:\ttest: 0.7379341\ttest1: 0.7233476\tbest: 0.7234837 (737)\ttotal: 1m 16s\tremaining: 2m 10s\n",
      "750:\ttest: 0.7380989\ttest1: 0.7235060\tbest: 0.7235158 (748)\ttotal: 1m 18s\tremaining: 2m 9s\n",
      "760:\ttest: 0.7384387\ttest1: 0.7236478\tbest: 0.7236688 (756)\ttotal: 1m 19s\tremaining: 2m 8s\n",
      "770:\ttest: 0.7386128\ttest1: 0.7236979\tbest: 0.7237225 (769)\ttotal: 1m 20s\tremaining: 2m 7s\n",
      "780:\ttest: 0.7388421\ttest1: 0.7238086\tbest: 0.7238894 (776)\ttotal: 1m 21s\tremaining: 2m 6s\n",
      "790:\ttest: 0.7390250\ttest1: 0.7236963\tbest: 0.7238894 (776)\ttotal: 1m 22s\tremaining: 2m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800:\ttest: 0.7393180\ttest1: 0.7236731\tbest: 0.7238894 (776)\ttotal: 1m 23s\tremaining: 2m 4s\n",
      "810:\ttest: 0.7397406\ttest1: 0.7237608\tbest: 0.7238894 (776)\ttotal: 1m 24s\tremaining: 2m 3s\n",
      "820:\ttest: 0.7400769\ttest1: 0.7240972\tbest: 0.7240972 (820)\ttotal: 1m 25s\tremaining: 2m 2s\n",
      "830:\ttest: 0.7401985\ttest1: 0.7240538\tbest: 0.7241155 (821)\ttotal: 1m 26s\tremaining: 2m 1s\n",
      "840:\ttest: 0.7403660\ttest1: 0.7241150\tbest: 0.7241158 (839)\ttotal: 1m 27s\tremaining: 2m\n",
      "850:\ttest: 0.7405366\ttest1: 0.7241955\tbest: 0.7242106 (847)\ttotal: 1m 28s\tremaining: 1m 59s\n",
      "860:\ttest: 0.7407310\ttest1: 0.7240821\tbest: 0.7242293 (854)\ttotal: 1m 29s\tremaining: 1m 57s\n",
      "870:\ttest: 0.7409686\ttest1: 0.7239965\tbest: 0.7242293 (854)\ttotal: 1m 30s\tremaining: 1m 56s\n",
      "880:\ttest: 0.7412699\ttest1: 0.7241222\tbest: 0.7242293 (854)\ttotal: 1m 31s\tremaining: 1m 55s\n",
      "890:\ttest: 0.7414287\ttest1: 0.7240674\tbest: 0.7242293 (854)\ttotal: 1m 32s\tremaining: 1m 54s\n",
      "900:\ttest: 0.7416672\ttest1: 0.7241307\tbest: 0.7242531 (898)\ttotal: 1m 33s\tremaining: 1m 53s\n",
      "910:\ttest: 0.7419715\ttest1: 0.7242128\tbest: 0.7242531 (898)\ttotal: 1m 34s\tremaining: 1m 52s\n",
      "920:\ttest: 0.7422154\ttest1: 0.7241995\tbest: 0.7242531 (898)\ttotal: 1m 35s\tremaining: 1m 51s\n",
      "930:\ttest: 0.7424042\ttest1: 0.7242195\tbest: 0.7242531 (898)\ttotal: 1m 36s\tremaining: 1m 50s\n",
      "940:\ttest: 0.7425616\ttest1: 0.7241381\tbest: 0.7242531 (898)\ttotal: 1m 37s\tremaining: 1m 49s\n",
      "950:\ttest: 0.7428547\ttest1: 0.7242777\tbest: 0.7243073 (949)\ttotal: 1m 38s\tremaining: 1m 48s\n",
      "960:\ttest: 0.7430520\ttest1: 0.7242991\tbest: 0.7243354 (952)\ttotal: 1m 39s\tremaining: 1m 47s\n",
      "970:\ttest: 0.7433726\ttest1: 0.7242275\tbest: 0.7243383 (965)\ttotal: 1m 40s\tremaining: 1m 46s\n",
      "980:\ttest: 0.7435985\ttest1: 0.7244519\tbest: 0.7244519 (980)\ttotal: 1m 41s\tremaining: 1m 45s\n",
      "990:\ttest: 0.7438396\ttest1: 0.7245988\tbest: 0.7246029 (987)\ttotal: 1m 42s\tremaining: 1m 44s\n",
      "1000:\ttest: 0.7440238\ttest1: 0.7245792\tbest: 0.7246351 (999)\ttotal: 1m 43s\tremaining: 1m 43s\n",
      "1010:\ttest: 0.7441484\ttest1: 0.7246538\tbest: 0.7246538 (1010)\ttotal: 1m 44s\tremaining: 1m 42s\n",
      "1020:\ttest: 0.7442537\ttest1: 0.7245303\tbest: 0.7247922 (1016)\ttotal: 1m 45s\tremaining: 1m 41s\n",
      "1030:\ttest: 0.7444438\ttest1: 0.7246783\tbest: 0.7247922 (1016)\ttotal: 1m 46s\tremaining: 1m 40s\n",
      "1040:\ttest: 0.7445621\ttest1: 0.7248156\tbest: 0.7248229 (1033)\ttotal: 1m 47s\tremaining: 1m 39s\n",
      "1050:\ttest: 0.7448269\ttest1: 0.7247370\tbest: 0.7248229 (1033)\ttotal: 1m 48s\tremaining: 1m 38s\n",
      "1060:\ttest: 0.7451507\ttest1: 0.7248299\tbest: 0.7249234 (1057)\ttotal: 1m 49s\tremaining: 1m 37s\n",
      "1070:\ttest: 0.7453000\ttest1: 0.7249367\tbest: 0.7250246 (1069)\ttotal: 1m 50s\tremaining: 1m 36s\n",
      "1080:\ttest: 0.7455720\ttest1: 0.7249906\tbest: 0.7250748 (1079)\ttotal: 1m 51s\tremaining: 1m 35s\n",
      "1090:\ttest: 0.7457237\ttest1: 0.7250102\tbest: 0.7250748 (1079)\ttotal: 1m 52s\tremaining: 1m 34s\n",
      "1100:\ttest: 0.7459833\ttest1: 0.7248925\tbest: 0.7251397 (1091)\ttotal: 1m 54s\tremaining: 1m 33s\n",
      "1110:\ttest: 0.7460582\ttest1: 0.7248530\tbest: 0.7251397 (1091)\ttotal: 1m 55s\tremaining: 1m 32s\n",
      "1120:\ttest: 0.7462865\ttest1: 0.7250106\tbest: 0.7251397 (1091)\ttotal: 1m 56s\tremaining: 1m 31s\n",
      "1130:\ttest: 0.7464100\ttest1: 0.7250172\tbest: 0.7251397 (1091)\ttotal: 1m 57s\tremaining: 1m 30s\n",
      "1140:\ttest: 0.7466523\ttest1: 0.7251355\tbest: 0.7251397 (1091)\ttotal: 1m 58s\tremaining: 1m 28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7251396814\n",
      "bestIteration = 1091\n",
      "\n",
      "Shrink model to first 1092 iterations.\n",
      "Fold 5, Valid score = 0.72514\n",
      "Score by each fold: [0.72068, 0.72638, 0.72999, 0.72155, 0.72514]\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "cb_params = {\n",
    "    \"n_estimators\": 2000,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss_function\": \"Logloss\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"max_bin\": 20,\n",
    "    \"verbose\": 10,\n",
    "    \"max_depth\": 6,\n",
    "    \"l2_leaf_reg\": 10,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"thread_count\": 6,\n",
    "    \"random_seed\": 42\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=1234123, shuffle=True)\n",
    "\n",
    "estimators, oof_preds = catboost_cross_validation(\n",
    "    params=cb_params, X=train, y=target, cv=cv, categorical=categorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72378\n"
     ]
    }
   ],
   "source": [
    "oof_preds_cb = oof_preds\n",
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_cb\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль нескольких моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оценить корреляцию прогнозов на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.36165103],\n",
       "       [0.36165103, 1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(\n",
    "    x = oof_preds_lgb,\n",
    "    y = oof_preds_xgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.01071466, 0.08306752, 0.06918635, ..., 0.08362073, 0.01843834,\n",
       "        0.0997197 ]),\n",
       " array([0.02397243, 0.08568921, 0.06078126, ..., 0.08364594, 0.03411563,\n",
       "        0.06130429])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_train = []\n",
    "oof_train.append(oof_preds_lgb)\n",
    "oof_train.append(oof_preds_cb)\n",
    "#oof_train = np.array(oof_train)\n",
    "oof_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применить модели на тестовую выборку и оценить корреляцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test[numerical]\n",
    "y_pred_cb = np.zeros(test.shape[0])\n",
    "test[numerical] = test[numerical].astype(float)\n",
    "test[categorial] = test[categorial].astype(str)\n",
    "\n",
    "for estimator in estimators:\n",
    "    y_pred_cb += estimator.predict_proba(test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0579011 , 0.21880019, 0.19389816, ..., 0.08437272, 0.02094533,\n",
       "       0.05025549])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cb = y_pred_cb / cv.n_splits\n",
    "y_pred_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.9035469],\n",
       "       [0.9035469, 1.       ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(\n",
    "    x = y_pred_cb,\n",
    "    y = y_pred_lgb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04265717, 0.28020678, 0.13450095, ..., 0.08217762, 0.01037823,\n",
       "        0.02629846],\n",
       "       [0.0579011 , 0.21880019, 0.19389816, ..., 0.08437272, 0.02094533,\n",
       "        0.05025549]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_test = []\n",
    "oof_test.append(y_pred_lgb)\n",
    "oof_test.append(y_pred_cb)\n",
    "oof_test = np.array(oof_test)\n",
    "oof_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>110078</th>\n",
       "      <th>110079</th>\n",
       "      <th>110080</th>\n",
       "      <th>110081</th>\n",
       "      <th>110082</th>\n",
       "      <th>110083</th>\n",
       "      <th>110084</th>\n",
       "      <th>110085</th>\n",
       "      <th>110086</th>\n",
       "      <th>110087</th>\n",
       "      <th>110088</th>\n",
       "      <th>110089</th>\n",
       "      <th>110090</th>\n",
       "      <th>110091</th>\n",
       "      <th>110092</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.083068</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.113912</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.560826</td>\n",
       "      <td>0.025938</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.108530</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.082242</td>\n",
       "      <td>0.061880</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056113</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.025226</td>\n",
       "      <td>0.107808</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.081648</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.038181</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>0.018438</td>\n",
       "      <td>0.099720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.060781</td>\n",
       "      <td>0.202907</td>\n",
       "      <td>0.082412</td>\n",
       "      <td>0.157971</td>\n",
       "      <td>0.036464</td>\n",
       "      <td>0.106675</td>\n",
       "      <td>0.108352</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>0.083646</td>\n",
       "      <td>0.066941</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.107796</td>\n",
       "      <td>0.246632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.066687</td>\n",
       "      <td>0.099185</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.040882</td>\n",
       "      <td>0.082412</td>\n",
       "      <td>0.085689</td>\n",
       "      <td>0.063469</td>\n",
       "      <td>0.084203</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.083646</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>0.061304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 110093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.010715  0.083068  0.069186  0.113912  0.083621  0.560826  0.025938   \n",
       "1  0.023972  0.085689  0.060781  0.202907  0.082412  0.157971  0.036464   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.032510  0.108530  0.038389  0.082242  0.061880  0.007936  0.129061   \n",
       "1  0.106675  0.108352  0.072403  0.083646  0.066941  0.021256  0.107796   \n",
       "\n",
       "     14      ...    110078    110079    110080    110081    110082    110083  \\\n",
       "0  0.237281  ...  0.056113  0.222659  0.025226  0.107808  0.012001  0.052649   \n",
       "1  0.246632  ...  0.066901  0.044671  0.066687  0.099185  0.019749  0.040882   \n",
       "\n",
       "     110084    110085    110086    110087    110088    110089    110090  \\\n",
       "0  0.081648  0.082990  0.081648  0.081648  0.083621  0.038181  0.083621   \n",
       "1  0.082412  0.085689  0.063469  0.084203  0.085914  0.054190  0.083646   \n",
       "\n",
       "     110091    110092  \n",
       "0  0.018438  0.099720  \n",
       "1  0.034116  0.061304  \n",
       "\n",
       "[2 rows x 110093 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_train)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015146657931371735"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6447537891184425"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(oof_train[0] - oof_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>165126</th>\n",
       "      <th>165127</th>\n",
       "      <th>165128</th>\n",
       "      <th>165129</th>\n",
       "      <th>165130</th>\n",
       "      <th>165131</th>\n",
       "      <th>165132</th>\n",
       "      <th>165133</th>\n",
       "      <th>165134</th>\n",
       "      <th>165135</th>\n",
       "      <th>165136</th>\n",
       "      <th>165137</th>\n",
       "      <th>165138</th>\n",
       "      <th>165139</th>\n",
       "      <th>165140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042657</td>\n",
       "      <td>0.280207</td>\n",
       "      <td>0.134501</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.018202</td>\n",
       "      <td>0.026691</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.101307</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.020221</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.042439</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>0.083732</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022487</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.040369</td>\n",
       "      <td>0.082178</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.026298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>0.193898</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.062838</td>\n",
       "      <td>0.121554</td>\n",
       "      <td>0.013626</td>\n",
       "      <td>0.032082</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.053428</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.104590</td>\n",
       "      <td>0.035006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027869</td>\n",
       "      <td>0.093394</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.045271</td>\n",
       "      <td>0.084373</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.050255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6       \\\n",
       "0  0.042657  0.280207  0.134501  0.082178  0.018202  0.026691  0.082178   \n",
       "1  0.057901  0.218800  0.193898  0.084373  0.021954  0.027600  0.062838   \n",
       "\n",
       "     7         8         9         10        11        12        13      \\\n",
       "0  0.101307  0.002751  0.020221  0.082178  0.042439  0.029281  0.083732   \n",
       "1  0.121554  0.013626  0.032082  0.084373  0.053428  0.041428  0.104590   \n",
       "\n",
       "     14      ...    165126    165127   165128    165129    165130    165131  \\\n",
       "0  0.020947  ...  0.022487  0.062768  0.01345  0.009253  0.003990  0.082178   \n",
       "1  0.035006  ...  0.027869  0.093394  0.01265  0.021012  0.011818  0.084373   \n",
       "\n",
       "     165132    165133    165134    165135    165136    165137    165138  \\\n",
       "0  0.082178  0.082178  0.006549  0.082178  0.082178  0.040369  0.082178   \n",
       "1  0.084373  0.084373  0.010979  0.084373  0.084373  0.045271  0.084373   \n",
       "\n",
       "     165139    165140  \n",
       "0  0.010378  0.026298  \n",
       "1  0.020945  0.050255  \n",
       "\n",
       "[2 rows x 165141 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = pd.DataFrame(oof_test)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.001287118063018821"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(oof_test[0] - oof_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_arifm = (oof_preds_lgb + oof_preds_cb) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_geom = (oof_preds_lgb * oof_preds_cb) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72234\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_arifm\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72258\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, oof_preds_geom\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")\n",
    "# [0.72194, 0.72659, 0.73283, 0.72053, 0.72657]\n",
    "# OOF-score = 0.72481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11362.  , 78218.  , 53087.5 , ..., 75194.75, 21968.5 , 68548.  ])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_rank = rankdata(oof_preds_lgb) \n",
    "cb_rank = rankdata(oof_preds_cb)\n",
    "amean_rank = (lgb_rank + cb_rank) / 2\n",
    "amean_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF-score = 0.72214\n"
     ]
    }
   ],
   "source": [
    "oof_score = roc_auc_score(\n",
    "    target, amean_rank\n",
    ")\n",
    "print(f\"OOF-score = {round(oof_score, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего с геперпараметрами из коробки работает catBoost. Он показал результат 72%. LightGBM занял 2 место и показал результат 71%, но зато модель обучалась значительно быстрее. XGBoost показал плохой результат, но возможно требуется тюнинг гиперпараметров. Ансамбль моделей catBoost и lgb не привел к улучшению результата. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
