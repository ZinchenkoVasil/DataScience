{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "hw7_AttentionTransformer.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xin7g0jk3AFv",
        "colab_type": "text"
      },
      "source": [
        "# В предыдущей серии\n",
        "\n",
        "\n",
        "<img src=\"images/RNNCompar.png\"/>\n",
        "\n",
        "\n",
        "Мы посмотрели на задачу классификации текстов. Но есть ряд более сильных подходов, которые лучше показывать через задачу генерации\n",
        "\n",
        "\n",
        "# Генерация текстов, encoder-decoder\n",
        "\n",
        "<img src=\"images/EncDec.png\"/>\n",
        "\n",
        "\n",
        "Данная архитектура называется seq2seq, простыми словами выглядит она следующим образом:\n",
        "<img src=\"images/seq2seq.png\"/>\n",
        "\n",
        "\n",
        "эту модель можно строить на уровне слов и на уровне токенов. Попробуем обучить на уровне токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6jqRZ1c3AFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jrdADhQ3AF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 30\n",
        "latent_dim = 256\n",
        "num_samples = 10000\n",
        "data_path = 'rus.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByX7IpYI3AF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guv4Mdua3AF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjvwump03AF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_SlQ1ad3AGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhaK7KZx3AGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cd67d2c-6b0c-4be9-d555-6182a5d50bbd"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "125/125 [==============================] - 47s 376ms/step - loss: 1.1416 - accuracy: 0.7739 - val_loss: 0.9398 - val_accuracy: 0.7596\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 47s 373ms/step - loss: 0.7370 - accuracy: 0.8017 - val_loss: 0.7789 - val_accuracy: 0.7947\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 46s 371ms/step - loss: 0.7188 - accuracy: 0.8181 - val_loss: 0.7625 - val_accuracy: 0.7963\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 46s 371ms/step - loss: 0.6198 - accuracy: 0.8351 - val_loss: 0.6781 - val_accuracy: 0.8141\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 47s 374ms/step - loss: 0.5645 - accuracy: 0.8439 - val_loss: 0.6379 - val_accuracy: 0.8208\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 46s 371ms/step - loss: 0.5352 - accuracy: 0.8495 - val_loss: 0.6138 - val_accuracy: 0.8262\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 46s 369ms/step - loss: 0.5156 - accuracy: 0.8532 - val_loss: 0.5911 - val_accuracy: 0.8303\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 46s 368ms/step - loss: 0.5000 - accuracy: 0.8565 - val_loss: 0.5795 - val_accuracy: 0.8304\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 47s 373ms/step - loss: 0.4871 - accuracy: 0.8593 - val_loss: 0.5666 - val_accuracy: 0.8347\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 46s 365ms/step - loss: 0.4747 - accuracy: 0.8618 - val_loss: 0.5545 - val_accuracy: 0.8391\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 46s 367ms/step - loss: 0.5923 - accuracy: 0.8463 - val_loss: 0.6040 - val_accuracy: 0.8287\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 46s 369ms/step - loss: 0.4960 - accuracy: 0.8577 - val_loss: 0.5657 - val_accuracy: 0.8359\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 46s 367ms/step - loss: 0.4755 - accuracy: 0.8621 - val_loss: 0.5523 - val_accuracy: 0.8400\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 46s 365ms/step - loss: 0.4644 - accuracy: 0.8646 - val_loss: 0.5423 - val_accuracy: 0.8426\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 46s 368ms/step - loss: 0.4558 - accuracy: 0.8668 - val_loss: 0.5340 - val_accuracy: 0.8437\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 46s 369ms/step - loss: 0.4490 - accuracy: 0.8684 - val_loss: 0.5281 - val_accuracy: 0.8462\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 46s 368ms/step - loss: 0.4421 - accuracy: 0.8702 - val_loss: 0.5215 - val_accuracy: 0.8476\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 46s 368ms/step - loss: 0.4358 - accuracy: 0.8717 - val_loss: 0.5168 - val_accuracy: 0.8477\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 47s 374ms/step - loss: 0.4298 - accuracy: 0.8737 - val_loss: 0.5100 - val_accuracy: 0.8507\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 46s 365ms/step - loss: 0.4231 - accuracy: 0.8755 - val_loss: 0.5053 - val_accuracy: 0.8517\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 46s 366ms/step - loss: 0.4166 - accuracy: 0.8772 - val_loss: 0.5014 - val_accuracy: 0.8530\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 46s 370ms/step - loss: 0.4104 - accuracy: 0.8789 - val_loss: 0.4917 - val_accuracy: 0.8561\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 45s 364ms/step - loss: 0.4047 - accuracy: 0.8805 - val_loss: 0.4905 - val_accuracy: 0.8554\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 45s 364ms/step - loss: 0.3977 - accuracy: 0.8829 - val_loss: 0.4852 - val_accuracy: 0.8579\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 45s 363ms/step - loss: 0.3912 - accuracy: 0.8848 - val_loss: 0.4806 - val_accuracy: 0.8596\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 45s 363ms/step - loss: 0.3854 - accuracy: 0.8864 - val_loss: 0.4756 - val_accuracy: 0.8624\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 45s 363ms/step - loss: 0.3789 - accuracy: 0.8884 - val_loss: 0.4698 - val_accuracy: 0.8628\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 45s 363ms/step - loss: 0.3727 - accuracy: 0.8906 - val_loss: 0.4696 - val_accuracy: 0.8645\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 46s 367ms/step - loss: 0.3668 - accuracy: 0.8924 - val_loss: 0.4605 - val_accuracy: 0.8675\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 45s 363ms/step - loss: 0.3598 - accuracy: 0.8945 - val_loss: 0.4560 - val_accuracy: 0.8685\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Иди ста.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Иди ста.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Иди ста.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Провайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Провайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Провайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Провайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Провайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Простайтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Простайтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Пострайтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Пострайтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Who?\n",
            "Decoded sentence: Кто было не породи?\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Как та мне!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Постаньтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Постаньтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Посмотите мне.\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Посмотите мне.\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Посмотите мне.\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Просто на меня!\n",
            "\n",
            "-\n",
            "Input sentence: Jump!\n",
            "Decoded sentence: Просто на меня!\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Просто одомойте это.\n",
            "\n",
            "-\n",
            "Input sentence: Jump.\n",
            "Decoded sentence: Просто одомойте это.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Прекратите на мне.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Прекратите на мне.\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Прекратите на мне.\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Подождите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Do it.\n",
            "Decoded sentence: Постаньтесь это.\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Идите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Идите содань!\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Провоти это.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Провоти это.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Провоти это.\n",
            "\n",
            "-\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Провоти это.\n",
            "\n",
            "-\n",
            "Input sentence: Hurry!\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я постал.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я постал.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я постал.\n",
            "\n",
            "-\n",
            "Input sentence: I ran.\n",
            "Decoded sentence: Я постал.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I see.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I try.\n",
            "Decoded sentence: Я постала.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я была на на.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я была на на.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я была на на.\n",
            "\n",
            "-\n",
            "Input sentence: I won!\n",
            "Decoded sentence: Я была на на.\n",
            "\n",
            "-\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: Покожите это.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Relax.\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: Пристайтесь!\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Посторь мне.\n",
            "\n",
            "-\n",
            "Input sentence: Attack!\n",
            "Decoded sentence: Начинайся.\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Постань!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Постань!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Постань!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Постань!\n",
            "\n",
            "-\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: Постань!\n",
            "\n",
            "-\n",
            "Input sentence: Eat it.\n",
            "Decoded sentence: Постаньте это.\n",
            "\n",
            "-\n",
            "Input sentence: Eat up.\n",
            "Decoded sentence: Постанайся с дельно.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Посмотрите это.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Поставайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Поставайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Get up.\n",
            "Decoded sentence: Поставайте это.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Go now.\n",
            "Decoded sentence: Идите содать.\n",
            "\n",
            "-\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Начитесь.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Начни снай.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Начни снай.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Начни снай.\n",
            "\n",
            "-\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Начни снай.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neFr0UWC3AGI",
        "colab_type": "text"
      },
      "source": [
        "Но есть проблемы:\n",
        "- на длинных последовательностях результат будет не очень - быстро забывается контекст\n",
        "- хочется научить сеть смотреть в определенное место в прошлом при генерации\n",
        "\n",
        "attention\n",
        "\n",
        "<img src=\"images/Attention.png\"/>\n",
        "\n",
        "<img src=\"images/Attention2.png\"/>\n",
        "\n",
        "\n",
        "- h(t): скрытое состояние декодера\n",
        "- c(t): вектор контекста, который подается на вход\n",
        "- y(t): текущий таргет\n",
        "- $\\bar{h}(t)$: скрытое состояние attention\n",
        "- a(t): скор нормализации\n",
        "\n",
        "\n",
        "$$\\bar{h}(t)\\ =\\ tanh(W_c\\ [c_t,\\ h_t]) $$\n",
        "\n",
        "$$P(y_t|y_{<t},\\ x)\\ =\\ softmax(W_s\\ \\bar{h}_t) $$\n",
        "\n",
        "\n",
        "Зачем нужен скор нормализации? - пытаемся сравнить похожесть текущего скрытого состояния и скрытого состояния из прошлого и понять, на что обращать внимание\n",
        "\n",
        "\n",
        "$$a_t(s)\\ =\\ \\frac{exp(score(h_t,\\ \\bar{h}_s))}{\\sum_{i}\\ exp(score(h_t,\\ \\bar{h}_i)) }$$ \n",
        "\n",
        "\n",
        "<img src=\"images/scores.png\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUsUDocK3AGJ",
        "colab_type": "text"
      },
      "source": [
        "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GholUK0s3AGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "data_path = 'rus.txt'\n",
        "num_samples = 10000\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_sentence(input_text))\n",
        "    target_texts.append(preprocess_sentence(target_text))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkuGHPyp3AGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-0SOks13AGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_256ULSp3AGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp6FMJtv3AGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHoRywXg3AGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8fH_-Ir3AGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyNbZK993AGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fr2Y6xg3AGl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "38135ac9-eddf-4354-9e67-4b3742464fba"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.1009\n",
            "Epoch 2 Loss 0.0295\n",
            "Epoch 3 Loss 0.0244\n",
            "Epoch 4 Loss 0.0207\n",
            "Epoch 5 Loss 0.0197\n",
            "Epoch 6 Loss 0.0199\n",
            "Epoch 7 Loss 0.0183\n",
            "Epoch 8 Loss 0.0184\n",
            "Epoch 9 Loss 0.0157\n",
            "Epoch 10 Loss 0.0153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH7Nz8yx3AGo",
        "colab_type": "text"
      },
      "source": [
        "Некоторые украденные функции для оценки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mt3KQxO3AGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwv_1iuF3AGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "afada8c5-53df-4e89-dff1-73714ec51cb1"
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "translate(u'good morning')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Input: <start> good morning <end>\n",
            "Predicted translation: ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c884e860ca82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'good morning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted translation: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ticker' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk7kBHIY3AGw",
        "colab_type": "text"
      },
      "source": [
        "# Transformer\n",
        "\n",
        "<img src=\"images/transformer.png\"/>\n",
        "\n",
        "\n",
        "Идея в том, что каждое слово параллельно проходит через слои, изображенные на картинке.\n",
        "Некоторые из них — это стандартные fully-connected layers, некоторые — shortcut connections как в ResNet (там, где на картинке Add).\n",
        "\n",
        "\n",
        "Multi-head attention - это специальный новый слой, который дает возможность каждому входному вектору взаимодействовать с другими словами через attention mechanism, вместо передачи hidden state как в RNN или соседних слов как в CNN.\n",
        "\n",
        "\n",
        "<img src=\"images/mha.png\"/>\n",
        "\n",
        "\n",
        "<img src=\"images/AttTr.png\"/>\n",
        "\n",
        "\n",
        "Работа энкодера:\n",
        "\n",
        "\n",
        "Делаются эмбеддинги для всех слов предложения (вектора одинаковой размерности). Для примера пусть это будет предложение I am stupid. В эмбеддинг добавляется еще позиция слова в предложении.\n",
        "\n",
        "\n",
        "Берется вектор первого слова и вектор второго слова (I, am), подаются на однослойную сеть с одним выходом, которая выдает степень их похожести (скалярная величина). Эта скалярная величина умножается на вектор второго слова, получая его некоторую \"ослабленную\" на величину похожести копию.\n",
        "\n",
        "\n",
        "Вместо второго слова подается третье слово и делается тоже самое что в п.2. с той же самой сетью с теми же весами (для векторов I, stupid).\n",
        "\n",
        "\n",
        "Делая тоже самое для всех оставшихся слов предложения получаются их \"ослабленные\" (взвешенные) копии, которые выражают степень их похожести на первое слово. Далее эти все взвешенные вектора складываются друг с другом, получая один результирующий вектор размерности одного эмбединга:\n",
        "output=am * weight(I, am) + stupid * weight(I, stupid)\n",
        "\n",
        "\n",
        "Это механизм \"обычного\" attention.\n",
        "Так как оценка похожести слов всего одним способом (по одному критерию) считается недостаточной, тоже самое (п.2-4) повторяется несколько раз с другими весами. Типа одна один attention может определять похожесть слов по смысловой нагрузке, другой по грамматической, остальные еще как-то и т.п.\n",
        "\n",
        "\n",
        "На выходе п.5. получается несколько векторов, каждый из которых является взвешенной суммой всех остальных слов предложения относительно их похожести на первое слово (I). Конкантенируем этот вректор в один.\n",
        "\n",
        "\n",
        "Дальше ставится еще один слой линейного преобразования, уменьшающий размерность результата п.6. до размерности вектора одного эмбединга. Получается некое представление первого слова предложения, составленное из взвешенных векторов всех остальных слов предложения.\n",
        "\n",
        "\n",
        "Такой же процесс производится для всех других слов в предложении.\n",
        "\n",
        "\n",
        "Так как размерность выхода та же, то можно проделать все тоже самое еще раз (п.2-8), но вместо оригинальных эмбеддингов слов взять то, что получается после прохода через этот Multi-head attention, а нейросети аттеншенов внутри взять с другими весами (веса между слоями не общие). И таких слоев можно сделать много (у гугла 6). Однако между первым и вторым слоем добавляется еще полносвязный слой и residual соединения, чтобы добавить сети выразительности."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khovg6Sv3AGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHyM4r8f3AGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFlAgBZM3AG1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "    \n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "    \n",
        "    \n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUxwElN3AG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                 look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7qmbhSY3AG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                               input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                               target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDQ6uQ5x3AG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
        "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bSZqp973AHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlYbl53y3AHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "  \n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAlFqLGZ3AHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rqdA9lt3AHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2YROVTK3AHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "winYNlFS3AHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "  \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0DzzyMh3AHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8ea0b88-0fdc-4efe-edbc-bc3160afb403"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "for epoch in range(100):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.8839 Accuracy 0.3906\n",
            "Epoch 1 Batch 50 Loss 1.7537 Accuracy 0.2754\n",
            "Epoch 1 Batch 100 Loss 1.3880 Accuracy 0.2803\n",
            "Epoch 1 Loss 1.2481 Accuracy 0.3039\n",
            "Epoch 2 Batch 0 Loss 0.4078 Accuracy 0.4492\n",
            "Epoch 2 Batch 50 Loss 0.2955 Accuracy 0.4616\n",
            "Epoch 2 Batch 100 Loss 0.2302 Accuracy 0.4739\n",
            "Epoch 2 Loss 0.2108 Accuracy 0.4768\n",
            "Epoch 3 Batch 0 Loss 0.1993 Accuracy 0.4883\n",
            "Epoch 3 Batch 50 Loss 0.1253 Accuracy 0.4907\n",
            "Epoch 3 Batch 100 Loss 0.1199 Accuracy 0.4911\n",
            "Epoch 3 Loss 0.1199 Accuracy 0.4912\n",
            "Epoch 4 Batch 0 Loss 0.1473 Accuracy 0.4844\n",
            "Epoch 4 Batch 50 Loss 0.1105 Accuracy 0.4913\n",
            "Epoch 4 Batch 100 Loss 0.1068 Accuracy 0.4917\n",
            "Epoch 4 Loss 0.1016 Accuracy 0.4920\n",
            "Epoch 5 Batch 0 Loss 0.0374 Accuracy 0.4961\n",
            "Epoch 5 Batch 50 Loss 0.0875 Accuracy 0.4913\n",
            "Epoch 5 Batch 100 Loss 0.0852 Accuracy 0.4923\n",
            "Epoch 5 Loss 0.0883 Accuracy 0.4925\n",
            "Epoch 6 Batch 0 Loss 0.0178 Accuracy 0.5000\n",
            "Epoch 6 Batch 50 Loss 0.0761 Accuracy 0.4933\n",
            "Epoch 6 Batch 100 Loss 0.0796 Accuracy 0.4937\n",
            "Epoch 6 Loss 0.0758 Accuracy 0.4939\n",
            "Epoch 7 Batch 0 Loss 0.0466 Accuracy 0.4922\n",
            "Epoch 7 Batch 50 Loss 0.0705 Accuracy 0.4944\n",
            "Epoch 7 Batch 100 Loss 0.0717 Accuracy 0.4941\n",
            "Epoch 7 Loss 0.0693 Accuracy 0.4948\n",
            "Epoch 8 Batch 0 Loss 0.0499 Accuracy 0.5000\n",
            "Epoch 8 Batch 50 Loss 0.0625 Accuracy 0.4945\n",
            "Epoch 8 Batch 100 Loss 0.0636 Accuracy 0.4951\n",
            "Epoch 8 Loss 0.0622 Accuracy 0.4956\n",
            "Epoch 9 Batch 0 Loss 0.0155 Accuracy 0.5000\n",
            "Epoch 9 Batch 50 Loss 0.0592 Accuracy 0.4954\n",
            "Epoch 9 Batch 100 Loss 0.0606 Accuracy 0.4948\n",
            "Epoch 9 Loss 0.0611 Accuracy 0.4954\n",
            "Epoch 10 Batch 0 Loss 0.0205 Accuracy 0.4961\n",
            "Epoch 10 Batch 50 Loss 0.0573 Accuracy 0.4956\n",
            "Epoch 10 Batch 100 Loss 0.0594 Accuracy 0.4956\n",
            "Epoch 10 Loss 0.0574 Accuracy 0.4959\n",
            "Epoch 11 Batch 0 Loss 0.0998 Accuracy 0.4805\n",
            "Epoch 11 Batch 50 Loss 0.0528 Accuracy 0.4958\n",
            "Epoch 11 Batch 100 Loss 0.0555 Accuracy 0.4957\n",
            "Epoch 11 Loss 0.0533 Accuracy 0.4963\n",
            "Epoch 12 Batch 0 Loss 0.0530 Accuracy 0.4922\n",
            "Epoch 12 Batch 50 Loss 0.0422 Accuracy 0.4979\n",
            "Epoch 12 Batch 100 Loss 0.0479 Accuracy 0.4966\n",
            "Epoch 12 Loss 0.0519 Accuracy 0.4959\n",
            "Epoch 13 Batch 0 Loss 0.0428 Accuracy 0.4961\n",
            "Epoch 13 Batch 50 Loss 0.0480 Accuracy 0.4966\n",
            "Epoch 13 Batch 100 Loss 0.0478 Accuracy 0.4964\n",
            "Epoch 13 Loss 0.0489 Accuracy 0.4963\n",
            "Epoch 14 Batch 0 Loss 0.0139 Accuracy 0.5078\n",
            "Epoch 14 Batch 50 Loss 0.0544 Accuracy 0.4959\n",
            "Epoch 14 Batch 100 Loss 0.0495 Accuracy 0.4965\n",
            "Epoch 14 Loss 0.0497 Accuracy 0.4966\n",
            "Epoch 15 Batch 0 Loss 0.0602 Accuracy 0.4922\n",
            "Epoch 15 Batch 50 Loss 0.0446 Accuracy 0.4983\n",
            "Epoch 15 Batch 100 Loss 0.0478 Accuracy 0.4975\n",
            "Epoch 15 Loss 0.0485 Accuracy 0.4969\n",
            "Epoch 16 Batch 0 Loss 0.0038 Accuracy 0.5000\n",
            "Epoch 16 Batch 50 Loss 0.0512 Accuracy 0.4970\n",
            "Epoch 16 Batch 100 Loss 0.0473 Accuracy 0.4975\n",
            "Epoch 16 Loss 0.0476 Accuracy 0.4974\n",
            "Epoch 17 Batch 0 Loss 0.0076 Accuracy 0.5000\n",
            "Epoch 17 Batch 50 Loss 0.0548 Accuracy 0.4968\n",
            "Epoch 17 Batch 100 Loss 0.0484 Accuracy 0.4971\n",
            "Epoch 17 Loss 0.0482 Accuracy 0.4972\n",
            "Epoch 18 Batch 0 Loss 0.0332 Accuracy 0.5000\n",
            "Epoch 18 Batch 50 Loss 0.0464 Accuracy 0.4975\n",
            "Epoch 18 Batch 100 Loss 0.0467 Accuracy 0.4972\n",
            "Epoch 18 Loss 0.0475 Accuracy 0.4973\n",
            "Epoch 19 Batch 0 Loss 0.0235 Accuracy 0.5039\n",
            "Epoch 19 Batch 50 Loss 0.0487 Accuracy 0.4978\n",
            "Epoch 19 Batch 100 Loss 0.0497 Accuracy 0.4969\n",
            "Epoch 19 Loss 0.0504 Accuracy 0.4972\n",
            "Epoch 20 Batch 0 Loss 0.0222 Accuracy 0.5000\n",
            "Epoch 20 Batch 50 Loss 0.0508 Accuracy 0.4972\n",
            "Epoch 20 Batch 100 Loss 0.0502 Accuracy 0.4972\n",
            "Epoch 20 Loss 0.0483 Accuracy 0.4976\n",
            "Epoch 21 Batch 0 Loss 0.0420 Accuracy 0.5039\n",
            "Epoch 21 Batch 50 Loss 0.0457 Accuracy 0.4966\n",
            "Epoch 21 Batch 100 Loss 0.0453 Accuracy 0.4974\n",
            "Epoch 21 Loss 0.0487 Accuracy 0.4974\n",
            "Epoch 22 Batch 0 Loss 0.0189 Accuracy 0.5039\n",
            "Epoch 22 Batch 50 Loss 0.0403 Accuracy 0.4992\n",
            "Epoch 22 Batch 100 Loss 0.0552 Accuracy 0.4974\n",
            "Epoch 22 Loss 0.0555 Accuracy 0.4974\n",
            "Epoch 23 Batch 0 Loss 0.0045 Accuracy 0.5039\n",
            "Epoch 23 Batch 50 Loss 0.0506 Accuracy 0.4962\n",
            "Epoch 23 Batch 100 Loss 0.0559 Accuracy 0.4961\n",
            "Epoch 23 Loss 0.0540 Accuracy 0.4963\n",
            "Epoch 24 Batch 0 Loss 0.0345 Accuracy 0.5000\n",
            "Epoch 24 Batch 50 Loss 0.0506 Accuracy 0.4972\n",
            "Epoch 24 Batch 100 Loss 0.0470 Accuracy 0.4976\n",
            "Epoch 24 Loss 0.0462 Accuracy 0.4974\n",
            "Epoch 25 Batch 0 Loss 0.0701 Accuracy 0.4922\n",
            "Epoch 25 Batch 50 Loss 0.0440 Accuracy 0.4977\n",
            "Epoch 25 Batch 100 Loss 0.0465 Accuracy 0.4975\n",
            "Epoch 25 Loss 0.0466 Accuracy 0.4974\n",
            "Epoch 26 Batch 0 Loss 0.0316 Accuracy 0.4922\n",
            "Epoch 26 Batch 50 Loss 0.0489 Accuracy 0.4974\n",
            "Epoch 26 Batch 100 Loss 0.0550 Accuracy 0.4973\n",
            "Epoch 26 Loss 0.0568 Accuracy 0.4966\n",
            "Epoch 27 Batch 0 Loss 0.0321 Accuracy 0.4961\n",
            "Epoch 27 Batch 50 Loss 0.0591 Accuracy 0.4960\n",
            "Epoch 27 Batch 100 Loss 0.0528 Accuracy 0.4965\n",
            "Epoch 27 Loss 0.0527 Accuracy 0.4966\n",
            "Epoch 28 Batch 0 Loss 0.0109 Accuracy 0.5039\n",
            "Epoch 28 Batch 50 Loss 0.0312 Accuracy 0.4992\n",
            "Epoch 28 Batch 100 Loss 0.0481 Accuracy 0.4971\n",
            "Epoch 28 Loss 0.0568 Accuracy 0.4963\n",
            "Epoch 29 Batch 0 Loss 0.0362 Accuracy 0.4961\n",
            "Epoch 29 Batch 50 Loss 0.0824 Accuracy 0.4916\n",
            "Epoch 29 Batch 100 Loss 0.0662 Accuracy 0.4929\n",
            "Epoch 29 Loss 0.0703 Accuracy 0.4931\n",
            "Epoch 30 Batch 0 Loss 0.0234 Accuracy 0.5000\n",
            "Epoch 30 Batch 50 Loss 0.0494 Accuracy 0.4951\n",
            "Epoch 30 Batch 100 Loss 0.0604 Accuracy 0.4944\n",
            "Epoch 30 Loss 0.0643 Accuracy 0.4943\n",
            "Epoch 31 Batch 0 Loss 0.0651 Accuracy 0.4883\n",
            "Epoch 31 Batch 50 Loss 0.0762 Accuracy 0.4922\n",
            "Epoch 31 Batch 100 Loss 0.0675 Accuracy 0.4931\n",
            "Epoch 31 Loss 0.0669 Accuracy 0.4935\n",
            "Epoch 32 Batch 0 Loss 0.1114 Accuracy 0.4922\n",
            "Epoch 32 Batch 50 Loss 0.0738 Accuracy 0.4903\n",
            "Epoch 32 Batch 100 Loss 0.0771 Accuracy 0.4906\n",
            "Epoch 32 Loss 0.0790 Accuracy 0.4911\n",
            "Epoch 33 Batch 0 Loss 0.0819 Accuracy 0.4883\n",
            "Epoch 33 Batch 50 Loss 0.0781 Accuracy 0.4942\n",
            "Epoch 33 Batch 100 Loss 0.0802 Accuracy 0.4939\n",
            "Epoch 33 Loss 0.0818 Accuracy 0.4939\n",
            "Epoch 34 Batch 0 Loss 0.1278 Accuracy 0.4844\n",
            "Epoch 34 Batch 50 Loss 0.0972 Accuracy 0.4913\n",
            "Epoch 34 Batch 100 Loss 0.0777 Accuracy 0.4928\n",
            "Epoch 34 Loss 0.0761 Accuracy 0.4930\n",
            "Epoch 35 Batch 0 Loss 0.0191 Accuracy 0.5000\n",
            "Epoch 35 Batch 50 Loss 0.0492 Accuracy 0.4953\n",
            "Epoch 35 Batch 100 Loss 0.0586 Accuracy 0.4938\n",
            "Epoch 35 Loss 0.0601 Accuracy 0.4944\n",
            "Epoch 36 Batch 0 Loss 0.0517 Accuracy 0.5000\n",
            "Epoch 36 Batch 50 Loss 0.0635 Accuracy 0.4938\n",
            "Epoch 36 Batch 100 Loss 0.0733 Accuracy 0.4920\n",
            "Epoch 36 Loss 0.0706 Accuracy 0.4921\n",
            "Epoch 37 Batch 0 Loss 0.0628 Accuracy 0.4922\n",
            "Epoch 37 Batch 50 Loss 0.0689 Accuracy 0.4941\n",
            "Epoch 37 Batch 100 Loss 0.0653 Accuracy 0.4944\n",
            "Epoch 37 Loss 0.0694 Accuracy 0.4939\n",
            "Epoch 38 Batch 0 Loss 0.0461 Accuracy 0.4922\n",
            "Epoch 38 Batch 50 Loss 0.0521 Accuracy 0.4982\n",
            "Epoch 38 Batch 100 Loss 0.0516 Accuracy 0.4971\n",
            "Epoch 38 Loss 0.0517 Accuracy 0.4975\n",
            "Epoch 39 Batch 0 Loss 0.0413 Accuracy 0.4922\n",
            "Epoch 39 Batch 50 Loss 0.0610 Accuracy 0.4972\n",
            "Epoch 39 Batch 100 Loss 0.0609 Accuracy 0.4964\n",
            "Epoch 39 Loss 0.0596 Accuracy 0.4965\n",
            "Epoch 40 Batch 0 Loss 0.0230 Accuracy 0.4961\n",
            "Epoch 40 Batch 50 Loss 0.0615 Accuracy 0.4969\n",
            "Epoch 40 Batch 100 Loss 0.0546 Accuracy 0.4979\n",
            "Epoch 40 Loss 0.0572 Accuracy 0.4971\n",
            "Epoch 41 Batch 0 Loss 0.0356 Accuracy 0.4961\n",
            "Epoch 41 Batch 50 Loss 0.0607 Accuracy 0.4968\n",
            "Epoch 41 Batch 100 Loss 0.0604 Accuracy 0.4969\n",
            "Epoch 41 Loss 0.0612 Accuracy 0.4974\n",
            "Epoch 42 Batch 0 Loss 0.0672 Accuracy 0.4961\n",
            "Epoch 42 Batch 50 Loss 0.0624 Accuracy 0.4991\n",
            "Epoch 42 Batch 100 Loss 0.0618 Accuracy 0.4986\n",
            "Epoch 42 Loss 0.0623 Accuracy 0.4986\n",
            "Epoch 43 Batch 0 Loss 0.0839 Accuracy 0.5039\n",
            "Epoch 43 Batch 50 Loss 0.0688 Accuracy 0.4969\n",
            "Epoch 43 Batch 100 Loss 0.0793 Accuracy 0.4964\n",
            "Epoch 43 Loss 0.0788 Accuracy 0.4965\n",
            "Epoch 44 Batch 0 Loss 0.1095 Accuracy 0.4883\n",
            "Epoch 44 Batch 50 Loss 0.2150 Accuracy 0.4818\n",
            "Epoch 44 Batch 100 Loss 0.1424 Accuracy 0.4897\n",
            "Epoch 44 Loss 0.1249 Accuracy 0.4915\n",
            "Epoch 45 Batch 0 Loss 0.0741 Accuracy 0.5000\n",
            "Epoch 45 Batch 50 Loss 0.0621 Accuracy 0.4971\n",
            "Epoch 45 Batch 100 Loss 0.0543 Accuracy 0.4974\n",
            "Epoch 45 Loss 0.0564 Accuracy 0.4973\n",
            "Epoch 46 Batch 0 Loss 0.0118 Accuracy 0.5039\n",
            "Epoch 46 Batch 50 Loss 0.0523 Accuracy 0.4979\n",
            "Epoch 46 Batch 100 Loss 0.0468 Accuracy 0.4978\n",
            "Epoch 46 Loss 0.0470 Accuracy 0.4979\n",
            "Epoch 47 Batch 0 Loss 0.0859 Accuracy 0.4883\n",
            "Epoch 47 Batch 50 Loss 0.0450 Accuracy 0.4984\n",
            "Epoch 47 Batch 100 Loss 0.0430 Accuracy 0.4983\n",
            "Epoch 47 Loss 0.0446 Accuracy 0.4978\n",
            "Epoch 48 Batch 0 Loss 0.0242 Accuracy 0.5000\n",
            "Epoch 48 Batch 50 Loss 0.0397 Accuracy 0.4974\n",
            "Epoch 48 Batch 100 Loss 0.0436 Accuracy 0.4980\n",
            "Epoch 48 Loss 0.0436 Accuracy 0.4980\n",
            "Epoch 49 Batch 0 Loss 0.0903 Accuracy 0.4883\n",
            "Epoch 49 Batch 50 Loss 0.0391 Accuracy 0.4974\n",
            "Epoch 49 Batch 100 Loss 0.0403 Accuracy 0.4982\n",
            "Epoch 49 Loss 0.0431 Accuracy 0.4983\n",
            "Epoch 50 Batch 0 Loss 0.1067 Accuracy 0.4922\n",
            "Epoch 50 Batch 50 Loss 0.0417 Accuracy 0.4975\n",
            "Epoch 50 Batch 100 Loss 0.0426 Accuracy 0.4980\n",
            "Epoch 50 Loss 0.0402 Accuracy 0.4982\n",
            "Epoch 51 Batch 0 Loss 0.0071 Accuracy 0.5117\n",
            "Epoch 51 Batch 50 Loss 0.0440 Accuracy 0.4997\n",
            "Epoch 51 Batch 100 Loss 0.0477 Accuracy 0.4984\n",
            "Epoch 51 Loss 0.0628 Accuracy 0.4962\n",
            "Epoch 52 Batch 0 Loss 0.0711 Accuracy 0.5000\n",
            "Epoch 52 Batch 50 Loss 0.0461 Accuracy 0.4972\n",
            "Epoch 52 Batch 100 Loss 0.0539 Accuracy 0.4968\n",
            "Epoch 52 Loss 0.0544 Accuracy 0.4964\n",
            "Epoch 53 Batch 0 Loss 0.0957 Accuracy 0.4922\n",
            "Epoch 53 Batch 50 Loss 0.0598 Accuracy 0.4961\n",
            "Epoch 53 Batch 100 Loss 0.0566 Accuracy 0.4962\n",
            "Epoch 53 Loss 0.0545 Accuracy 0.4965\n",
            "Epoch 54 Batch 0 Loss 0.0290 Accuracy 0.5039\n",
            "Epoch 54 Batch 50 Loss 0.0384 Accuracy 0.4985\n",
            "Epoch 54 Batch 100 Loss 0.0415 Accuracy 0.4986\n",
            "Epoch 54 Loss 0.0407 Accuracy 0.4987\n",
            "Epoch 55 Batch 0 Loss 0.0507 Accuracy 0.5000\n",
            "Epoch 55 Batch 50 Loss 0.0410 Accuracy 0.4984\n",
            "Epoch 55 Batch 100 Loss 0.0395 Accuracy 0.4984\n",
            "Epoch 55 Loss 0.0407 Accuracy 0.4982\n",
            "Epoch 56 Batch 0 Loss 0.0168 Accuracy 0.5000\n",
            "Epoch 56 Batch 50 Loss 0.0422 Accuracy 0.4975\n",
            "Epoch 56 Batch 100 Loss 0.0491 Accuracy 0.4970\n",
            "Epoch 56 Loss 0.0483 Accuracy 0.4973\n",
            "Epoch 57 Batch 0 Loss 0.0341 Accuracy 0.4961\n",
            "Epoch 57 Batch 50 Loss 0.0395 Accuracy 0.4991\n",
            "Epoch 57 Batch 100 Loss 0.0392 Accuracy 0.4989\n",
            "Epoch 57 Loss 0.0411 Accuracy 0.4987\n",
            "Epoch 58 Batch 0 Loss 0.0181 Accuracy 0.5000\n",
            "Epoch 58 Batch 50 Loss 0.0401 Accuracy 0.4984\n",
            "Epoch 58 Batch 100 Loss 0.0393 Accuracy 0.4990\n",
            "Epoch 58 Loss 0.0374 Accuracy 0.4991\n",
            "Epoch 59 Batch 0 Loss 0.0137 Accuracy 0.5039\n",
            "Epoch 59 Batch 50 Loss 0.0320 Accuracy 0.5003\n",
            "Epoch 59 Batch 100 Loss 0.0388 Accuracy 0.4988\n",
            "Epoch 59 Loss 0.0387 Accuracy 0.4988\n",
            "Epoch 60 Batch 0 Loss 0.0117 Accuracy 0.5000\n",
            "Epoch 60 Batch 50 Loss 0.0369 Accuracy 0.4988\n",
            "Epoch 60 Batch 100 Loss 0.0404 Accuracy 0.4986\n",
            "Epoch 60 Loss 0.0410 Accuracy 0.4981\n",
            "Epoch 61 Batch 0 Loss 0.0797 Accuracy 0.4883\n",
            "Epoch 61 Batch 50 Loss 0.0340 Accuracy 0.4987\n",
            "Epoch 61 Batch 100 Loss 0.0391 Accuracy 0.4986\n",
            "Epoch 61 Loss 0.0379 Accuracy 0.4986\n",
            "Epoch 62 Batch 0 Loss 0.0687 Accuracy 0.5000\n",
            "Epoch 62 Batch 50 Loss 0.0375 Accuracy 0.4989\n",
            "Epoch 62 Batch 100 Loss 0.0359 Accuracy 0.4987\n",
            "Epoch 62 Loss 0.0358 Accuracy 0.4988\n",
            "Epoch 63 Batch 0 Loss 0.1069 Accuracy 0.4961\n",
            "Epoch 63 Batch 50 Loss 0.0391 Accuracy 0.4980\n",
            "Epoch 63 Batch 100 Loss 0.0366 Accuracy 0.4988\n",
            "Epoch 63 Loss 0.0350 Accuracy 0.4992\n",
            "Epoch 64 Batch 0 Loss 0.0216 Accuracy 0.4961\n",
            "Epoch 64 Batch 50 Loss 0.0311 Accuracy 0.4996\n",
            "Epoch 64 Batch 100 Loss 0.0335 Accuracy 0.4997\n",
            "Epoch 64 Loss 0.0337 Accuracy 0.4994\n",
            "Epoch 65 Batch 0 Loss 0.0447 Accuracy 0.4961\n",
            "Epoch 65 Batch 50 Loss 0.0339 Accuracy 0.4992\n",
            "Epoch 65 Batch 100 Loss 0.0354 Accuracy 0.4993\n",
            "Epoch 65 Loss 0.0340 Accuracy 0.4990\n",
            "Epoch 66 Batch 0 Loss 0.0234 Accuracy 0.4922\n",
            "Epoch 66 Batch 50 Loss 0.0331 Accuracy 0.4982\n",
            "Epoch 66 Batch 100 Loss 0.0646 Accuracy 0.4971\n",
            "Epoch 66 Loss 0.0589 Accuracy 0.4977\n",
            "Epoch 67 Batch 0 Loss 0.0224 Accuracy 0.5000\n",
            "Epoch 67 Batch 50 Loss 0.0251 Accuracy 0.5002\n",
            "Epoch 67 Batch 100 Loss 0.0327 Accuracy 0.4994\n",
            "Epoch 67 Loss 0.0326 Accuracy 0.4992\n",
            "Epoch 68 Batch 0 Loss 0.0364 Accuracy 0.4922\n",
            "Epoch 68 Batch 50 Loss 0.0304 Accuracy 0.4991\n",
            "Epoch 68 Batch 100 Loss 0.0338 Accuracy 0.4987\n",
            "Epoch 68 Loss 0.0331 Accuracy 0.4989\n",
            "Epoch 69 Batch 0 Loss 0.0104 Accuracy 0.4961\n",
            "Epoch 69 Batch 50 Loss 0.0296 Accuracy 0.5001\n",
            "Epoch 69 Batch 100 Loss 0.0337 Accuracy 0.4989\n",
            "Epoch 69 Loss 0.0337 Accuracy 0.4992\n",
            "Epoch 70 Batch 0 Loss 0.0120 Accuracy 0.4961\n",
            "Epoch 70 Batch 50 Loss 0.0301 Accuracy 0.4992\n",
            "Epoch 70 Batch 100 Loss 0.0343 Accuracy 0.4988\n",
            "Epoch 70 Loss 0.0367 Accuracy 0.4986\n",
            "Epoch 71 Batch 0 Loss 0.0195 Accuracy 0.4961\n",
            "Epoch 71 Batch 50 Loss 0.0405 Accuracy 0.4975\n",
            "Epoch 71 Batch 100 Loss 0.0421 Accuracy 0.4977\n",
            "Epoch 71 Loss 0.0420 Accuracy 0.4981\n",
            "Epoch 72 Batch 0 Loss 0.0565 Accuracy 0.4922\n",
            "Epoch 72 Batch 50 Loss 0.0312 Accuracy 0.4990\n",
            "Epoch 72 Batch 100 Loss 0.0324 Accuracy 0.4991\n",
            "Epoch 72 Loss 0.0330 Accuracy 0.4991\n",
            "Epoch 73 Batch 0 Loss 0.0569 Accuracy 0.5000\n",
            "Epoch 73 Batch 50 Loss 0.0276 Accuracy 0.5001\n",
            "Epoch 73 Batch 100 Loss 0.0321 Accuracy 0.4999\n",
            "Epoch 73 Loss 0.0333 Accuracy 0.4995\n",
            "Epoch 74 Batch 0 Loss 0.0367 Accuracy 0.4961\n",
            "Epoch 74 Batch 50 Loss 0.0346 Accuracy 0.4989\n",
            "Epoch 74 Batch 100 Loss 0.0340 Accuracy 0.4992\n",
            "Epoch 74 Loss 0.0353 Accuracy 0.4994\n",
            "Epoch 75 Batch 0 Loss 0.0101 Accuracy 0.5000\n",
            "Epoch 75 Batch 50 Loss 0.0350 Accuracy 0.4985\n",
            "Epoch 75 Batch 100 Loss 0.0351 Accuracy 0.4986\n",
            "Epoch 75 Loss 0.0348 Accuracy 0.4988\n",
            "Epoch 76 Batch 0 Loss 0.0194 Accuracy 0.5000\n",
            "Epoch 76 Batch 50 Loss 0.0326 Accuracy 0.4989\n",
            "Epoch 76 Batch 100 Loss 0.0337 Accuracy 0.4985\n",
            "Epoch 76 Loss 0.0352 Accuracy 0.4987\n",
            "Epoch 77 Batch 0 Loss 0.0087 Accuracy 0.5039\n",
            "Epoch 77 Batch 50 Loss 0.0435 Accuracy 0.4979\n",
            "Epoch 77 Batch 100 Loss 0.0427 Accuracy 0.4982\n",
            "Epoch 77 Loss 0.0410 Accuracy 0.4982\n",
            "Epoch 78 Batch 0 Loss 0.0086 Accuracy 0.5000\n",
            "Epoch 78 Batch 50 Loss 0.0323 Accuracy 0.4990\n",
            "Epoch 78 Batch 100 Loss 0.0340 Accuracy 0.4992\n",
            "Epoch 78 Loss 0.0341 Accuracy 0.4990\n",
            "Epoch 79 Batch 0 Loss 0.0415 Accuracy 0.5039\n",
            "Epoch 79 Batch 50 Loss 0.0356 Accuracy 0.4994\n",
            "Epoch 79 Batch 100 Loss 0.0369 Accuracy 0.4988\n",
            "Epoch 79 Loss 0.0371 Accuracy 0.4988\n",
            "Epoch 80 Batch 0 Loss 0.0866 Accuracy 0.4961\n",
            "Epoch 80 Batch 50 Loss 0.0356 Accuracy 0.5002\n",
            "Epoch 80 Batch 100 Loss 0.0332 Accuracy 0.4993\n",
            "Epoch 80 Loss 0.0346 Accuracy 0.4991\n",
            "Epoch 81 Batch 0 Loss 0.0546 Accuracy 0.4883\n",
            "Epoch 81 Batch 50 Loss 0.0370 Accuracy 0.4975\n",
            "Epoch 81 Batch 100 Loss 0.0315 Accuracy 0.4990\n",
            "Epoch 81 Loss 0.0304 Accuracy 0.4992\n",
            "Epoch 82 Batch 0 Loss 0.0106 Accuracy 0.5000\n",
            "Epoch 82 Batch 50 Loss 0.0557 Accuracy 0.4937\n",
            "Epoch 82 Batch 100 Loss 0.0506 Accuracy 0.4950\n",
            "Epoch 82 Loss 0.0499 Accuracy 0.4950\n",
            "Epoch 83 Batch 0 Loss 0.0244 Accuracy 0.4961\n",
            "Epoch 83 Batch 50 Loss 0.0371 Accuracy 0.4989\n",
            "Epoch 83 Batch 100 Loss 0.0289 Accuracy 0.4998\n",
            "Epoch 83 Loss 0.0333 Accuracy 0.4991\n",
            "Epoch 84 Batch 0 Loss 0.0047 Accuracy 0.5039\n",
            "Epoch 84 Batch 50 Loss 0.0300 Accuracy 0.4990\n",
            "Epoch 84 Batch 100 Loss 0.0306 Accuracy 0.4985\n",
            "Epoch 84 Loss 0.0323 Accuracy 0.4987\n",
            "Epoch 85 Batch 0 Loss 0.0307 Accuracy 0.5156\n",
            "Epoch 85 Batch 50 Loss 0.0285 Accuracy 0.4998\n",
            "Epoch 85 Batch 100 Loss 0.0306 Accuracy 0.5001\n",
            "Epoch 85 Loss 0.0291 Accuracy 0.4999\n",
            "Epoch 86 Batch 0 Loss 0.0034 Accuracy 0.5000\n",
            "Epoch 86 Batch 50 Loss 0.0294 Accuracy 0.5002\n",
            "Epoch 86 Batch 100 Loss 0.0312 Accuracy 0.4996\n",
            "Epoch 86 Loss 0.0303 Accuracy 0.4995\n",
            "Epoch 87 Batch 0 Loss 0.0034 Accuracy 0.5000\n",
            "Epoch 87 Batch 50 Loss 0.0258 Accuracy 0.4994\n",
            "Epoch 87 Batch 100 Loss 0.0304 Accuracy 0.4991\n",
            "Epoch 87 Loss 0.0307 Accuracy 0.4993\n",
            "Epoch 88 Batch 0 Loss 0.0034 Accuracy 0.5117\n",
            "Epoch 88 Batch 50 Loss 0.0305 Accuracy 0.4993\n",
            "Epoch 88 Batch 100 Loss 0.0276 Accuracy 0.4997\n",
            "Epoch 88 Loss 0.0291 Accuracy 0.4994\n",
            "Epoch 89 Batch 0 Loss 0.0093 Accuracy 0.4961\n",
            "Epoch 89 Batch 50 Loss 0.0257 Accuracy 0.4989\n",
            "Epoch 89 Batch 100 Loss 0.0301 Accuracy 0.4991\n",
            "Epoch 89 Loss 0.0328 Accuracy 0.4992\n",
            "Epoch 90 Batch 0 Loss 0.0341 Accuracy 0.4961\n",
            "Epoch 90 Batch 50 Loss 0.0323 Accuracy 0.4993\n",
            "Epoch 90 Batch 100 Loss 0.0305 Accuracy 0.4992\n",
            "Epoch 90 Loss 0.0317 Accuracy 0.4995\n",
            "Epoch 91 Batch 0 Loss 0.0267 Accuracy 0.5039\n",
            "Epoch 91 Batch 50 Loss 0.0324 Accuracy 0.4989\n",
            "Epoch 91 Batch 100 Loss 0.0305 Accuracy 0.4991\n",
            "Epoch 91 Loss 0.0307 Accuracy 0.4993\n",
            "Epoch 92 Batch 0 Loss 0.0421 Accuracy 0.5000\n",
            "Epoch 92 Batch 50 Loss 0.1046 Accuracy 0.4887\n",
            "Epoch 92 Batch 100 Loss 0.1176 Accuracy 0.4818\n",
            "Epoch 92 Loss 0.1167 Accuracy 0.4812\n",
            "Epoch 93 Batch 0 Loss 0.1197 Accuracy 0.4766\n",
            "Epoch 93 Batch 50 Loss 0.1041 Accuracy 0.4766\n",
            "Epoch 93 Batch 100 Loss 0.1021 Accuracy 0.4781\n",
            "Epoch 93 Loss 0.0955 Accuracy 0.4809\n",
            "Epoch 94 Batch 0 Loss 0.0482 Accuracy 0.4922\n",
            "Epoch 94 Batch 50 Loss 0.0596 Accuracy 0.4943\n",
            "Epoch 94 Batch 100 Loss 0.0509 Accuracy 0.4954\n",
            "Epoch 94 Loss 0.0503 Accuracy 0.4952\n",
            "Epoch 95 Batch 0 Loss 0.0141 Accuracy 0.5000\n",
            "Epoch 95 Batch 50 Loss 0.0427 Accuracy 0.4962\n",
            "Epoch 95 Batch 100 Loss 0.0438 Accuracy 0.4958\n",
            "Epoch 95 Loss 0.0465 Accuracy 0.4953\n",
            "Epoch 96 Batch 0 Loss 0.0365 Accuracy 0.4922\n",
            "Epoch 96 Batch 50 Loss 0.0447 Accuracy 0.4956\n",
            "Epoch 96 Batch 100 Loss 0.0455 Accuracy 0.4951\n",
            "Epoch 96 Loss 0.0486 Accuracy 0.4951\n",
            "Epoch 97 Batch 0 Loss 0.0289 Accuracy 0.5000\n",
            "Epoch 97 Batch 50 Loss 0.0389 Accuracy 0.4965\n",
            "Epoch 97 Batch 100 Loss 0.0477 Accuracy 0.4955\n",
            "Epoch 97 Loss 0.0477 Accuracy 0.4952\n",
            "Epoch 98 Batch 0 Loss 0.0816 Accuracy 0.4922\n",
            "Epoch 98 Batch 50 Loss 0.0416 Accuracy 0.4956\n",
            "Epoch 98 Batch 100 Loss 0.0426 Accuracy 0.4959\n",
            "Epoch 98 Loss 0.0448 Accuracy 0.4955\n",
            "Epoch 99 Batch 0 Loss 0.0103 Accuracy 0.5000\n",
            "Epoch 99 Batch 50 Loss 0.0490 Accuracy 0.4952\n",
            "Epoch 99 Batch 100 Loss 0.0460 Accuracy 0.4947\n",
            "Epoch 99 Loss 0.0447 Accuracy 0.4950\n",
            "Epoch 100 Batch 0 Loss 0.1314 Accuracy 0.4922\n",
            "Epoch 100 Batch 50 Loss 0.0505 Accuracy 0.4952\n",
            "Epoch 100 Batch 100 Loss 0.0459 Accuracy 0.4956\n",
            "Epoch 100 Loss 0.0450 Accuracy 0.4956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RezbNph03AHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40bfd37c-3810-4be7-80e4-67f5e9b342c0"
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "    start_token = [1]\n",
        "    end_token = [2]\n",
        "  \n",
        "    sentence = preprocess_sentence(inp_sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    \n",
        "    encoder_input = tf.expand_dims(inputs, 0)\n",
        "  \n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "    decoder_input = [1]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(max_length_targ):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "\n",
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "    sentence = inp_lang_tokenizer.encode(sentence)\n",
        "  \n",
        "    attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "        # plot the attention weights\n",
        "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "        fontdict = {'fontsize': 10}\n",
        "\n",
        "        ax.set_xticks(range(len(sentence)+2))\n",
        "        ax.set_yticks(range(len(result)))\n",
        "\n",
        "        ax.set_ylim(len(result)-1.5, -0.5)\n",
        "\n",
        "        ax.set_xticklabels(\n",
        "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "            fontdict=fontdict, rotation=90)\n",
        "\n",
        "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                            if i < tokenizer_en.vocab_size], \n",
        "                           fontdict=fontdict)\n",
        "\n",
        "        ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def translate(sentence, plot=''):\n",
        "    result, attention_weights = evaluate(sentence)\n",
        "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "    if plot:\n",
        "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
        "        \n",
        "translate(\"good morning.\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: good morning.\n",
            "Predicted translation: ['<start>', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}