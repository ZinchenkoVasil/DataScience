{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwAdrrlks_ZJ"
   },
   "source": [
    "# ДЗ Text classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eHK0K1Lw6nb"
   },
   "source": [
    "## Задача (Sentiment Analysis)\n",
    "\n",
    "Собраны твиты 2-ух тональностей, необходимо произвести классификацию на 2-а класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H5tFUEMCE7d"
   },
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 40\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUCk-5M2yg3S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('/train.csv')\n",
    "df_test = pd.read_csv(\"/test.csv\")\n",
    "df_val = pd.read_csv(\"/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "KBSf-OfDzWOI",
    "outputId": "1b397fc7-a4f8-4900-8fad-5db7a4903228"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "LuZtq9cwIvMt",
    "outputId": "76cc3088-87c8-41cb-fb55-06070b156e01"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204150</td>\n",
       "      <td>Тектоника и рельеф-самое ужасное в мире мучение(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204151</td>\n",
       "      <td>Ходили запускать шар желаний, но у нас не полу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204152</td>\n",
       "      <td>Хочу лето только ради того, что бы направить н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204153</td>\n",
       "      <td>RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204154</td>\n",
       "      <td>RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  204150   Тектоника и рельеф-самое ужасное в мире мучение(\n",
       "1  204151  Ходили запускать шар желаний, но у нас не полу...\n",
       "2  204152  Хочу лето только ради того, что бы направить н...\n",
       "3  204153  RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...\n",
       "4  204154  RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_9l0iHhaI0O1",
    "outputId": "4bc680a0-f3e3-4966-c63e-a656c925bff8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEyvOxoOJDTP"
   },
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "g-T3oo4v-dou",
    "outputId": "efeb7303-9fc3-4b51-dee3-458e67b8d714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
      "Building wheels for collected packages: stop-words\n",
      "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32917 sha256=4cfd13acb341a58b39a153d90ad2a1c8460b0cfcf82c10639ad5a2fd9706e061\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2018.7.23\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "5sOGAKBZ-doy",
    "outputId": "35575da2-07c2-4536-c149-a11a2624c0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\r",
      "\u001b[K     |███████                         | 10kB 22.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
      "Collecting pymorphy2-dicts<3.0,>=2.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1MB 6.4MB/s \n",
      "\u001b[?25hCollecting dawg-python>=0.7\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W97hWg3h-do1"
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJY7K7eS-do3"
   },
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4o9QgmWI3Pw"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"text\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Hed2ySbwJH6B",
    "outputId": "c9401ccb-d25e-49aa-aa10-d057a0a278e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJ8T0fwYJYJX"
   },
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXOLVK1tJLT8"
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qCQH5nIJoiB"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bRQ-6wwjJrGo",
    "outputId": "3538a24a-24c2-4e80-9700-e9a2611e475d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['вообще',\n",
       " 'думать',\n",
       " 'идти',\n",
       " 'иня',\n",
       " 'блин',\n",
       " 'самый',\n",
       " 'сидеть',\n",
       " 'спать',\n",
       " 'дом',\n",
       " '3',\n",
       " 'друг',\n",
       " 'писать',\n",
       " 'сделать',\n",
       " 'утро',\n",
       " 'школа',\n",
       " '2',\n",
       " 'ждать',\n",
       " 'настроение',\n",
       " 'мама',\n",
       " 'ахи',\n",
       " 'пойти',\n",
       " 'любимый',\n",
       " 'хотеться',\n",
       " 'болеть',\n",
       " 'написать',\n",
       " 'видеть',\n",
       " 'работа',\n",
       " 'свой',\n",
       " 'последний',\n",
       " 'посмотреть',\n",
       " 'добрый',\n",
       " 'найти',\n",
       " 'ночь',\n",
       " 'понять',\n",
       " 'купить',\n",
       " 'понимать',\n",
       " 'нравиться',\n",
       " 'чтоть',\n",
       " 'скучать',\n",
       " 'скоро',\n",
       " 'дать',\n",
       " 'час',\n",
       " 'вчера',\n",
       " 'давать',\n",
       " 'читать',\n",
       " 'стать',\n",
       " 'дело',\n",
       " 'остаться',\n",
       " 'забыть',\n",
       " 'говорить',\n",
       " 'работать',\n",
       " 'плохо',\n",
       " 'фильм',\n",
       " 'урок',\n",
       " 'оо',\n",
       " 'жить',\n",
       " 'ничегон',\n",
       " 'вечер',\n",
       " 'снег',\n",
       " 'ходить',\n",
       " 'домой',\n",
       " 'пара',\n",
       " 'сон',\n",
       " 'нормальный',\n",
       " '5',\n",
       " 'нужный',\n",
       " 'начать',\n",
       " 'нг',\n",
       " 'телефон',\n",
       " 'надеяться',\n",
       " 'жаль',\n",
       " '4',\n",
       " 'бля',\n",
       " 'правда',\n",
       " 'улица',\n",
       " 'увидеть',\n",
       " 'ахахи',\n",
       " 'слово',\n",
       " 'твиттереть',\n",
       " 'изз',\n",
       " 'вроде',\n",
       " 'равно',\n",
       " 'новогодний',\n",
       " 'помнить',\n",
       " 'рука',\n",
       " 'большой',\n",
       " 'дажена',\n",
       " 'минута',\n",
       " 'твит',\n",
       " 'место',\n",
       " 'фотка',\n",
       " 'ехать',\n",
       " '1',\n",
       " 'рождение',\n",
       " 'играть',\n",
       " 'половина',\n",
       " 'прийти',\n",
       " 'приехать',\n",
       " '10',\n",
       " 'привет',\n",
       " 'решить',\n",
       " 'голова',\n",
       " 'круто',\n",
       " 'девушка',\n",
       " 'днём',\n",
       " 'парень',\n",
       " 'х',\n",
       " 'выйти',\n",
       " 'сразу',\n",
       " 'этоня',\n",
       " 'никтоня',\n",
       " 'новое',\n",
       " 'подарок',\n",
       " 'взять',\n",
       " 'выходной',\n",
       " 'мнить',\n",
       " 'вопрос',\n",
       " 'смочь',\n",
       " 'кстати',\n",
       " 'никогдать',\n",
       " 'прийтись',\n",
       " 'бояться',\n",
       " 'должный',\n",
       " 'класс',\n",
       " 'слушать',\n",
       " 'лента',\n",
       " 'понравиться',\n",
       " 'чувствовать',\n",
       " 'глаз',\n",
       " 'конец',\n",
       " 'папа',\n",
       " 'столько',\n",
       " 'пришлый',\n",
       " 'город',\n",
       " 'сильно',\n",
       " 'ребёнок',\n",
       " 'чтоня',\n",
       " 'крутой',\n",
       " 'бог',\n",
       " 'ладный',\n",
       " 'еда',\n",
       " 'прям',\n",
       " 'естить',\n",
       " 'точно',\n",
       " 'пройти',\n",
       " 'русский',\n",
       " 'момент',\n",
       " 'любовь',\n",
       " 'блять',\n",
       " 'месяц',\n",
       " 'зима',\n",
       " 'уйти',\n",
       " 'красивый',\n",
       " 'деньга',\n",
       " 'простить',\n",
       " 'маленький',\n",
       " 'наверное',\n",
       " 'меняня',\n",
       " 'главный',\n",
       " 'часы',\n",
       " 'че',\n",
       " 'получиться',\n",
       " 'получить',\n",
       " 'успеть',\n",
       " 'интересно',\n",
       " 'экзамен',\n",
       " 'душить',\n",
       " 'закончиться',\n",
       " 'нога',\n",
       " 'девочка',\n",
       " 'узнать',\n",
       " 'проснуться',\n",
       " 'жалко',\n",
       " 'норма',\n",
       " 'отличный',\n",
       " 'серия',\n",
       " 'ёлка',\n",
       " 'пиздец',\n",
       " 'учить',\n",
       " 'тын',\n",
       " 'щас',\n",
       " 'праздник',\n",
       " 'стоить',\n",
       " 'поставить',\n",
       " 'вк',\n",
       " 'поехать',\n",
       " 'история',\n",
       " 'приятно',\n",
       " 'музыка',\n",
       " 'сходить',\n",
       " 'мир',\n",
       " 'ребята',\n",
       " 'ктоть',\n",
       " 'счастие',\n",
       " 'начинать',\n",
       " 'нона',\n",
       " 'такно',\n",
       " 'вспомнить',\n",
       " 'песня',\n",
       " 'россия',\n",
       " 'гулять',\n",
       " '8',\n",
       " 'удить',\n",
       " 'както',\n",
       " 'ужасно',\n",
       " 'плохой',\n",
       " 'игра',\n",
       " 'обидный',\n",
       " 'ана',\n",
       " 'фото',\n",
       " 'жена',\n",
       " 'чувство',\n",
       " 'скучно',\n",
       " 'пить',\n",
       " 'хватать',\n",
       " 'интересный',\n",
       " 'каникулы',\n",
       " 'офигенный',\n",
       " 'вместе',\n",
       " 'подруга',\n",
       " 'dd',\n",
       " 'проблема',\n",
       " 'заболеть',\n",
       " 'никто',\n",
       " 'ибо',\n",
       " 'помочь',\n",
       " 'учиться',\n",
       " 'милый',\n",
       " 'прекрасный',\n",
       " 'устать',\n",
       " 'вообщить',\n",
       " '6',\n",
       " 'холодный',\n",
       " 'классный',\n",
       " 'погода',\n",
       " 'верить',\n",
       " 'умереть',\n",
       " 'пусть',\n",
       " 'эх',\n",
       " 'интернет',\n",
       " 'полный',\n",
       " 'таки',\n",
       " 'ага',\n",
       " 'машина',\n",
       " 'дорогой',\n",
       " 'ой',\n",
       " 'счастливый',\n",
       " 'группа',\n",
       " 'пошлый',\n",
       " 'боль',\n",
       " 'быстро',\n",
       " 'желание',\n",
       " 'видео',\n",
       " 'собираться',\n",
       " 'тип',\n",
       " 'пятница',\n",
       " 'сдать',\n",
       " 'начаться',\n",
       " 'зачёт',\n",
       " 'плакать',\n",
       " 'поход',\n",
       " 'утром',\n",
       " 'новость',\n",
       " 'отлично',\n",
       " 'подарить',\n",
       " 'сезон',\n",
       " 'приходить',\n",
       " 'концерт',\n",
       " 'встать',\n",
       " '7',\n",
       " 'зайти',\n",
       " 'брат',\n",
       " 'целый',\n",
       " 'ужасный',\n",
       " 'понедельник',\n",
       " 'москва',\n",
       " 'мысль',\n",
       " 'план',\n",
       " 'знаешь',\n",
       " 'вставать',\n",
       " 'родитель',\n",
       " 'лицо',\n",
       " 'голос',\n",
       " 'сериал',\n",
       " 'книга',\n",
       " 'учёба',\n",
       " 'грустно',\n",
       " 'выходить',\n",
       " '9',\n",
       " 'бесить',\n",
       " 'б',\n",
       " 'магазин',\n",
       " 'скорее',\n",
       " 'капец',\n",
       " 'кот',\n",
       " 'пытаться',\n",
       " 'говорят',\n",
       " 'удача',\n",
       " 'тема',\n",
       " 'весело',\n",
       " 'получаться',\n",
       " 'подумать',\n",
       " 'др',\n",
       " 'окно',\n",
       " 'поэтому',\n",
       " 'лень',\n",
       " 'готовый',\n",
       " 'убить',\n",
       " 'искать',\n",
       " 'обожать',\n",
       " 'сука',\n",
       " 'выспаться',\n",
       " 'быня',\n",
       " 'вернуться',\n",
       " 'реально',\n",
       " 'євромайдан',\n",
       " 'приятный',\n",
       " 'брать',\n",
       " 'суббота',\n",
       " 'уехать',\n",
       " 'ох',\n",
       " 'поздравлять',\n",
       " '15',\n",
       " 'з',\n",
       " 'больсить',\n",
       " 'следующий',\n",
       " 'заходить',\n",
       " 'число',\n",
       " 'хватить',\n",
       " 'жопа',\n",
       " 'никакой',\n",
       " 'мороз',\n",
       " 'чувак',\n",
       " 'рада',\n",
       " 'какойтый',\n",
       " 'провести',\n",
       " 'декабрь',\n",
       " 'сердце',\n",
       " 'первое',\n",
       " 'мальчик',\n",
       " '20',\n",
       " 'страшно',\n",
       " 'попасть',\n",
       " 'ужас',\n",
       " 'рассказать',\n",
       " 'oo',\n",
       " 'свет',\n",
       " 'худой',\n",
       " 'уния',\n",
       " 'соскучиться',\n",
       " 'потерять',\n",
       " 'люба',\n",
       " 'позвонить',\n",
       " 'считать',\n",
       " 'слышать',\n",
       " 'общаться',\n",
       " 'молодец',\n",
       " 'женщина',\n",
       " 'чаять',\n",
       " 'сессия',\n",
       " 'мужик',\n",
       " 'тупой',\n",
       " 'короче',\n",
       " 'гол',\n",
       " 'английский',\n",
       " '30',\n",
       " 'ааа',\n",
       " 'аж',\n",
       " 'весёлый',\n",
       " 'звонить',\n",
       " 'часть',\n",
       " 'черта',\n",
       " 'бабушка',\n",
       " 'тви',\n",
       " 'спокойный',\n",
       " 'больно',\n",
       " 'заметить',\n",
       " 'сила',\n",
       " 'литр',\n",
       " 'уходить',\n",
       " 'страна',\n",
       " 'оказываться',\n",
       " 'уснуть',\n",
       " 'куча',\n",
       " 'лечь',\n",
       " 'билет',\n",
       " 'всякий',\n",
       " 'видимо',\n",
       " 'комп',\n",
       " 'правильно',\n",
       " 'хд',\n",
       " 'радовать',\n",
       " 'хах',\n",
       " 'мужчина',\n",
       " 'лежать',\n",
       " 'желать',\n",
       " 'наконецтый',\n",
       " 'лето',\n",
       " 'старый',\n",
       " 'скорый',\n",
       " 'вместо',\n",
       " 'детство',\n",
       " '12',\n",
       " 'надоесть',\n",
       " 'песнь',\n",
       " 'слеза',\n",
       " 'вечером',\n",
       " 'послать',\n",
       " 'стоять',\n",
       " 'сайт',\n",
       " 'похоже',\n",
       " 'прочитать',\n",
       " 'петь',\n",
       " 'волос',\n",
       " 'отвечать',\n",
       " 'чо',\n",
       " 'появиться',\n",
       " 'ставить',\n",
       " 'картинка',\n",
       " 'ночью',\n",
       " 'физик',\n",
       " 'инуть',\n",
       " 'печаль',\n",
       " 'менянета',\n",
       " 'сторона',\n",
       " 'тоня',\n",
       " 'кино',\n",
       " 'дорога',\n",
       " 'пропустить',\n",
       " 'оказаться',\n",
       " 'перестать',\n",
       " 'вид',\n",
       " 'ахахахи',\n",
       " 'кофе',\n",
       " 'готовиться',\n",
       " 'народ',\n",
       " 'общий',\n",
       " 'наверно',\n",
       " 'смысл',\n",
       " 'постоянно',\n",
       " 'танец',\n",
       " 'сниться',\n",
       " 'быстрый',\n",
       " 'ответить',\n",
       " 'чёрный',\n",
       " 'просить',\n",
       " 'придумать',\n",
       " 'погулять',\n",
       " 'квартира',\n",
       " 'случай',\n",
       " 'добро',\n",
       " 'показать',\n",
       " 'январь',\n",
       " 'упасть',\n",
       " 'честно',\n",
       " 'совсемень',\n",
       " 'единственный',\n",
       " 'похожий',\n",
       " 'обещать',\n",
       " 'прошлый',\n",
       " 'право',\n",
       " 'звать',\n",
       " 'спасть',\n",
       " 'температура',\n",
       " 'сестра',\n",
       " 'ddd',\n",
       " 'кинуть',\n",
       " 'бедный',\n",
       " 'лох',\n",
       " 'каток',\n",
       " 'больница',\n",
       " 'родной',\n",
       " 'мечта',\n",
       " 'забрать',\n",
       " 'бегать',\n",
       " 'разный',\n",
       " 'семья',\n",
       " 'радость',\n",
       " 'спросить',\n",
       " 'настоящий',\n",
       " 'номер',\n",
       " 'говно',\n",
       " 'огромный',\n",
       " 'ответ',\n",
       " 'автобус',\n",
       " 'заниматься',\n",
       " 'комната',\n",
       " 'онный',\n",
       " 'знакомый',\n",
       " 'вспоминать',\n",
       " 'готовить',\n",
       " 'письмо',\n",
       " 'ок',\n",
       " 'замечательный',\n",
       " 'покупать',\n",
       " 'страшный',\n",
       " 'ура',\n",
       " 'печально',\n",
       " 'сный',\n",
       " 'остальной',\n",
       " 'настя',\n",
       " 'дождь',\n",
       " 'оставаться',\n",
       " 'прислать',\n",
       " 'гость',\n",
       " 'даа',\n",
       " 'смешно',\n",
       " 'страница',\n",
       " '11',\n",
       " 'странный',\n",
       " 'простон',\n",
       " 'либо',\n",
       " 'вещий',\n",
       " 'попробовать',\n",
       " 'становиться',\n",
       " 'сообщение',\n",
       " 'испортить',\n",
       " 'a',\n",
       " 'поговорить',\n",
       " 'ощущение',\n",
       " 'вод',\n",
       " 'вернуть',\n",
       " 'одноклассник',\n",
       " 'идиот',\n",
       " 'контрольный',\n",
       " 'курс',\n",
       " 'представлять',\n",
       " 'химия',\n",
       " 'супер',\n",
       " 'обратно',\n",
       " 'ретвит',\n",
       " 'никакно',\n",
       " 'открыть',\n",
       " 'итог',\n",
       " 'обязательно',\n",
       " 'безумно',\n",
       " 'встретить',\n",
       " 'простой',\n",
       " 'начинаться',\n",
       " 'мыть',\n",
       " 'сладкое',\n",
       " 'тренировка',\n",
       " 'происходить',\n",
       " 'майдан',\n",
       " 'нос',\n",
       " 'ездить',\n",
       " 'кушать',\n",
       " 'сдавать',\n",
       " 'фигня',\n",
       " 'фотография',\n",
       " 'тебян',\n",
       " 'собака',\n",
       " 'помощь',\n",
       " 'зря',\n",
       " 'рабочий',\n",
       " 'тожена',\n",
       " 'встреча',\n",
       " 'достать',\n",
       " 'вкусный',\n",
       " 'показывать',\n",
       " 'прямо',\n",
       " 'шок',\n",
       " 'называть',\n",
       " 'съесть',\n",
       " 'встретиться',\n",
       " 'уезжать',\n",
       " 'состояние',\n",
       " 'случиться',\n",
       " 'понятно',\n",
       " 'вести',\n",
       " 'проходить',\n",
       " 'прикольный',\n",
       " 'везти',\n",
       " 'странно',\n",
       " 'мозг',\n",
       " 'лола',\n",
       " 'оставить',\n",
       " 'смеяться',\n",
       " 'разговаривать',\n",
       " 'жрать',\n",
       " 'живой',\n",
       " '100',\n",
       " 'сесть',\n",
       " 'сегодняшний',\n",
       " 'рубль',\n",
       " 'сильный',\n",
       " 'шикарный',\n",
       " 'нуна',\n",
       " 'рад',\n",
       " 'мын',\n",
       " 'пост',\n",
       " 'ум',\n",
       " 'поздравить',\n",
       " 'алгебра',\n",
       " 'повод',\n",
       " '13',\n",
       " 'саша',\n",
       " 'украина',\n",
       " 'воскресение',\n",
       " 'тёплый',\n",
       " 'приезжать',\n",
       " 'скинуть',\n",
       " 'прошлое',\n",
       " 'нахуй',\n",
       " 'толькон',\n",
       " 'сложно',\n",
       " 'проспать',\n",
       " 'отправить',\n",
       " 'помогать',\n",
       " 'идея',\n",
       " 'хуй',\n",
       " 'красный',\n",
       " 'язык',\n",
       " 'муж',\n",
       " 'стол',\n",
       " 'спрашивать',\n",
       " 'отношение',\n",
       " 'очередной',\n",
       " 'настолько',\n",
       " 'классно',\n",
       " 'тяжёлый',\n",
       " 'горло',\n",
       " 'стыдно',\n",
       " 'ложиться',\n",
       " 'кровать',\n",
       " 'универ',\n",
       " 'метро',\n",
       " 'lt3',\n",
       " 'пробка',\n",
       " 'поздно',\n",
       " 'выглядеть',\n",
       " 'читатель',\n",
       " 'ващий',\n",
       " 'радоваться',\n",
       " 'tukvasociopat',\n",
       " 'мило',\n",
       " 'сломать',\n",
       " 'дед',\n",
       " 'палец',\n",
       " 'забывать',\n",
       " 'дождаться',\n",
       " 'выздоравливать',\n",
       " 'отдать',\n",
       " 'старое',\n",
       " 'удалить',\n",
       " 'дура',\n",
       " 'молодёжка',\n",
       " 'ради',\n",
       " 'никак',\n",
       " 'наушник',\n",
       " 'поднять',\n",
       " 'возможно',\n",
       " 'шк',\n",
       " 'видно',\n",
       " 'баба',\n",
       " 'называться',\n",
       " 'follow',\n",
       " 'попросить',\n",
       " 'вчерашний',\n",
       " 'выпить',\n",
       " 'учитель',\n",
       " 'волгоград',\n",
       " 'платье',\n",
       " 'рассказывать',\n",
       " 'менять',\n",
       " 'ошибка',\n",
       " 'сожаление',\n",
       " 'оч',\n",
       " 'включить',\n",
       " 'аааа',\n",
       " 'сегодняня',\n",
       " 'оценка',\n",
       " 'хахи',\n",
       " 'всетаки',\n",
       " 'гдеть',\n",
       " 'киев',\n",
       " 'принести',\n",
       " 'злой',\n",
       " 'присниться',\n",
       " 'переживать',\n",
       " 'ржать',\n",
       " 'заставить',\n",
       " 'реклама',\n",
       " 'повезти',\n",
       " 'ожидать',\n",
       " 'дааа',\n",
       " 'карочий',\n",
       " 'мечтать',\n",
       " 'красиво',\n",
       " 'жуйк',\n",
       " 'олимпиада',\n",
       " 'грустный',\n",
       " 'танцевать',\n",
       " 'путин',\n",
       " 'тепло',\n",
       " 'кататься',\n",
       " 'позитив',\n",
       " 'ток',\n",
       " 'питер',\n",
       " 'еслина',\n",
       " 'просыпаться',\n",
       " 'бросить',\n",
       " 'ооо',\n",
       " 'собраться',\n",
       " 'ктонибыть',\n",
       " 'умирать',\n",
       " 'кошка',\n",
       " 'сосед',\n",
       " 'умный',\n",
       " 'откуда',\n",
       " 'рисовать',\n",
       " 'покан',\n",
       " 'господь',\n",
       " 'многий',\n",
       " 'лёгкий',\n",
       " 'катя',\n",
       " 'загадать',\n",
       " 'выучить',\n",
       " 'список',\n",
       " 'жизньболь',\n",
       " 'например',\n",
       " 'егон',\n",
       " 'тяжело',\n",
       " 'шутка',\n",
       " 'зимний',\n",
       " 'плач',\n",
       " 'вариант',\n",
       " 'назвать',\n",
       " 'разговор',\n",
       " 'пропасть',\n",
       " 'ах',\n",
       " 'давнона',\n",
       " 'чутьня',\n",
       " 'держать',\n",
       " 'отдыхать',\n",
       " 'цвет',\n",
       " 'физр',\n",
       " 'больной',\n",
       " 'нь',\n",
       " 'судить',\n",
       " 'контакт',\n",
       " 'вечно',\n",
       " 'мать',\n",
       " 'сложный',\n",
       " 'поспать',\n",
       " 'коготь',\n",
       " 'q',\n",
       " 'поесть',\n",
       " 'кровь',\n",
       " 'ппц',\n",
       " 'хуйня',\n",
       " 'онана',\n",
       " 'ситуация',\n",
       " 'пздец',\n",
       " 'альбом',\n",
       " 'футбол',\n",
       " 'почитать',\n",
       " 'штука',\n",
       " 'пацан',\n",
       " 'ссылка',\n",
       " 'почемуть',\n",
       " 'память',\n",
       " 'компания',\n",
       " 'врач',\n",
       " 'тт',\n",
       " 'чудо',\n",
       " 'какно',\n",
       " 'близкий',\n",
       " 'бл',\n",
       " 'обычный',\n",
       " 'сюда',\n",
       " 'скачать',\n",
       " 'хрен',\n",
       " 'хреновый',\n",
       " '111213',\n",
       " 'ухо',\n",
       " 'поиграть',\n",
       " 'снежок',\n",
       " 'закрыть',\n",
       " 'проводить',\n",
       " 'добавить',\n",
       " 'какаять',\n",
       " 'послушать',\n",
       " 'фраза',\n",
       " 'устроить',\n",
       " 'серьёзно',\n",
       " 'срочно',\n",
       " 'айфон',\n",
       " 'встречать',\n",
       " 'статус',\n",
       " 'команда',\n",
       " 'согласный',\n",
       " 'впервые',\n",
       " 'детский',\n",
       " 'красота',\n",
       " 'пиво',\n",
       " 'свободный',\n",
       " 'улыбаться',\n",
       " 'шапка',\n",
       " 'личный',\n",
       " 'виноватый',\n",
       " 'завидовать',\n",
       " 'четверг',\n",
       " 'фу',\n",
       " 'teamfollowback',\n",
       " 'подряд',\n",
       " 'пользоваться',\n",
       " 'улыбка',\n",
       " 'кончиться',\n",
       " 'живот',\n",
       " 'очередь',\n",
       " 'чё',\n",
       " 'жесть',\n",
       " 'случайно',\n",
       " 'сутки',\n",
       " 'идеальный',\n",
       " 'хз',\n",
       " 'результат',\n",
       " 'унея',\n",
       " 'летом',\n",
       " 'спокойно',\n",
       " 'напомнить',\n",
       " 'извинить',\n",
       " 'ща',\n",
       " 'сеть',\n",
       " 'шо',\n",
       " 'почта',\n",
       " 'счёт',\n",
       " 'мнение',\n",
       " 'збс',\n",
       " 'ахахха',\n",
       " 'центр',\n",
       " 'привыкнуть',\n",
       " 'посидеть',\n",
       " 'чтонибыть',\n",
       " 'илинуть',\n",
       " 'решать',\n",
       " 'gt',\n",
       " 'выбрать',\n",
       " 'редко',\n",
       " 'лететь',\n",
       " 'даша',\n",
       " 'здорово',\n",
       " 'геометрия',\n",
       " 'услышать',\n",
       " 'тест',\n",
       " 'приходиться',\n",
       " 'знаете',\n",
       " 'бывать',\n",
       " 'снимать',\n",
       " 'судьба',\n",
       " 'ненавидеть',\n",
       " 'зал',\n",
       " 'the',\n",
       " 'пизда',\n",
       " 'снять',\n",
       " 'трудно',\n",
       " 'продолжать',\n",
       " 'забить',\n",
       " 'стараться',\n",
       " 'шерлок',\n",
       " 'здоровье',\n",
       " 'тож',\n",
       " '2014',\n",
       " 'помоему',\n",
       " 'огонь',\n",
       " 'левый',\n",
       " 'страдать',\n",
       " 'поздравление',\n",
       " '40',\n",
       " 'привезти',\n",
       " 'ciooptimal',\n",
       " 'минь',\n",
       " 'зуб',\n",
       " 'внимание',\n",
       " 'спин',\n",
       " 'подойти',\n",
       " 'держаться',\n",
       " 'удачный',\n",
       " 'выиграть',\n",
       " 'отмечать',\n",
       " 'собрать',\n",
       " 'звонок',\n",
       " 'теперьня',\n",
       " 'белый',\n",
       " 'путь',\n",
       " 'орать',\n",
       " 'удаться',\n",
       " 'эмоция',\n",
       " 'вика',\n",
       " 'падать',\n",
       " 'тело',\n",
       " 'всена',\n",
       " 'любим',\n",
       " 'предлагать',\n",
       " 'захотеть',\n",
       " 'закончить',\n",
       " 'курить',\n",
       " 'причина',\n",
       " 'тупо',\n",
       " 'увы',\n",
       " 'российский',\n",
       " 'среда',\n",
       " '25',\n",
       " 'хрень',\n",
       " 'дарить',\n",
       " 'отдохнуть',\n",
       " 'выбор',\n",
       " 'биология',\n",
       " 'подходить',\n",
       " 'получать',\n",
       " 'зимой',\n",
       " 'карта',\n",
       " 'причём',\n",
       " '50',\n",
       " 'mtvstars',\n",
       " 'фига',\n",
       " 'цена',\n",
       " 'высокий',\n",
       " 'возможность',\n",
       " 'название',\n",
       " 'обед',\n",
       " 'ааааа',\n",
       " 'иначе',\n",
       " 'внезапно',\n",
       " 'серый',\n",
       " 'обидеться',\n",
       " 'смешной',\n",
       " 'полностью',\n",
       " 'плюс',\n",
       " 'стихнуть',\n",
       " 'ноут',\n",
       " 'пьяный',\n",
       " 'дурацкий',\n",
       " 'скайп',\n",
       " 'домашний',\n",
       " 'клуб',\n",
       " 'заставлять',\n",
       " 'грусть',\n",
       " 'программа',\n",
       " 'чета',\n",
       " 'звезда',\n",
       " 'наний',\n",
       " '18',\n",
       " 'успевать',\n",
       " 'порадовать',\n",
       " 'целое',\n",
       " 'разбудить',\n",
       " 'просмотр',\n",
       " 'дверь',\n",
       " 'ктоня',\n",
       " 'победитель',\n",
       " 'молчать',\n",
       " 'скучный',\n",
       " 'вообщеть',\n",
       " 'долгий',\n",
       " 'кидать',\n",
       " 'пипец',\n",
       " 'познакомиться',\n",
       " 'захотеться',\n",
       " 'слава',\n",
       " 'заказать',\n",
       " 'минус',\n",
       " 'положить',\n",
       " 'игрушка',\n",
       " 'жутко',\n",
       " 'смерть',\n",
       " 'увидеться',\n",
       " 'сын',\n",
       " 'инстагра',\n",
       " 'типо',\n",
       " 'рота',\n",
       " 'канал',\n",
       " 'приложение',\n",
       " 'смех',\n",
       " 'факт',\n",
       " 'і',\n",
       " 'юм',\n",
       " '14',\n",
       " 'пароль',\n",
       " 'тебена',\n",
       " 'онина',\n",
       " '0',\n",
       " 'этогон',\n",
       " 'наоборот',\n",
       " 'шоколадка',\n",
       " 'создать',\n",
       " 'текст',\n",
       " 'жирный',\n",
       " 'проект',\n",
       " 'многие',\n",
       " 'никомуна',\n",
       " 'сдохнуть',\n",
       " 'youtube',\n",
       " 'сто',\n",
       " 'клип',\n",
       " 'мелкий',\n",
       " 'впереди',\n",
       " 'убивать',\n",
       " 'солнце',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OULZgvkJzpj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqHlf5nNJ2hl"
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"text\"]], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lI4NUg_TJ6NK",
    "outputId": "e99a70c8-c38c-4be2-d34c-8e0f8d91c6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181467, 40)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9QlLvXd9KDf3",
    "outputId": "1d7af667-9aaf-410b-b786-a520b60edd40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 202, 437, 158,\n",
       "         6], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-WNRvya-dpX"
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "351mgj6H-dpX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clOLjuCM-dpZ"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(df_train[\"class\"], num_classes)\n",
    "y_val = keras.utils.to_categorical(df_val[\"class\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDW3lJvB-dpc"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jsy2ADwU-dpe"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "hYIMDTeO-dph",
    "outputId": "f7c7b423-4a9b-4ac9-9f83-fbb787a6ae3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  2/319 [..............................] - ETA: 13s - loss: 0.6928 - accuracy: 0.5068WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0267s vs `on_train_batch_end` time: 0.0561s). Check your callbacks.\n",
      "319/319 [==============================] - 8s 24ms/step - loss: 0.5744 - accuracy: 0.6813 - val_loss: 0.5499 - val_accuracy: 0.6999\n",
      "Epoch 2/20\n",
      "319/319 [==============================] - 8s 24ms/step - loss: 0.5327 - accuracy: 0.7164 - val_loss: 0.5470 - val_accuracy: 0.7015\n",
      "Epoch 3/20\n",
      "319/319 [==============================] - 8s 24ms/step - loss: 0.5066 - accuracy: 0.7360 - val_loss: 0.5500 - val_accuracy: 0.7021\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "ftp9ODiZ-dpj",
    "outputId": "42ce7d4b-c5af-4571-90b1-25de80cb18de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 9ms/step - loss: 0.5614 - accuracy: 0.6941\n",
      "\n",
      "\n",
      "Test score: 0.5614053606987\n",
      "Test accuracy: 0.6941321492195129\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CAm6vqN--dpm",
    "outputId": "90018719-0bd1-4182-9647-d39a5e26968d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILtp5YFT-dpo"
   },
   "source": [
    "Теперь посмотрим word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "QOkSlY-m-dpo",
    "outputId": "f968df8a-38a4-4b45-8088-8d84e814419f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [alisachachkaн, уезжаааааааать, ❤, тожена, уез...\n",
       "1    [rt, galyginvadim, ребята, девчата, кино, любо...\n",
       "Name: text_token, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "df_train['text_token'] = df_train['text'].apply(lambda x: nltk.tokenize.word_tokenize(x))\n",
    "df_train['text_token'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEQdLlE2-dpq"
   },
   "outputs": [],
   "source": [
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maAcuJiQ-dps"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "modelW2V = Word2Vec(sentences=df_train['text_token'], size=max_len, window=5, min_count=2, sg = 1, hs = 0, negative = 10, workers= 32, seed = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vhwOTPn7M_85",
    "outputId": "3c1eba85-754c-440a-823e-8765a48491dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(df_train['text_token'])\n",
    "modelW2V.train([[\"hello\", \"world\"]], total_examples=l, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FhrEbZZ2-dpx",
    "outputId": "372ee229-e2e8-48ea-f0cc-a087bf0aa21a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['❤',\n",
       " 'тожена',\n",
       " 'уезжать',\n",
       " 'rt',\n",
       " 'galyginvadim',\n",
       " 'ребята',\n",
       " 'девчата',\n",
       " 'кино',\n",
       " 'любовь',\n",
       " 'завтра']"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(modelW2V.wv.vocab.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64XrzY5T-dpz"
   },
   "outputs": [],
   "source": [
    "def get_vector(tweet, model, size):\n",
    "    vector = np.zeros(size)\n",
    "    norm = 0\n",
    "    for word in tweet:\n",
    "        if word in model:\n",
    "#            print(model[word])\n",
    "            vector += model[word]\n",
    "            norm += 1\n",
    "    if norm > 0:\n",
    "        vector = vector / norm\n",
    "#    print(vector)    \n",
    "    return vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekginNuR-dp1"
   },
   "outputs": [],
   "source": [
    "def word2vec(text, max_len):\n",
    "    padding = get_vector(text, modelW2V, max_len)        \n",
    "    return padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "Nqe4pp7N-dp2",
    "outputId": "60b07f17-3fb1-4cb8-a423-623021efc50b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "x_train = np.asarray([word2vec(text, max_len) for text in df_train[\"text\"]], dtype=np.float)\n",
    "x_test = np.asarray([word2vec(text, max_len) for text in df_test[\"text\"]], dtype=np.float)\n",
    "x_val = np.asarray([word2vec(text, max_len) for text in df_val[\"text\"]], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "haKAIbUK-dp4",
    "outputId": "5cd2e6f3-70be-443f-b5ca-39ac6c23e5b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06971743,  0.11461692,  0.01857886,  0.17572134,  0.1337138 ,\n",
       "       -0.06400263, -0.08668889, -0.23518825,  0.00785943, -0.03390469,\n",
       "        0.21238295, -0.04811243, -0.12852715,  0.16513976, -0.15731257,\n",
       "        0.1378894 , -0.09309374,  0.08760185,  0.1184424 ,  0.09868269,\n",
       "        0.14519504,  0.16162618,  0.18734167, -0.03032083, -0.19047221,\n",
       "       -0.18847665, -0.05904012,  0.06857269, -0.07616063,  0.08437547,\n",
       "        0.02572098,  0.01014211, -0.00037681, -0.24608478, -0.00647513,\n",
       "       -0.20026101,  0.00762361, -0.03444053,  0.23609251,  0.09397777,\n",
       "        0.08381789,  0.02750923,  0.072346  , -0.1281656 , -0.04202159,\n",
       "       -0.29754912,  0.06536306,  0.05637842,  0.20915617,  0.09762205,\n",
       "       -0.09389511,  0.11918464,  0.1220331 , -0.17528061, -0.11039565,\n",
       "       -0.06862528,  0.29002417, -0.09558262,  0.01054835,  0.08506566,\n",
       "        0.01316793, -0.0038082 ,  0.17293618,  0.35604502,  0.10074459,\n",
       "        0.14606528,  0.04433867, -0.2578047 , -0.00597849, -0.07317959,\n",
       "       -0.03987283, -0.15566725,  0.02318823,  0.08828872, -0.12799802,\n",
       "       -0.00815973, -0.06914451,  0.02456844, -0.2017298 ,  0.03857887,\n",
       "       -0.06576869, -0.05835318,  0.00802008,  0.15648177, -0.10042057,\n",
       "       -0.03447417, -0.10830017,  0.08968511,  0.22872281, -0.0844124 ,\n",
       "        0.04492909, -0.07987026,  0.05227531,  0.10995432,  0.08058836,\n",
       "        0.06745687, -0.07038474,  0.21820602,  0.06816464,  0.24200516,\n",
       "       -0.08512611, -0.07238612,  0.02784056,  0.03632559,  0.01383661,\n",
       "        0.30782515,  0.04402101,  0.142335  ,  0.1119353 , -0.03398324,\n",
       "       -0.15681222,  0.10915068,  0.27282717,  0.04046903,  0.17650947,\n",
       "        0.12704147,  0.07792885, -0.29243647, -0.16801446,  0.19813745,\n",
       "        0.02061481, -0.1086471 ,  0.11860793,  0.03863767,  0.10174324,\n",
       "        0.06362159,  0.08639355, -0.00277142,  0.22345136,  0.16962221,\n",
       "        0.01524108,  0.03365291,  0.1002708 , -0.14317104, -0.2898024 ,\n",
       "       -0.18658838, -0.1180441 , -0.20579182,  0.05740211,  0.08701841,\n",
       "        0.0601629 , -0.14095852, -0.05952767, -0.16108188, -0.023241  ,\n",
       "        0.00099953, -0.08520915,  0.05047074, -0.13965442, -0.08426885,\n",
       "       -0.01656966,  0.18514075, -0.10182512,  0.19594671,  0.30214316,\n",
       "        0.05173642, -0.08989805, -0.13610338,  0.10817395,  0.04424337,\n",
       "       -0.0669745 , -0.00445016, -0.03396631, -0.06131429,  0.15355553,\n",
       "        0.01375521, -0.00260763,  0.19021859, -0.09672671,  0.23770886,\n",
       "       -0.20655733, -0.00656339, -0.22998271,  0.03546786,  0.12348289,\n",
       "        0.0800238 , -0.04812788, -0.03679642,  0.05352881,  0.11768636,\n",
       "        0.03628042, -0.15823517, -0.08651669, -0.09387485, -0.07602178,\n",
       "       -0.08481563,  0.06806605,  0.24204311,  0.01677351, -0.07989869,\n",
       "        0.09766316, -0.06834237, -0.0328949 , -0.07841844,  0.14588307,\n",
       "        0.09958003,  0.23002325, -0.00312014, -0.03321204,  0.01344592])"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPPelbr8xT_B"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVtK8LkJxfm-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "38TEsl2n-dp7",
    "outputId": "0b784344-f607-4503-96b5-86bc69b3abc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "319/319 [==============================] - 27s 85ms/step - loss: 0.6931 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5049\n",
      "Epoch 2/20\n",
      "319/319 [==============================] - 27s 85ms/step - loss: 0.6931 - accuracy: 0.5065 - val_loss: 0.6931 - val_accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "trGK_Reb-dp9",
    "outputId": "fe6c3878-5182-4ef0-e860-af9b5056fc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 33ms/step - loss: 0.6931 - accuracy: 0.5047\n",
      "\n",
      "\n",
      "Test score: 0.6931247115135193\n",
      "Test accuracy: 0.5047392249107361\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Lie8Hz9p-dp-",
    "outputId": "c52d4573-d435-4c6b-d43b-fc549f2e2704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: в случае word2vec Test score=0.69, а было 0.56, но Test accuracy=0.5047 (было 0.69). score увеличился, а accuracy точность уменьшилась. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw05-nlp-cnn1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
